<transcript><text start="0.0" dur="3.56">human intelligence</text><text start="4.22" dur="5.5">Unbound by wisdom</text><text start="7.259" dur="4.441">it is fair to say is the cause of the</text><text start="9.72" dur="3.72">metacrisis and the growth imperative of</text><text start="11.7" dur="4.339">the superorganism or the capacity that</text><text start="13.44" dur="5.4">gives rise to it</text><text start="16.039" dur="4.841">that intelligence has created all the</text><text start="18.84" dur="4.56">Technologies the industrial Tech the</text><text start="20.88" dur="5.159">agricultural tech the digital Tech the</text><text start="23.4" dur="4.02">nuclear weapons the energy harvesting</text><text start="26.039" dur="3.361">the all of it that intelligence has</text><text start="27.42" dur="4.32">created all those things</text><text start="29.4" dur="4.319">it has made the system of capitalism it</text><text start="31.74" dur="5.88">made the system communism although all</text><text start="33.719" dur="4.561">of those things right and</text><text start="37.62" dur="4.14">um</text><text start="38.28" dur="5.459">now that system of intelligence it takes</text><text start="41.76" dur="3.72">corporeal capacities things that a body</text><text start="43.739" dur="3.961">could do and externalizes them the way</text><text start="45.48" dur="4.14">that a fist can get extended through a</text><text start="47.7" dur="3.42">hammer or a grip can get extended</text><text start="49.62" dur="2.939">through a plier or an eye can get</text><text start="51.12" dur="3.06">extended through a microscope or a</text><text start="52.559" dur="3.721">telescope</text><text start="54.18" dur="4.019">um or our own metabolism can get</text><text start="56.28" dur="3.36">extended through an internal combustion</text><text start="58.199" dur="2.941">engine or there are musculature or</text><text start="59.64" dur="4.02">whatever it is right so it takes the</text><text start="61.14" dur="6.12">corporeal capacity and extends the</text><text start="63.66" dur="5.52">out of it extracorporeally so that type</text><text start="67.26" dur="4.74">of intelligence that does that is now</text><text start="69.18" dur="5.4">having the extra corporeal technology be</text><text start="72.0" dur="5.659">that type of intelligence itself in</text><text start="74.58" dur="6.92">maximize recursion</text><text start="77.659" dur="3.841">not bound by wisdom</text><text start="81.9" dur="4.38">driven by</text><text start="83.759" dur="6.18">International multi-polar military traps</text><text start="86.28" dur="9.8">and markets and narrow short-term goals</text><text start="89.939" dur="6.141">at the expense of long-term wide values</text><text start="96.54" dur="4.98">so where</text><text start="99.119" dur="4.64">in The Meta crisis there are many risks</text><text start="101.52" dur="5.099">synthetic biology can make bad pandemics</text><text start="103.759" dur="5.021">and extreme weather events can drive</text><text start="106.619" dur="3.96">human migration in local Wars and this</text><text start="108.78" dur="3.54">kind of weapon can do this and this kind</text><text start="110.579" dur="3.9">of mining can cause us pollution and</text><text start="112.32" dur="3.659">this kind of pesticide can kill these</text><text start="114.479" dur="4.081">animals those are all risks within the</text><text start="115.979" dur="5.1">meta crisis AI</text><text start="118.56" dur="5.94">is not a risk within the meta crisis it</text><text start="121.079" dur="5.64">is an accelerant to all of them</text><text start="124.5" dur="4.02">as used by the choice making</text><text start="126.719" dur="3.481">architectures that are currently driving</text><text start="128.52" dur="2.939">The Meta crisis if we weren't in the</text><text start="130.2" dur="2.94">meta crisis if we had different Choice</text><text start="131.459" dur="4.021">making architectures we'd be using AI</text><text start="133.14" dur="4.5">for different things but if AI is in</text><text start="135.48" dur="3.6">service of human goals and human goals</text><text start="137.64" dur="3.599">have driven the superorganism and The</text><text start="139.08" dur="4.2">Meta crisis the way they are then this</text><text start="141.239" dur="4.321">context of human goals as an accelerant</text><text start="143.28" dur="5.16">of them all now if I think about AGI</text><text start="145.56" dur="4.56">risk let's make we we make an AI that is</text><text start="148.44" dur="4.28">fully autonomous we can't pull the plug</text><text start="150.12" dur="4.44">it has goals that aren't ours it starts</text><text start="152.72" dur="3.7">optimizing for those and then the</text><text start="154.56" dur="3.6">process decides to use all the atoms for</text><text start="156.42" dur="3.899">something else and completely terraforms</text><text start="158.16" dur="4.079">the Earth right which it could do it</text><text start="160.319" dur="3.78">could totally do and we're moving way</text><text start="162.239" dur="3.061">faster towards that than we are towards</text><text start="164.099" dur="3.541">safety on that</text><text start="165.3" dur="6.18">that is a risk within the metacrisis</text><text start="167.64" dur="5.52">landscape but AI being used by all types</text><text start="171.48" dur="3.6">of militaries all types of governments</text><text start="173.16" dur="3.719">all types of Corporations for all types</text><text start="175.08" dur="4.62">of purposes achieving narrow goals</text><text start="176.879" dur="4.561">externalizing harm to wide goals is an</text><text start="179.7" dur="3.119">accelerant of the meta crisis on every</text><text start="181.44" dur="4.32">dimension</text><text start="182.819" dur="4.861">and so now as we take the intelligence</text><text start="185.76" dur="3.36">that has driven these problems Unbound</text><text start="187.68" dur="4.02">by wisdom</text><text start="189.12" dur="6.839">and we exponentialize that kind of</text><text start="191.7" dur="6.119">intelligence we get to see whoa</text><text start="195.959" dur="4.92">super intelligence is really</text><text start="197.819" dur="4.5">potent what goals are worth optimizing</text><text start="200.879" dur="3.36">with that much power with something</text><text start="202.319" dur="4.381">that's a trillion trillion times smarter</text><text start="204.239" dur="4.381">and faster than humans what goals are</text><text start="206.7" dur="4.56">worth optimizing it's not Global GDP</text><text start="208.62" dur="4.38">because I can increase GDP with war and</text><text start="211.26" dur="3.839">addiction and all all kinds of things</text><text start="213.0" dur="4.86">and destroy the environment every</text><text start="215.099" dur="5.161">definition and any so I say okay it's</text><text start="217.86" dur="3.72">GDP plus Genie coefficient plus this</text><text start="220.26" dur="3.42">other thing plus carbon plus whatever</text><text start="221.58" dur="4.26">nope there's still lots of life that</text><text start="223.68" dur="4.86">matters outside of those 10 metrics or</text><text start="225.84" dur="6.0">100 metrics that I can damage to improve</text><text start="228.54" dur="5.88">those the metric set that is definable</text><text start="231.84" dur="3.959">like the doubt itching says the Dow that</text><text start="234.42" dur="2.819">is speakable in words is not the Eternal</text><text start="235.799" dur="4.321">doubt</text><text start="237.239" dur="5.881">the metric set that is definable is not</text><text start="240.12" dur="5.28">the right metric set so if I keep</text><text start="243.12" dur="4.979">expanding the metric set to be GDP plus</text><text start="245.4" dur="4.68">dot dot dot I can still do a weighted</text><text start="248.099" dur="3.481">optimization with an AI on this and</text><text start="250.08" dur="4.2">destroy life</text><text start="251.58" dur="4.74">and the unknown unknown means there will</text><text start="254.28" dur="3.66">always be stuff that matters that has to</text><text start="256.32" dur="3.599">be pulled in where I don't want to run</text><text start="257.94" dur="3.299">optimization on this thing so then the</text><text start="259.919" dur="3.421">question comes if I have something that</text><text start="261.239" dur="4.201">can optimize so powerfully</text><text start="263.34" dur="4.56">what is the right thing to guide that</text><text start="265.44" dur="4.08">it's the thing that can identify the</text><text start="267.9" dur="3.299">difference between the set of metrics</text><text start="269.52" dur="3.42">you've identified as important in</text><text start="271.199" dur="4.201">reality itself</text><text start="272.94" dur="5.819">the limits of your own models</text><text start="275.4" dur="5.16">that is not intelligence that is wisdom</text><text start="278.759" dur="3.66">I'm defining these roughly in a way that</text><text start="280.56" dur="5.22">you get the someone gets the sense of</text><text start="282.419" dur="5.401">the difference between what the weighted</text><text start="285.78" dur="4.139">metric set of all the identified</text><text start="287.82" dur="4.74">important metrics and the optimization</text><text start="289.919" dur="3.84">function on it says you should do the</text><text start="292.56" dur="3.78">difference between that and what you</text><text start="293.759" dur="4.981">should actually do is wisdom and it</text><text start="296.34" dur="4.859">requires being able to attune to more</text><text start="298.74" dur="5.58">than just the known metrics</text><text start="301.199" dur="5.22">and more than just the optimization and</text><text start="304.32" dur="5.7">logic process on those</text><text start="306.419" dur="5.461">and so as super intelligence shows us</text><text start="310.02" dur="5.1">how dangerous narrow</text><text start="311.88" dur="5.099">optimization is it even shows us our own</text><text start="315.12" dur="4.32">intelligence and our own intelligence</text><text start="316.979" dur="5.121">running across all the humans via things</text><text start="319.44" dur="5.16">like markets that and the market</text><text start="322.1" dur="4.48">incentivizes some humans to innovate new</text><text start="324.6" dur="4.379">ways to turn the world into dollars and</text><text start="326.58" dur="4.08">other humans to</text><text start="328.979" dur="3.361">um take those Innovations and exploit</text><text start="330.66" dur="3.36">the out of them right so you both</text><text start="332.34" dur="3.6">search algorithms and optimization</text><text start="334.02" dur="4.08">algorithms the market makes the general</text><text start="335.94" dur="4.68">intelligence of humans do those in</text><text start="338.1" dur="4.379">groups so the cybernetic intelligence of</text><text start="340.62" dur="4.26">Corporations and nation states in the</text><text start="342.479" dur="5.22">world as a whole is already a general</text><text start="344.88" dur="4.86">autonomous super intelligence running on</text><text start="347.699" dur="4.56">all the humans as general intelligence</text><text start="349.74" dur="6.179">is rather than running on CPUs but also</text><text start="352.259" dur="5.461">using all the CPUs and tpus and gpus in</text><text start="355.919" dur="4.681">service of</text><text start="357.72" dur="4.919">the collection of all the narrow goals</text><text start="360.6" dur="5.159">so</text><text start="362.639" dur="5.28">AI accelerates The Meta crisis but it</text><text start="365.759" dur="4.44">also makes clear to us that what it</text><text start="367.919" dur="3.481">would take to align it is you cannot</text><text start="370.199" dur="2.881">have and this is why the question you</text><text start="371.4" dur="4.2">asked who's building it and who owns it</text><text start="373.08" dur="4.44">and what goals do those groups have</text><text start="375.6" dur="4.5">if you wanted to make a super</text><text start="377.52" dur="4.98">intelligence that was aligned with the</text><text start="380.1" dur="3.9">thriving of all life and perpetuity the</text><text start="382.5" dur="2.819">group that was building it would have to</text><text start="384.0" dur="4.16">have the goal of the thriving of all</text><text start="385.319" dur="2.841">life in perpetuity which</text></transcript>
