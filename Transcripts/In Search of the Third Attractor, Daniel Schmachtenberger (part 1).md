---
tags: transcript
aliases:
youtube_id: 8XCXvzQdcug
published_at: '2022-08-16'
---

<div class="yt-container"><iframe src="https://www.youtube.com/embed/8XCXvzQdcug"></iframe></div>

music music my hope with this content today is that we can give a bit of an overview of some of the [[catastrophic risk|catastrophic risks]] that the world currently faces why the solutions to some of those risks can actually make other of the risks [31](https://www.youtube.com/watch?v=8XCXvzQdcug&t=31.199s)

worse why the solutions to the risk landscape as a whole can create dystopias because to have the power to be able to check all the [[catastrophic risk|catastrophic risks]] then uh becomes a a very constant can become a very concentrated power [51](https://www.youtube.com/watch?v=8XCXvzQdcug&t=51.28s)

that is itself hard to check all of these risks are unsolvable without solving the things the patterns of human behavior that give rise to them but that the patterns of human behavior that give rise to them can be named and can be progressively not perfectly but [68](https://www.youtube.com/watch?v=8XCXvzQdcug&t=68.96s)

progressively better addressed and that in doing so there is a possibility to create a attractor for the world that is not catastrophes or dystopias in which we have the responsibility and wisdom adequate individually and collectively to steward the power [93](https://www.youtube.com/watch?v=8XCXvzQdcug&t=93.36s)

of the exponential technology that we are creating and the hope of this as a introduction is that people might feel that it helps them make sense of what feels like lots of different problems in the world in a way that is hopefully clarifying and integrating and they can have [118](https://www.youtube.com/watch?v=8XCXvzQdcug&t=118.0s)

more people engage in the kind of innovation and [[collective intelligence]] towards solutions to the deepest underlying dynamics yeah so in the conversations that you and i had leading up to deciding to do this piece i realized that we have done these pieces on this [139](https://www.youtube.com/watch?v=8XCXvzQdcug&t=139.36s)

channel before on [[sensemaking]] which many people engaged with and responded to and i was really happy to do together and that the entire topic of [[sensemaking]] is a facet of this larger topic of what we're going to explore today what you know i might kind of call and [158](https://www.youtube.com/watch?v=8XCXvzQdcug&t=158.879s)

shorthand the [[metacrisis]] [[metacrisis]] meaning [[climate change]] and many different environmental issues from topsoil erosion to [[dead zone|dead zones]] in ocean to pollinators to um biodiversity loss you know [[species extinction]] etc to a lot of new [[existential risk|existential risks]] as a result of new emerging fields of exponential technology ai biotech nanotech drone cyber etc to the intersection of a [[economic system]] that requires continuous [[exponential growth]] with a planet that is reaching [[planetary boundary|planetary boundaries]] that all of these are uh very serious issues and thinking about any of them can seem kind of overwhelming thinking about all of them together the only way i have found uh to think about how we navigate that meaningfully is to start to explore do all of these issues have anything in [221](https://www.youtube.com/watch?v=8XCXvzQdcug&t=221.04s)

common are there any dynamics about how human coordination and [[collective action]] and patterns of human choice making and patterns of human choice making intersecting with things like markets and states and technology work that both give rise to these kind of human-induced problems and [242](https://www.youtube.com/watch?v=8XCXvzQdcug&t=242.56s)

make them challenging to shift and both that collective set of crises and the underlying dynamics that give rise to them is what we think of as kind of the the [[metacrisis]] which is i would say a very a meaningful way to orient to what humanity needs to address at this current phase and the issue with [[sensemaking]] is a part of that if we can't agree on what the nature of the issues are that need addressed or what good solutions look like then some percentage of the people go working on a thing they think is important like a particular approach to [[climate change]] and the other half of the population that radically disagrees with them does everything they can to prevent that from happening or since we can't all agree to do a particular thing like nuclear disarmament or not doing the ai weapons or making the cost of carbon higher or to deal with externalities if we can't all [302](https://www.youtube.com/watch?v=8XCXvzQdcug&t=302.56s)

internationally agree to that anyone that consciously chooses to do that disadvantages themselves in a geopolitical game of power relative to others therefore nobody can do the effective thing and then you just have kind of [[collective action]] failures that create races to the bottom if we can't have some better shared [[sensemaking]] of what needs done to inform better coordination collective choice making obviously we don't even have like a starting point so all the conversations on [[sensemaking]] are one really critical part of this and i'm not going to readdress those because we've done that on the channel people can check it out if they're interested [340](https://www.youtube.com/watch?v=8XCXvzQdcug&t=340.08s)

i'm going to try to just do like apply some [[sensemaking]] to look at some frameworks for how to make sense of what's going on that might lead to design criteria for what more adequate solutions could look like that hopefully get more people engaging in in innovative generative ways along [363](https://www.youtube.com/watch?v=8XCXvzQdcug&t=363.759s)

these lines the exponential power of [[exponential tech]] makes via decentralization catastrophes more likely as and it doesn't matter which one whether it's this ai scenario or that ai scenario this bioscenario this environmental scenario or this warfare scenario we [383](https://www.youtube.com/watch?v=8XCXvzQdcug&t=383.199s)

just put them all in the bucket called cascading catastrophes or to be able to bind those catastrophes it has to bind all of them because any of the catastrophes are enough to break the thing down to bind all of them requires really centralized power or one possibility is really centralized power i'm going to say that there's [402](https://www.youtube.com/watch?v=8XCXvzQdcug&t=402.0s)

another possibility if it goes decentralized power capacity then that ends up looking like dystopias those are the two attractors that civilization is currently most likely heading in and we can see how the solutions to either one orient to the other one more if you try to say we don't want these dystopic things so we want to stop [420](https://www.youtube.com/watch?v=8XCXvzQdcug&t=420.0s)

authoritarian tech we want to decentralize and democratize technological capabilities then we get more [[collective action]] failures and decentralized catastrophic tech if you're like we don't want this we want some surveillance on this and whatever then we get more dystopic tech so i would say that we are seeking a [[third attractor]] that is neither catastrophes or dystopias seems like a pretty fair starting place for how do we design a civilization that is desirable or at least allows us to continue to advance in the on the meaningful questions what a desirable civilization is um involves being able to avoid the twin attractors of catastrophes and dystopias [460](https://www.youtube.com/watch?v=8XCXvzQdcug&t=460.4s)

and that those two must always be taken in consideration because it's very easy for a partial solution to externalize a problem somewhere else as we've mentioned before that one of the major problems with the world is the problem with our problem solving we define the problem generally externalize harm somewhere else that these we can solve for one [[catastrophic risk]] while making another one more likely we can also solve for [[catastrophic risk]] as a whole making dystopias more likely so we want to be able to hold the undesirable possibilities that are in relationship to each other at the same time we want to be able to hold all [493](https://www.youtube.com/watch?v=8XCXvzQdcug&t=493.36s)

the problems at the same time to then be able to say what does a solution look like it decreases the likelihood for all of those simultaneously since such a [[third attractor]] is defined at least to start as being something that avoids the other two attractors of catastrophes or dystopias we're going to start by sketching out [512](https://www.youtube.com/watch?v=8XCXvzQdcug&t=512.399s)

what the [[catastrophic risk]] landscape and the generative dynamics that give rise to it look like and what the kind of dystopic solution dynamics could look like so that we understand the underlying dynamics that have to be solved as a necessary but not sufficient starting point i want to share a few things in preface before diving in first is that the concepts that i'm sharing are not my concepts i claim no propriety i've been fortunate to be in dialogue for many years a lot of [559](https://www.youtube.com/watch?v=8XCXvzQdcug&t=559.12s)

uh really important thinkers in the field of [[existential risk]] in the environment and economics and you know also study a lot of people's work so i'm hoping to share some of the frameworks that i find most useful that is mostly a synthesis i wish i could do good attribution in real time for all of it but in a podcast form where it's [579](https://www.youtube.com/watch?v=8XCXvzQdcug&t=579.279s)

going to be edited it's tricky so what i'd say is i have a blog civilizationemerging.com there's a resources section you can look at the books articles um collaborators there and you'll see where a lot of you know the provenance of the ideas came from you can also go to the consilience project and the articles there are all well cited and you can also see [600](https://www.youtube.com/watch?v=8XCXvzQdcug&t=600.56s)

uh you know some of the team and advisors people i've worked with so that's just one important part next important part in preface is i absolutely don't claim that the frameworks i'm sharing are complete or adequate to make sense of everything um i'm continuously uh refining my own understanding of it in [629](https://www.youtube.com/watch?v=8XCXvzQdcug&t=629.76s)

this process so i this is halfway through 2022 that's my best current understanding of things i've no doubt that that will improve and that's actually one of the reasons to share this is so that if people have thoughts on better frameworks or errors that are here or [648](https://www.youtube.com/watch?v=8XCXvzQdcug&t=648.64s)

additions that more [[collective intelligence]] can be working in this direction of what are the most fundamental things to think about and work on for advancing what is most critical that's not already being tended to i also want to share that when we think about [666](https://www.youtube.com/watch?v=8XCXvzQdcug&t=666.16s)

global [[catastrophic risk|catastrophic risks]] and global [[existential risk|existential risks]] uh in particular it can be a very overwhelming and disheartening topic and um there's just a reality to that my hope is that i would neither leave anyone [687](https://www.youtube.com/watch?v=8XCXvzQdcug&t=687.92s)

in a disheartened place nor do i want to kind of present the bypass that there isn't uh a reality to feeling you know whatever feelings you feel about um the real challenges in the state of the world um for what it's worth i've been focused on [709](https://www.youtube.com/watch?v=8XCXvzQdcug&t=709.44s)

these issues for a very long time i felt existential angst and sadness and despair and fear and all kinds of things about it i continue to work on it because i also feel hope and a real sense of possibility to navigate through these things and so for whatever it's worth if you have not been if you're newer to this study uh as someone who has been looking at accidental risk for a very long time across lots of sectors i will just share for what it's worth i don't feel um that this is a hopeless situation i wouldn't be sharing here if i did i feel [749](https://www.youtube.com/watch?v=8XCXvzQdcug&t=749.36s)

like the solutions that are needed very much are threading the eye of a needle but i both have a sense of possible solutions possible architectures of a world that can be stable metastable in the presence of exponential technologies and pathways to enact those solutions it's not a given that we will but it's also not a given that we won't it feels still very much like a thing that our collective choices are determining the outcome of and so the hope in sharing this is uh that more people's intelligence and care makes a difference in uh navigating these things i also want to say that there are a lot of really important things that need done other than trying to figure out meta-systemic stuff about how to navigate the [[metacrisis]] and so if there's work that you're doing on that is aligned with this whether it's [812](https://www.youtube.com/watch?v=8XCXvzQdcug&t=812.16s)

work in animal rights or environmental work or social justice work or you're making intentional communities to prototype some things or community gardens and that feels like what is yours to do and a meaningful application of your agency i don't want focusing on the scale and complexity of these issues to be disheartening or make [832](https://www.youtube.com/watch?v=8XCXvzQdcug&t=832.399s)

it seem like what you're doing is less meaningful all those things have to keep happening and are really important for the some people who are oriented to try to work on how do we change our macroeconomic systems our governance systems our collective [[sensemaking]] and choice making systems the way we think about problem solving writ large the way we think about tech or at large what we think about education the way we deal with regulation of [[exponential tech]] hopefully this is useful there and even for people who are not necessarily going to be working in that area but just having a better s sense of the things you're already [866](https://www.youtube.com/watch?v=8XCXvzQdcug&t=866.72s)

sensing and intuiting in some way is at least helpful for orientation that would be my hope i think for the people who are probably drawn to listen to this i might share frameworks and details that you're not familiar with but it it probably resonates with an intuition [888](https://www.youtube.com/watch?v=8XCXvzQdcug&t=888.079s)

that many people have um i i think i mean i can share a little bit about just like brief aspects of my journey of like what got me into thinking about this um because i think it's actually i think the things that got me thinking about are pretty common i think i had some uncommon [908](https://www.youtube.com/watch?v=8XCXvzQdcug&t=908.24s)

exposure to things that allowed me to you know find different frameworks and put more time into the topics but um i i i was exposed to environmental work and animal rights work and extreme poverty work and things when i was pretty young my parents were into the topics and just getting engaged in kind of the field of activism you see a particular thing like the dolphins in the cove or [[factory farm|factory farms]] or what's happening in the amazon or the congo or whatever and that one thing seems worthy of the dedication of a whole life it seems so um catastrophic and unacceptable and um and then when you start to see lots of those things uh there's some sense that i had that i feel that i've heard many people have of like they're they seem somehow interconnected they seem somehow like [966](https://www.youtube.com/watch?v=8XCXvzQdcug&t=966.16s)

expressions of some underlying patterns of how humanity is operating that uh collectively are reaching a point as we have eight billion people globalization high technology high resource use per capita that they can't continue this way they're not just a bummer anymore they're um they're somehow kind [985](https://www.youtube.com/watch?v=8XCXvzQdcug&t=985.44s)

of [[self-terminating]] um and all somehow interconnected i think that i think some sense that there is a fundamental kind of reorientation that is not just a continuation of the dialectic of progress but is a kind of epochal phase shift of some kind it was the first conversation you and i had it's about this type of epochal [1013](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1013.04s)

phase shift i think an intuition like that is not uncommon um so that you know that kind of uh was there from pretty early in my exploration of the topics and uh something that was maybe a little bit unique in my experience was i was engaged in these areas of activism but also because of being homeschooled and because of what my parents were into i was reading buck mr fuller and kind of design science considerations reading fritz off [1048](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1048.16s)

capra and the kind of ecological systems thinkers that talked about the inner connectivity of it uh reading david baume and people who were and krishnamurti who were talking about the fragmentation of our worldview being underlying to all of the problems the ability to identify with an in-group and go into [1067](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1067.52s)

rivalry with an out-group the ability to optimize a particular metric while externalizing harm to other metrics that all the ability to benefit the near term while harming the long term that all of those were special case they were individual instances of the general thing of perceiving parts rather [1089](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1089.2s)

than holes where we would try to optimize parts in ways that damage the holes which ended up actually damaging the parts those kinds of world views i was exposed to early and so i was thinking about what are the underlying patterns of all these problems what could solutions to those [1110](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1110.799s)

things look like and specifically i got to see that some of the really well intended activism that did actually succeed in solving particular problems ended up unintentionally causing other problems in the process and i think there'd been a lot of critiques of philanthropy and people have come to [1132](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1132.0s)

understand this that i've spoke about this in other places but the the first one where this really hit me and then and then i saw this everywhere was a project that was working on stopping elephant poaching in a particular uh preserve and when you see how sentient elephants are when you see how kind of gruesome the poaching is for [1153](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1153.679s)

making rings or whatever out of ivory um doing whatever you can to just stop it is a very reasonable response but the solution was bigger fences around the uh preserve to keep poachers out and legislation for harsher sentencing for poachers for elephants particularly and after a huge amount of work to have those things occur [1176](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1176.24s)

the poaching of the white rhino and the mountain gorilla increased from some of the same people because the underlying poverty of the people hadn't changed a macroeconomic system that creates poverty at scale hadn't changed the [[value system|value systems]] towards animals hadn't changed an [[economic system]] where animals alive are not worth anything on anyone's [1198](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1198.16s)

balance sheet but animals dead are the like they were all those underlying drivers hadn't shifted and the other animals that were being poached now were actually more endangered and so not only did it not shift the underlying causes it arguably made other it made the the whole global situation worse and [1216](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1216.0s)

that was really devastating to me because like the first devastation was seeing uh seeing these issues at all it was uh [[factory farm|factory farms]] for me it was the first one and so then the solution was there is a thing called activism and we can make the things better the next devastation was seeing that the way we would try to make it better often made [1235](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1235.919s)

it worse and not in an obvious way because it did make it better for those elephants there right but as we zoom out if our goal is not these elephants here but is the kind of thriving of all life and perpetuity as best as possible uh then the way we define the problem has to get deeper and so we see that um gdp as a metric of the success of a nation is not an adequate metric uh it does seem to like in so far as you believe market ideology that gdp going up means more products and services that improve people's quality of life goes up it seems like a good idea insofar as you realize that war makes [1274](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1274.799s)

gdp go up and sick people engaging in more health expenses does and addiction makes it go up you realize okay and the gdp corresponds to environmental and sustainability gdp is not an adequate metric in the same way that that's the case we can start to over focus on the metric of these elephants here or carbon [1293](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1293.919s)

reductionism the whole focus is get co2 out of the air but we can do that through mechanisms that cause other environmental or social problems there's a need to kind of step back and say our approach to problem solving is actually one of the problems one of the underlying kind of generators is because [1312](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1312.64s)

we define the problems in too narrow a way and so when we define a problem in a narrow way then we can create a solution to that narrow problem that does benefit that thing but that interacts with a lot of other things and ends up causing externalities or harm in those other areas and so when we think about defining [1331](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1331.6s)

problems in a narrow way in a world that is actually interconnected and we're separating out from that interconnectedness a particular part that we care about want to advance we can and this is kind of what is unique to humans our capacity to understand particular parts with abstraction in a way that allows us to build tools our our technology creation [1349](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1349.36s)

capacities are one of the obvious things that is unique to uh to sapiens also allows us to advance parts irrespective of and in ways that are harmful to holes that end up creating these other issues so [1371](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1371.919s)

um so one of the defining kind of features of the [[metacrisis]] that became clear early on for me was that our way of thinking about problems is one of the problems and that we actually have to have a much more holistic way of thinking about uh what is worth advancing what are all of the [1391](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1391.36s)

things that are driving a particular problem and what are the possible things that will come out of a particular solution that might create other problems to other metrics to other areas to other agents you know to other beings and how to factor all of that into what solutions are actually solutions worth advancing it was long tangent on saying i think [1411](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1411.52s)

that the intuition that we're at some kind of inflection point that there are is something about the nature of how we think about things and how we go about solving problems and how we go about advancing things that there is some change that has to occur at a deep level like that i think this is not an uncommon intuition [1432](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1432.08s)

people will kind of come to things like uh greed and um things about music motivating patterns of human behavior seeming like the obvious places to start uh the kind of real politic assessment [1453](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1453.44s)

that um humans are uh too irrational to make the good choices and or too rivalrous to make the good choices and that we're in problems kind of as a result of us being very good at making very powerful tech and not very good at uh long range and more inclusive considerations i think these are like i said somewhat common intuitions what i [1476](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1476.72s)

what i hope to do is to deepen some of these and clarify them in ways that might actually start to highlight uh what adequate solutions that are actually inactible could look like in terms of a high-tech [1500](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1500.48s)

civilization that are actually responsible stewards of the power of that tech all right so as we dive into assessing where civilization currently is uh i want to talk about the actual [[catastrophic risk|catastrophic risks]] that we face give some examples of them uh and some timelines and [1526](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1526.84s)

um what is actually novel about this historically and what the support tends for the future and if we want a different feature than the path we're currently on what it might take to do that um i want to give a preface first that when we try to do any kind of like long arc of history um big picture orienting frameworks uh we have to be careful with it there are it it's easy to make those over simplifying and then become a source of um kind of [[confirmation bias]] so there are there are a couple types of uh historical narrative that often occur here that i think are both uh problematic one is kind of the hobzyan dialectic of progress perspective that um pre-agricultural early people were [1589](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1589.48s)

had lives that were brutish mean short and nasty and it's been kind of a upward ascent from the mud since then and that technology science and capitalism have been the candle in the darkness illuminating and making everything better and that we simply need to keep doing more of those and it will continue to get better and better and there's certainly plenty of popular books and popular thinkers that explicate this narrative and there's certainly truth to it nobody wants to go to dentistry and a time before novocaine on and on that perspective generally leaves out the rat the unbelievable amount of [[species extinction]] and environmental harm and increased movement towards uh [[catastrophic risk]] writ large uh leaves out ubiquitous mental health issues that were probably not evolutionarily prevalent in the same way and you know a lot lots of other things like that and has a cartoonishly negative view of past people and also a homogenizingly cartoonishly negative view the other one is the view that kind of over romanticizes the living in perfect harmony and balance with nature indigenous people and that it's been kind of a fall from the garden or fall from redemption type model and that we have to get back to that early wisdom and um i don't think that the way that people lived hundreds of thousands of years ago gives in relative with relatively much lower [1705](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1705.12s)

tech much lower populations much smaller population sizes has adequate solutions for what we do with a population of this size and global [[supply chain|supply chains]] and exponential technologies that doesn't mean it has nothing to share i think there is actually a lot that can be shared but we're not going to find adequate solutions there [1723](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1723.6s)

i think first it's just valuable to see that if you look around the planet today and take samplings of people from very different parts of the world or different subcultures they're really different right and uh similarly if you go back into the past before the plow the idea that they were all kind of brutish nasty and mean [1741](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1741.919s)

or all kind of enlightened is pretty silly there's probably a pretty wide distribution of the values and the sustainability and the enlightenment if you would call it of the people and we see that early civilizations rose to certain kinds of heights and then [1762](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1762.159s)

collapsed and so we also see that there was neither a kind of continuous descent nor continuous ascent or something that had cycles in it where how much knowledge was lost in the burning of alexandria how much was lost in the fall of sumeria or other places when we see things like the anti-catheria mechanism which is like a metal geared [1782](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1782.24s)

clock that is thousands of years old that was not supposed to be the case or like oh the the historical narrative of just kind of um progress not probably not very true um so it's important whenever we try to do [1799](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1799.2s)

these kind of sweeping assessments that we understand that at any given time there was a pretty wide distribution of the different types of civilizations and through time there would be fluctuations within those all that said uh i think some patterns that we can see pretty clearly is that from all of recorded history that we have any good evidence for the total level of technology that we have possessed since the [[industrial revolution]] and progressively throughout that time in particular since [1838](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1838.159s)

the digital revolution is historically unprecedented the total population size and the interconnectivity of that globally through global [[supply chain|supply chains]] is also totally unprecedented i think that's that's pretty straightforward that's not that hard to argue [1856](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1856.559s)

so i want to talk about the state of [[catastrophic risk]] facing the world today and kind of a historical perspective on that it's fair to say that human induced [[existential risk]] because we always face the possibility of a meteor or a solar flare or something outside of you know like some kind of [1881](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1881.12s)

natural phenomena that could wipe us out but that's different than us doing something that wipes ourselves out right so human-induced [[catastrophic risk]] can be said to have started in world war ii with the nuclear bomb that before that we just didn't have enough technological power to destroy that much that quickly even if [1902](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1902.88s)

we wanted to that as effective as he was genghis khan still couldn't make the planet not habitable and so one important insight when we think about [[catastrophic risk]] is human-induced [[catastrophic risk]] is it is inexorably tied to the level of [1922](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1922.72s)

technological development because the technology is the amongst other things is a lever for how much power our choices have it also ends up influencing the type of choices we make which is an important point we'll get to later but to just start with for now it obviously impacts the scope of our choices and people with stone tools just can't destroy the biosphere and just can't create a world war that destroys everybody people with bronze tools or iron tools also can't people with nukes can and so the nuclear bomb was the first time and you know people recognized this at the time is like [1961](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1961.44s)

um when you see a mushroom cloud and you then hear the stories of zeus's lightning bolt or whatever the mushroom cloud was a bigger destructive force than most of the kind of mythos of what the power of gods in different cultures had been so it's like oh [1980](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1980.96s)

we have something like the power of god so we can split atoms and destroy things at an unbelievable scale and then we can go into something like mutual assure destruction and do that at a global scale do we have something like the wisdom of gods and the love and the prudence to be able to steward and guide the [1998](https://www.youtube.com/watch?v=8XCXvzQdcug&t=1998.64s)

power of it adequately that's one of the kind of deep orienting questions and frameworks uh that i come back to and so it's fair to say that the bomb was the beginning of the level of technology where human-induced [[catastrophic risk]] was actually a thing it's important to say that before that [2021](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2021.44s)

[[catastrophic risk]] at the level of individual civilizations was a real thing and not only was it a real thing it was it pretty much happened to every civilization if you uh read books like the uh collapse of complex societies by tainter that are doing analyses of the fall of previous empires one of the [2042](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2042.24s)

things in and you just kind of think of the history of it one of the things that most empires have in common is that they don't still exist that they either went through gradual decline or um not gradual quick failures which can happen sometimes they happen militarily sometimes they happen through their own [2060](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2060.0s)

environmental and sustainability topsoil depletion using up all the trees things like that so i think it's an important point that if people are not thinking about this generally they might not be in the front of their awareness that human civilizations have had lifespans and they've ended and they [2080](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2080.48s)

have largely ended from self-induced causes that either they were they would grow in a way that was unsustainable to the environment and collapse for those reasons or they would uh engage in resource conflicts to be able to have continuous growth that engendered more enmity with others that [2100](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2100.8s)

eventually led to their war many of them fell from rivals that were less capable than previous rivals that they had defended against because they went through a internal erosion they became so powerful that then they started infighting and having you know things [2119](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2119.2s)

like polarization and lack of coordination where then even smaller rivals could fight them so there was something like institutional or civilizational decay that occurred as a result of their success oftentimes so it's important to get that the early civilizations went extinct and they went extinct [2137](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2137.04s)

largely for self-induced causes that a enduring human civilization is a thing that we don't have a model for so far that what is novel now is that we have a truly global civilization for the first time that as big as the aztec or inca or egyptian empires or even all the way up to something like the roman empire it was not truly a [2160](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2160.48s)

fully global system but given that the computer or tv that you're probably watching this on required six continent [[supply chain|supply chains]] to be able to build meaning that the the fundamental technologies that mediate the way that we live today require globalized [[supply chain|supply chains]] that no countries can make the technology by themselves that they need we really do it is fair to say we don't have a chinese civilization and a u.s civilization since they are not autonomous right we really do have a global civilization that i would say is also in the process of self-induced collapse and [2200](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2200.96s)

that but the scope of that collapse rather than just kind of local environmental destruction something like destruction of the habitability of the biosphere at large or rather than a local war something like you know totalizing war is really unprecedented um music but of course those those civilizations did face the experience of [[existential threat]] to themselves um so it is important to understand we're not talking about like some unprecedented kind of uh excessively negative thing we're talking about something that has happened a [2241](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2241.839s)

bunch of times just never in a fully global context so then we get to world war ii and we say okay so the bomb gave us the ability to uh have global scale [[catastrophic risk]] for the first time and because of that it we had to not do that it became very clear we had to [2259](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2259.52s)

actually for the first time in human history we had a technology so powerfully destructive that we had to ensure we never used it and before that every time we had a technology there was a race to deploy it as quickly as possible for everybody to be able to use it for advantage this is the first time we had a technology that [2275](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2275.359s)

rather than race to use it we had to ensure that nobody ever used it now of course there was still a race to maximize the total amount of stockpile and things like that and so an entire [[world system]] was created after world war ii to prevent the use of the bomb again and i would say that that post-world war ii [2292](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2292.16s)

system was successful at preventing nuclear exchange in world war iii of that kind kinetic world war three up till now i would say that it also advanced it was responsible as a solution to a problem that was too narrowly defined that caused other problems that [[world system]] was also responsible for advancing many of the [[catastrophic risk|catastrophic risks]] we now face and that that whole [[world system]] is ending and i'll speak to the structures of this briefly so the the [[world system]] we created after world war ii was one mutually sure destruction how do we make sure that these two superpowers are not going to fire the weapon let's make sure that uh [2331](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2331.359s)

nobody feels like they nobody believes they could win it that it would be lose lose for everybody so that nobody in does that thing that was one part of the solution another part was the new global monetary system the [[bretton woods]] monetary system and the um kind of reserve currency system and like that that allowed for [2352](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2352.24s)

[[exponential growth]] of the uh global economy and the idea there being that um resources economics were one of the main drivers of war historically because everybody wanted more stuff and that if there isn't a larger pie than to get more stuff you have to take each other's stuff which causes war so that the way to prevent [2374](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2374.4s)

war is a continuously growing pie so everybody can have more stuff without taking each other's stuff of course where does that stuff comes from that meant unrenewable depletion and pollution of the environment which brings us to all the [[planetary boundary|planetary boundaries]] that we're you know about to hit so [[exponential growth]] of the monetary system year-over-year [[exponential growth]] means uh exponential uh unrenewable depletion of resources and exponential pollution both of which have happened you don't get to do that forever on a finite planet so running an exponential financial system on a linear [[materials economy]] that is taking unrenewable resources and turning it into unprocessable waste brings us to all these different planetary tipping points and we can see depletion of topsoil and trace minerals depletion of trees depletion of fish you know depletion of species depletion of pollinators on this side and we can see them the accumulation of co2 and [2432](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2432.319s)

mining waste and you know microplastics in the ocean and so many other things here uh but we can see that all those environmental problems are the side effects the second order unintended consequences of the solution to the how do we not have nuclear war issue which is how do we grow the economy um another major aspect of the post-world war ii solution was globalization and having these radically interconnected global [[supply chain|supply chains]] so that since we depended upon each other to make stuff we had lessons sent up to bomb each other because we'd be bombing our own [[supply chain|supply chains]] and so that global interdependence um there's a lot of people in the [2470](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2470.24s)

environmental movement focused on wanting you know local production move everything back to kind of local the movement to globalization was actually really important which was it made us invested in each other's success rather than bombing each other but it also produced a world where [2491](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2491.44s)

collapses of of [[supply chain|supply chains]] anywhere can start to lead to kind of cascading catastrophic shocks everywhere and we saw that really clearly with cobit we saw that a problem in one part of the world in muhan started to have cascading issues not just the movement of the virus but to be able to stop the movement of the [2514](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2514.319s)

virus stopping travel which also meant shutting down [[supply chain|supply chains]] which meant that fertilizers and pesticides didn't get where they needed to which meant uh you know devastated crops from locusts in northern africa and parts of the middle east and crop failure in india and which created uh more food shortage of for hundreds of millions of people and you know risks there than probably um the total risk for attended by covet itself um we got to start to see how a world this interconnected [[supply chain]] wise can have local issues really lead to global [2552](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2552.319s)

catastrophic issues so these were some of the main aspects of the post-world war ii solution and i would say that while they served a purpose they brought us to the point that now we have reached [[planetary boundary|planetary boundaries]] across lots of different axes where both the unrenewability [2572](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2572.88s)

or running out of unrenewable resource and running into the un unsustainability of the pollution issue means we cannot continue to exponentially grow the gdp on a linear [[materials economy]] what do we do instead that doesn't then also cause war from shrinking gdp and having people continue to want more stuff like this is where we [2595](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2595.52s)

have to hold the various tensions together and not say then okay now the problem is the environmental one so let's go ahead and try to solve that by lowering use in gdp which by itself is a very nearly impossible thing to do because if you don't get everyone to agree to it whoever voluntarily does it geopolitically disadvantages themselves so much that nobody's gonna do it [2613](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2613.839s)

but um also if then anyone is or you know if anyone is uh oriented towards continuing to grow their population resource et cetera then and in a shrinking pie situation then war increases so we have to think about the environmental issues the economic issues the geopolitical issues all [2633](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2633.92s)

together to be able to have solutions to any of them the next part of the kind of post-world war ii system that is no longer viable is the idea of mutually sure destruction on music technology that we shouldn't use measure destruction is a way of kind of forcing an equilibrium forcing a nash equilibrium which when you have one [[catastrophe weapon]] and you have two players that have it and it's one that is easy to monitor because there are not that many uranium mines and enriching uranium takes huge cyclotrons that you can see from space and whatever you can do mutual destruction in that way when you start to get to a world [2677](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2677.04s)

where um because of ai weapons and [[bioweapon|bioweapons]] and cyber weapons on infrastructure and like that you have many different types of [[catastrophe weapon|catastrophe weapons]] and many different players that have them not all of whom are [[nation state|nation states]] you cannot put a f [2695](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2695.839s)

a mutation or destruction or force nash equilibrium on that in the same way so we have advanced to a world where more states have new [[nuclear weapon|nuclear weapons]] more other states have that don't have [[nuclear weapon|nuclear weapons]] have the ability to do disinformation attacks and things that could lead to nuclear escalation between the countries that do have them [2721](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2721.28s)

and the other kinds of catastrophic weapons [[nuclear weapon|nuclear weapons]] are very hard to build right the the actual hardware involved is very hard to build this is not true with ai swarm intelligence empowered drone weapons that can take out massive infrastructure targets that can be built [2741](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2741.92s)

by small groups of people this is not true with bio weapons that particularly with gene drives and tabletop crispr and these technologies advancing right now many areas of biotech synthetic bio and genetic engineering are advancing faster than moore's law which you know we hear all these things in the kind of positive silicon valley world about the democratization of [2768](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2768.079s)

technological power is a good thing the democratization of catastrophic power not necessarily a good thing right like the the idea that um power that can be used intentionally or accidentally right say someone's not building biotechnology intentionally as [[bioweapon|bioweapons]] but [[biosecurity]] is a hard thing technology that can be catastrophic being radically decentralized that is not monitorable and where you have a very hard time being able to enforce agreements uh creates radical fragility in the world so um small actors [2811](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2811.2s)

not nation-state actors with no special exotic materials in the next few years as these various categories of [[artificial intelligence]] and cyber capacities and drone capacities and biotech capacities get cheaper and cheaper more and more [2831](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2831.44s)

powerful um music how does the world make it through decentralized catastrophic capability right [[catastrophe weapon|catastrophe weapons]] for anybody who wants them capability and it's important to get even that [2848](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2848.72s)

again nukes are really hard to build so you have to keep the knowledge of nukes secret but even if the knowledge was out they're hard to build when we're talking about something like [[artificial intelligence]] or cyber technologies where you don't really have to build any hardware and the software is not that hard to build and you can build it on [2866](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2866.64s)

cloud computing infrastructures that are kind of equally that are easily open and available to everybody music then even scientific publishing portends [[catastrophic risk]] because let's say uh a major research institution is [2889](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2889.2s)

advancing knowledge of how to do uh swarming drones or whatever it is um a breakthrough in a model for ai they have ethical review boards for the purposes that they're doing it for but they figure out a capacity they publish it whoever now just reads that doesn't have an ethical review board on what they do with it and so [2913](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2913.359s)

we can it we can advance a technology for a positive purpose and have it unintentionally cause harms in other ways just through the result of using it for that positive purpose we can also advance the technology for a positive purpose and the underlying knowledge gets repurposed for all other kinds of purposes and so i would say that we are in a situation again that is so radically unprecedented not just in the world before world war ii but in the whole world since world war ii until really just now and over the next handful of years where even open access to [2950](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2950.559s)

knowledge and information in the fields of advancing technology poor tends [[catastrophic risk]] potential that is unmonitorable and so we we have to take that seriously and say what we would do about that um music so for these reasons that you can't do [[mutually assured destruction]] in the current landscape you can't keep an [[exponential growth]] economy with linear [[supply chain|supply chains]] that we don't have one [[catastrophic risk]] we have many that are in tensions with each other where the things that you do to decrease the likelihood of war might increase environmental risk the things [2992](https://www.youtube.com/watch?v=8XCXvzQdcug&t=2992.48s)

that you do to benefit a particular environmental risk might increase the likelihood of war i would say the post-world war ii world as a you know the pax americana world is fundamentally over is inadequate to the landscape of the problems we face the problems we face are historically novel are near-term catastrophic not on one axis but many many different axes and are without adequate solutions currently and so that's kind of a an introductory frame for what i would call the [[metacrisis]] the current state of affairs that we have to understand clearly to be [3041](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3041.04s)

able to take responsibility to address because obviously we want to address this so i want to give just a little bit more detail of what the relatively near term what a few of the relatively near-term catastrophes could look like [3065](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3065.44s)

across a few different sectors to have a sense of what we have to address right these create boundary conditions or kind of forcing functions for things that we need to address this will be by no means comprehensive in terms of the risk landscape and there's a lot of good work that has been [3087](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3087.359s)

published on this a lot of places if people are not familiar with nick bostrom's work and places like the future of humanity institute i would say check it out reading his vulnerable worlds hypothesis papers a good start music so [[climate change]] there's obviously pretty radical debate on um how [3110](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3110.88s)

much temperature change how much sea level rise how quickly how much extreme weather events are attributable um but i think that there are increasing extreme weather events is clear that uh extreme droughts and heat waves have been increasing over the last few years and everything indicates that they will continue to increase and that we don't need to get to the place of like runaway venusification of the planet to start to look at [[climate change]] leading to [[catastrophic risk]] if we look at right now as we're heading into the summer the heat waves that are happening in india and if we look at the last couple summers where they've been like almost 50 celsius heat waves in a in some areas of high population high population density that co-occur [3174](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3174.4s)

with running out of groundwater and not having access to air conditioning and other things would be necessary when we look at shocks to [[food supply]] storage that happened during covid and heat waves it could get hot enough to destroy crops and the amount of people then in food [3195](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3195.44s)

insecurity do we see a situation where the next few summers could have heat waves that displace large numbers of people much larger than we have dealt with anytime recently tens of millions or more people becoming [[climate change]] refugees this is really not unlikely [3218](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3218.96s)

and when we look at what's happened after the previous refugee crisis um syria and other ones there's no place that is really interested in taking tens of millions of refugees and people don't just die peacefully in those situations so let's say we look at a situation like [3240](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3240.64s)

northern india that has both huge population density huge population a lot of resource and security and a place where the heat waves can hit under resource shortage do you get resource wars do those resource wars possibly cleave along politically tense lines that already exist maybe muslim hindu lines or things like that can those escalate to things like india pakistan wars which are both nuclear-equipped countries this is an example and there are many other ones that's just one example of the way that uh [[climate change]] can lead to resource shortages it can lead to human migration that can lead to wars that [3283](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3283.68s)

could lead to escalation on existing geopolitical tension lines that hit technological amplifiers like places that have nukes or kind of weapons of mass destruction and so you see this kind of cascade effect where before [[climate change]] is a [[catastrophic risk]] by itself just through environmental phenomena it can be the beginning of a cascade [3303](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3303.44s)

music i think there are quite a few things like that in the next single digit number of years that have a much higher probability that are under mitigated so that's one set of things to look at um and i think that since covid and since the radical kind of polarization in the u.s between the left and right that has expressed itself through the kind of january 6 activity at the capitol the um music the huge polarization around trump and [[social media]] the um george floyd uh triggered social justice issues in the u.s as well as you know a pretty decent percentage of [3364](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3364.88s)

the continent of australia catching on fire and then barely even staying in the news because follow the things and then of course the war with ukraine and tensions over taiwan i think there is a sense of um the instability of the world situation that is much more widespread than it was five years ago [3384](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3384.799s)

um and not just the instability but the complexity of it and the fact that there is not one [[catastrophic risk]] there's a lot of things happening kind of simultaneously and that's trying that the probability of each of those plus the total number of scenarios and the number of escalation pathways is increasing each year rather than decreasing [3402](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3402.96s)

so if we just kept trying to deal with what are the three nearest [[catastrophic risk|catastrophic risks]] and how do we mitigate those we buy very little time so thinking about okay how what do we have to do to change like i said all of these are the result of tech and this is either the result of the cumulative results of industrial [3424](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3424.24s)

tech so all the environmental issues the [[planetary boundary]] issues of which [[climate change]] is one are pretty much industrial tech multiplied by globalization having cumulative effects over some hundreds of years and now reaching tipping points and then nuclear and other advanced military tech adds to that and then [[exponential tech]] adds to that right so the [[catastrophic risk]] landscape is kind of cumulative industrial plus particularly exponential the categories of [[exponential tech]] and what we mean by exponential i'll try to [3462](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3462.88s)

there's a few different ways we could define it we could say any technology that improves itself recursively nukes don't make better nukes but computers do make better computers i can use computers to model how to make better computer chips so you get moore's law type dynamics [3482](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3482.24s)

so technology that recursively has the capacity for supporting its own self-improvement creates an [[exponential curve]] technologies that allow exponentially larger impact per dollar or number of people or unit time so we see facebook and google getting to three billion users [3502](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3502.16s)

in like a decade compared to uh the scaling at which u.s standard oil or whatever got to nowhere near that many people over a much longer period of time we can see that a much smaller number of people can have a much larger impact much faster so exponential speed of effect exponential scale of effect which also means more players able to have a bad level of effect when we look at the myriad of environmental issues that we face that we said are a result of the cumulative effects of industrial tech with increasing population and increasing gdp demands it's illustrative to be able to have that kind of overarching framework to [3558](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3558.72s)

look at it as opposed to just individual areas because if we look at say [[climate change]] as one environmental risk that uh is largely a result of excessive co2 from the burning of carbon-based things mostly fossil fuels obviously there are methane and [3581](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3581.92s)

agriculture and other things but let's just take take the carbon part so as far as the [[supply chain]] goes that's kind of the waste or the output side of using hydrocarbons as fuel the other side is that we're getting diminishing returns on hydrocarbons that we have a [3603](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3603.52s)

society that depends upon hydrocarbons as the energy source and while we're figuring out creative ways like tar sands and shale and fracking and offshore drilling to find the rest of them we're having to go to harder more difficult areas because we've already got most of the [3624](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3624.559s)

easy ones and it takes a certain amount of oil to get more oil so the energy return on energy investment how much oil it takes to get a new barrel of oil is increasing when you look at the fact that the total amount of gdp is very closely coupled with the total amount of energy use globally and the gdp has to go up exponentially [3647](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3647.119s)

just to keep up with interest that means that there is a exponential demand for the total amount of energy used but we're getting a diminishing return on hydrocarbons and the new non-hydrocarbon sources of energy have required more hydrocarbons to make and they have a certain energy return on [3669](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3669.119s)

energy investment of how long it takes you know for them to pay off the there's a there's a massive kind of gap um and uh and reckoning on that side so obviously you have all of the like you said mountaintop removal mining for coals and the environmental harm of that and oil [3686](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3686.88s)

spills and geopolitical destabilization over oil on the side of getting it as well as the underlying deep issues between the inner global energy system and the global finance system that is also just the other side of the [[supply chain]] of [[climate change]] so you can see [[climate change]] when you look at the entirety of the energy system [3707](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3707.04s)

you're like wow there's some other really really critical and timely issues that are just part of looking at the movement of hydrocarbons to the system let alone everything else so um if you want to think about all of the environmental issues from the point of view of nature having mostly closed-loop processes that anything any type of waste in nature is just food for something else in a time scale that uh doesn't lead to either waste accumulation or depletion of a needed resource every dead thing and every type of byproduct feces or whatever is fully metabolized by everything else [3755](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3755.359s)

ecosystem that that is not the same for human technology and relationship with the ecosystem that we utilize materials that much faster than the earth can regenerate them or we can regenerate them through other sources and turn them into wastes much faster than nature can turn them back into anything else and we have real environmental harms from both [3773](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3773.039s)

of those so the idea of a linear [[materials economy]] that is undergoing [[exponential growth]] on a finite planet that thing has to shift so we both have to deal with the [[embedded growth obligation]] and finance for [[exponential growth]] and we have to deal with the closed loop on our [[materials economy]] so that we are making all of our new stuff from old [3791](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3791.44s)

stuff and all of our old stuff is not waste or pollution but it's getting you know cycled back in to make new stuff and that we're doing that with the energy bandwidth actually available to us that's an easy thing to say what it actually takes to do that factoring global coordination and the incentives [3809](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3809.839s)

not to do it and the fact that so many of the actual real costs are externalized and that when you internalize them almost no industry would actually be profitable and markets wouldn't be viable there's some deep there's some deep issues there but that's um yeah a framework for looking at the what has to happen underneath changing [3829](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3829.839s)

the environmental issues kind of very large music when we think about the [[exponential tech]] mediated issues one framework for thinking about that is that there is a [[perverse incentive]] a kind of um [[perverse incentive]] if people are not already familiar with the concept is another concept that you can see pretty quickly underlying most of the problems in the world not just the [[catastrophic risk|catastrophic risks]] just the suck that we have dealt with in lots of industries [[perverse incentive]] means where any individual or corporation or [[nation state]] or agent actor of any kind has some type of incentive that is misaligned with the well-being of other actors or the comments and so they are incented to do something that is directly causing harm or externalizing harm somewhere else it's pretty easy to see that a for-profit military-industrial complex that would go out of business if there [3885](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3885.68s)

was no war or there were adequate solutions to peace or for-profit health care structure the way it is or whatever we can see like [[perverse incentive|perverse incentives]] are not a hard thing to see so that would be an example of something that is kind of [3901](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3901.28s)

underneath and driving at the level of the nature of economic structure and how we regulate that and to really find adequate solutions i think actually requires changes at the level of how we create currency issues regarding the fungibility of currency and property ownership private property deep deep topics music but if we um if we were to think about what are some underlying drivers of the things that have been problems for forever but at this level of technological capacity and nearing planetary tipping points where those problems actually become catastrophes [[perverse incentive]] would be one of those drivers which then also means that it creates a basis for an orienting question which is the orienting question would be for humanity to think about how do we identify and close [[perverse incentive]] gaps procedurally everywhere there's not a perfect answer to that because whatever answer you have then there will be a way to gain that [3960](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3960.16s)

answer but the ability to or the orientation to progressively seek better and better answers and implement them towards that um i think is deeper than trying to solve [[climate change]] or trying to do healthcare reform or any other particular topic like that similarly the question [3980](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3980.319s)

how do we identify externalities and internalize them like force them into the cost equation and into the responsibility equation there is no perfect answer to that but seeking better and better ways to be able to do that having more [[collective intelligence]] focused on that is upstream from any particular problem we [3998](https://www.youtube.com/watch?v=8XCXvzQdcug&t=3998.48s)

can identify so there's a particular kind of [[perverse incentive]] um associated with the development of new technologies in particular which is that there is much more incentive to focus on opportunities than of a new technology than risks of a new technology so and a new technology will obviously have both right the technology is um it's only going to proliferate if it does provide some advantage um so of course there's going to be opportunity that's associated uh but because it's going to interact with a complex world there's going to be risks that are associated with it if i focus if i don't want to advance a technology that might harm the world meaningfully so i am going to do really deep risk assessment i'm going to think through what are all of the ways that this could cause risk both through its direct [4059](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4059.52s)

physical externalities as well as the ways it changes social dynamics because whoever uses it gets more power in some ways so what types of people will be how will it change the power landscape and how it will change the nature of psyches and things like that if i really try to do good thoughtful assessment of where the second third fourth order risks [4077](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4077.76s)

associated are and either not build the technology if they are too bad and i can't mitigate them or figure out how to design the technology differently to mitigate those or make sure that the technology also launches with particular regulation in place or whatever then i'm probably not going to be the first to market i might not get to [4096](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4096.64s)

market at all i might just decide not to do the thing if on the other hand i just focus on the positive application and probably whatever the nearest term most profitable positive application is and i either don't do risk assessment at all or i do a pro forma version that is mostly about box checking to say that i did risk assessment while really [4114](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4114.88s)

not wanting anything that slows the movement uh then i'll probably get first mover advantage i'll probably get the ability to scale and especially in [[network dynamics]] be the one who gets to benefit from metcalfe's law and kind of network monopolies and as a result there is a kind of [[race to the bottom]] of anyone who would want who's aware that there are risks either doesn't matter because they won't end up getting the power or they end up having to say well i can't focus on those now otherwise i won't be a player and i won't be able to do anything so i have to i have to pretend that the risks are [4152](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4152.88s)

going to be solvable later and still rush to get ahead so at least then i have the the capital in the market position to hopefully be able to implement solutions later which of course is pretty much impossible because then there will be a fiduciary responsibility to continue to [4169](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4169.839s)

maximize shareholder advantage there will be inertia already in place and things like that this is a really tricky issue right it's a really tricky issue because uh the incentive to move fast and break things externalize and socialize the losses but privatize the gains [4193](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4193.52s)

and that even if i feel like i want to be an ethical actor i still want to be able to do stuff and so i want to gain as much power as i can and if i don't do the thing it still doesn't prevent the thing because other people are going to do it anyways how we make it through gaining exponential influence capacities across domains as [4214](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4214.08s)

fundamental as the genome and the base code of life and the you know [[artificial intelligence]] getting increasingly generalized and things like that like this is a very deep fundamental thing to deal with and so i there's a great video i'll see if we can [4234](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4234.719s)

link it in the comments to this that somebody put out on leaded gasoline and the development of the lead additive that made a motor stop knocking and the actual health risks that were known even to the scientists at the time that they [4256](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4256.32s)

lied about and head that led to leaded gasoline proliferating globally that led to huge amounts of lead toxicity in the biosphere not just affecting human life but also human life and that a little bit of the effects known of that was that the lead decreases human iq significantly and the collective effect of that across the whole population is [4276](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4276.48s)

something like billions of points of iq loss globally and that it makes people more violent i think it was something like a forex increase in violence being exposed to it again across the entire populations like global populations we come back to think about how a lot of people like to write off [4295](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4295.84s)

that we can't make a better civilization because humans are too dumb and too nasty and we see just lead makes us dumber and nastier and we're like well how dumb and nasty are we is not a unchangeable metric it's actually changeable by a lot of things are there some cultures that have developed a much higher level of base education across their whole culture yes [4315](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4315.6s)

you know like jews have done a better job of education than a lot of other cultures have are there some that have done a better job at non-violence yes jains and buddhists and quakers are pretty nonviolent across large populations some populations are radically violent across the whole population so there's and that's not even getting into things like lead so now you think about you think about this one atom for the purpose of stopping engine knocking they got through where by the time we saw all the harm associated and regulated it out we had already lost billions of iq points [4351](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4351.6s)

you don't get rid of the lead in the environment anytime quickly right that's going to take for forever and so the fact of regulation happening after the fact because the market moved the thing forward it hid what it knew about the problems and or was never incentivized to figure it out to begin with it lobbied in its own interest and so only once the problem was so gruesome [4371](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4371.92s)

that it had so much support could regulation happen after the fact we see that with ddt we see that with cigarettes we see that with you know so many things do we get to do that with [[exponential tech]] where by the time the problem is so gruesome we regulate it nope like whether we're talking about ai or biotech it is too late at that point the consequences are too significant too fast-moving and too self-catalytic so this portends a radically different approach to the relationship between the market technology and regulation and you know whatever culture ends up in forming [4412](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4412.56s)

regulation we have the idea of a [[liberal democracy]] where the the law the right the basis of regulation is to be the result of the collective values of the people through democratic process so the the culture uh is supposed to be advancing human education and development and informedness so that people have progressively more developed [[value system|value systems]] that then they vote to have coded into law where then the monopoly of violence that the state has can regulate the market where the market would have reverse incentives [4450](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4450.8s)

so with biotech risk there's a lot of different things we're talking about we're talking about things associated with synthetic biology which is uh advancing faster than moore's law and things associated with crispr and different kind of gene editing technologies both as a result of things that could be used for positive applications like [4471](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4471.76s)

agriculture or waste management or whatever but that could produce unintentional consequences as a result of putting you know genetically modified organisms designed to benefit one thing but that start to proliferate and that you can't kind of pull back afterwards it might have other effects we haven't studied well enough there's that kind of risk [4491](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4491.199s)

there is much more acutely the um there's the risk that we're developing things that we know aren't safe for release but they get out because containing tiny microorganisms is a really hard thing to do um and so uh just accidents are a very real thing and then obviously uh bio weapons and not just state actors that you can kind of deal with via deterrence but non-state actors where it's very hard to deal with them via deterrence because they might not care and or might because they're a suicide cult or whatever and or because they're not identifiable [4529](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4529.76s)

when we see increasing kind of suicide shooters where you know they can kill a lot more people than assault rifle than they could with a handgun or with a knife as we move from assault rifle to weaponized drones or biotechnology or whatever obviously how much harm a [4550](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4550.32s)

psychologically unwell person can cause as the decentralized weaponizable technology increases changes a lot so far there's been this fortunate thing that the people who are good at tech and who are good at strategy have mostly been gainfully employed and not in the place of want to burn everything down [4574](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4574.08s)

as we're moving to a place whether it's through things like uh radical polarization where both sides feel that elections are existential and they feel that there is some kind of grand force uh harming the world irreparably or whether it's through way more people being [4596](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4596.159s)

disenfranchised through things like uh climate refugees um music and through the effects of kind of the [[social media]] orientation as it is optimizing for engagement that is largely achieved through getting people more limbicly hijacked and tribal and um [4618](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4618.32s)

doubling down on [[confirmation bias]] the total number of people that feel existentially disenfranchised and are motivated to take some kind of action like that that intersects with the number of people that would have catastrophic capability those two circles are moving [4639](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4639.44s)

closer together so there's more in the venn diagram and the more people with catastrophic capability is also growing exponentially so that's a increase in the vulnerability of the world um i think i think in his conversation with sam harris robbery talks about one of the examples of concern [4664](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4664.08s)

being a project that is happening at the time of filming this to try to that actually a u.s government department is engaged in trying to get all of the bio labs that do gain a function research to [4684](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4684.159s)

publish all of the sequences to some kind of [[open source]] database so that the knowledge is more available for preemptive vaccine creation so that if some future pandemic occurs we'll already have vaccines in place totally understandable to want to do something like that to want to take the collective knowledge that humanity knows and and centralize it so that um [4702](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4702.4s)

so that we can coordinate on solutions like it seems like a good idea though of course that also means making more centrally accessible and maybe even [[open source]] access to all of the catastrophic [[bioweapon|bioweapons]] capability for anyone who would use it for [[bioweapon|bioweapons]] purposes and in a world where the technology [4724](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4724.56s)

needed to build that is getting increasingly easy that's just an unbelievable risk so this is again an example of the way we try to solve a problem can make way worse problems and so one of the things you want to think about is what are the possible negative externalities of our solution [4744](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4744.239s)

whatever our solution is one what are the what are the upstream causes of the problem we're trying to solve and have we address those upstream causes if not what do those upstream causes do when this isn't their outlet and what are the possible negative externalities of the success of our solution we have to get so much better [4763](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4763.52s)

at those models of thinking with regard to ai we can see that the ai curation algorithms that run [[social media]] and search engines and infotech input technologies generally are already having a civilization altering [4787](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4787.12s)

culture altering effect that is particularly heightened in democratic societies you know this this is the work of tristan harris and people like this got plenty of stuff on the internet for people to check out if you haven't seen social dilemma but briefly that the ability to take kind of all of the [4807](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4807.12s)

information to say say we're talking about facebook you've got billions of people incentivized to upload stuff incentivize by getting likes and you know whatever and that's to create their own content or curate existing content and so you've got billions of people creating content [4830](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4830.239s)

billions of people uploading content and then billions of people engaging with that content and where what is going to show up in my news feed is what is optimized to make me spend the most time on site and engage with the feed the most empirically as it exposes me to different stuff in the news feed and it empirically measures what i would engage [4851](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4851.28s)

with the most and it happens to be that uh consciously i probably did not plan to spend an hour on facebook today as i was planning my day i probably wanted to check it briefly and go to other stuff so if i stay kind of an executive function i'll probably get off facebook if i get [4869](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4869.36s)

limbicly hijacked through um you know a bunch of [[hypernormal stimuli]] airbrushed pictures and whatever and things that outrage me i'll probably spend more time on site if i get confronted with views that are complex and make me think i'll probably bounce if i get things that kind of appeal to what i already think and enrage me i'll probably do it the [4889](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4889.52s)

clickbaity titles get clicked on more so without trying to there is this kind of comprehensive appeal to the lowest angels of our nature that occurs through an ai right it is a advanced [[artificial intelligence]] that is doing curation algorithms it is making almost everyone more certain more sanctimonious more [4911](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4911.76s)

righteous more tribal uh less open-minded more villainizing across all the views it's not left aligned or right aligned or whatever it's engagement aligned for everybody that's already an example of [[catastrophic risk]] happening globally then an increasingly polarized population elects an increasingly polarized representative class the [4933](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4933.679s)

increasingly polarized representative class in a democratic system means more gridlock and inability to do anything which means inability to regulate [[exponential tech]] or solve climate crisis or environmental crisis or engage in the great game of geopolitics with china that doesn't have the same issue and so we can see like real true [[catastrophic risk|catastrophic risks]] at the level of the environment and geopolitics as a result of the ai that is already employed in what seems like benign entertainment you know channels or whatever and that's extremely low and that wasn't intentional right like [4972](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4972.48s)

it was not designed to destroy democracy it was designed to you know do the very basic functions of design do those are second order effects as we look at things like gpt3 t3 that is already able to generate novel text that passes the turing test that people read and think it was a human that wrote [4993](https://www.youtube.com/watch?v=8XCXvzQdcug&t=4993.6s)

because it's good enough and can already generate novel text of specific types like in the voice of a particular person on a particular topic by in in taking all the writing of that kind and again though the rate of growth of generative ai of this type is faster than moore's law right now which both means how powerful it is and how widely available it's becoming so a lot of people have started to think about the kind of deep fake apocalypse of when content can be generated not just now curating existing content but generating bespoke content that can [5034](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5034.88s)

be used personalized info about people or groups to put forth content that would be maximally appealing to them that can utilize statistics and images and whatever but that are all created how does anyone make sense of anything in a world where i can have more fake information than real information can't tell the difference and the fake [5057](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5057.52s)

information is more compelling now you start to imagine you have the curation algorithms and the creation algorithms working together to be able to both show me the best of what has been created by humans and and then creating specific content and creating those together so you can see like a breakdown in public [[sensemaking]] tribalization polarization those types of issues associated with ai and that's again that's like happening through market dynamics already almost past tipping points this isn't getting into things like autonomous weapons but as you start you can also of course look at we are in a kind of global [[arms race]] on lots of different new technologies every new technology makes a weapon and nobody wants to uh not develop the weapon if somebody else is developing it so if anyone's going to develop it we need a race to get there first plus counter weapons so there are [[arms race|arms races]] on biotechnology and ai and so um autonomous weapons that you know can make autonomous decisions and have lethal capability creates a radically more vulnerable world for everybody and nobody would think that's a world i want to live in but nobody feels like they have the choice to prevent it because someone [5137](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5137.12s)

else is going to do it that's an obvious example but even like the swarming algorithms the kind of image recognition ai and swarming algorithms that can take a few commercial drones and make them swarm together is a type of ai that is took very very advanced development at places like mit to make but is now [5156](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5156.48s)

downloadable for free on github where any maker with some basic capabilities can do that and the total number of infrastructure targets that could really damage the world if hurt that are vulnerable is high so there are heaps more examples in general [5178](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5178.08s)

if you think about say alphago google's deepmind's technology they can beat the best human player at chess and the best human player at go and the best human player at starcraft in any definable game it's already not just a narrow intelligence right it's already a narrow intelligence [5197](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5197.84s)

across any sector that you want it to be that has radical supremacy over humans and the speed at which it develops the capacity to do that is is mind-boggling and so as you think about could a game be made of turning lots of [5221](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5221.04s)

metrics that you'd want to optimize for into games and figuring out how to win those in terms of applications in militaries and markets and public opinion and whatever uh that um that technology is in a it's not an [[arms race]] between [[nation state|nation states]] so that's also happening it's a market kind of [[arms race]] between companies competing for getting there first um but there is definitely an all-out race to advance the most powerful technologies of intelligence and obviously you have a artificial general intelligence case where it moves [5259](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5259.6s)

completely out of our control and maybe it's not possible for us to create alignment between its intent and ours and that's kind of the biggest risk but even the one where it stays within our control but it is radically leveraging human choice this is one of the things when we say we've got the power of gods without the love and wisdom of it history doesn't show humanity being particularly good stewards of its technological power in any meaningful definition of good the that we use increasing technological power to increasingly exploit the environment other classes other people it's pretty clear [5299](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5299.04s)

and uh what i would say is that we don't get to continue to utilize the power of technology in those types of ways as exponential technology comes online without [[self-terminating]] and so the type of mind that gives us the [5317](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5317.92s)

ability to make the tech is not the same type of mind that gives us the ability to regulate it and steward it wisely and that type of mind being able to catch up with and guide direct and bind the other is critical to humanity making it through its technological adolescence music okay all right so this brings us to the topic of [[multipolar trap|multipolar traps]] this is a underlying feature of what drives many of the major problems in the world both in terms of market issues environmental issues military issues many things like that and without being able to solve this underlying feature more fundamentally and categorically none of the specific areas find adequate solutions so i want to make sure we understand this if you want to read up more on it there's a exceptional paper online called meditations on molok on slate star codex that's probably the best overview on the topic i'm aware of [5384](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5384.719s)

so what do we mean by a [[multipolar trap]] we mean a multiplayer prisoner's dilemma or a situation in which you've got a number of different actors that could be different [[nation state|nation states]] different corporations different tribes whatever it is uh who [5405](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5405.12s)

can be in a competitive dynamic with each other where if any of them do a particular type of action that if everyone does that will kind of create the worst case for everyone long term but will create so much advantage for them in the near term that they will win enough power that everybody else loses if they don't also do the thing [5426](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5426.4s)

and so if anyone does the immediately advantageous though long-term harmful thing everybody else has to race to that thing so let me give some examples uh say there is a new type of technology that emerges that has the capacity to create a more powerful type [5445](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5445.52s)

of weapon and if anyone starts advancing the technology for weaponry in that way they will win the next war as a result everybody has to not only advance that weaponry but they have to try to race to advance it more powerfully than the other guy faster [5465](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5465.84s)

and also a whole suite of other weapons that are like counter weapons and defenses against that thing this of course increases the lethality of the entire world in the lethality of the next war for everybody but if we can't prove that the other guy isn't going to do it then we all have to race together as fast as we can [5485](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5485.04s)

and this obviously happened with [[nuclear weapon|nuclear weapons]] this is even when we were supposedly doing nuclear disarmament nobody wanted to give up their last nuke which is why nuclear disarmament is so hard nobody wants to give up their last nuke first because what if the other guys say they gave it [5502](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5502.88s)

up and they didn't really and they actually have a nuke and some secret deep underground military base and then it's game over for whoever authentically gave the thing up if we don't have the transparency to prove that the other guy really gave it up or hasn't done the thing then how can we ever create those agreements when there's so much consequence on the [5519](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5519.44s)

asymmetry of capacity in that agreement so even when we were supposedly in nuclear disarmament there was still an [[arms race]] happening to make faster and faster warheads the hypersonics because if someone had nukes that were way faster they could win first strike and so we see these types of [[arms race|arms races]] we see this right now in all the [5538](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5538.88s)

categories of exponential technology a new type of computation or computational capacity comes online it leads to new types of cyber weapons and there's both a race on the development of the cyber weapons and a race on the ability to create defenses and hardening against that the same is true with biotechnology as we mentioned earlier that there are [5558](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5558.4s)

real [[existential risk|existential risks]] associated with both um with many types of biotechnology from genetic engineering to synthetic bio and many of these are not from weaponized purposes they're from positively intended purposes that have externalities or positively intended purposes like gain of function that have accidental [5579](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5579.76s)

releases but obviously weaponization is one of the possibilities so again if they portend so much power if anyone might possibly be doing it then everyone has to race to do the thing and the counters to it and probably this is nowhere more pernicious than in the case of [[artificial intelligence]] and because [[artificial intelligence]] increases the ability to do every other kind of weapon and you can use [[artificial intelligence]] systems for developing biological and chemical and cyber and every other kind of purpose and there's this concept came from john boyd originally the concept of the ooda loop observe [5621](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5621.199s)

orient decide act the speed at which a particular actor in a military conflict can observe what's going on orient to it who's the bad guy who's a good guy what's the right thing to do make a decision act and then do it again based on the consequence of the action the speed and accuracy with which they can do that determines who wins in highly unpredictable scenarios [5639](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5639.679s)

obviously ais are going to win ooloops and so then you have ooda loops in kind of [[multipolar trap|multipolar traps]] with each other leading to the development of maximally capable ais and kind of [[multipolar trap|multipolar traps]] with each other um and you'd say well why not just [5659](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5659.52s)

make an international treaty that no one will build ai weapons that seems very straightforward the u.n could mediate it and we could all just agree nobody build ai weapons because really who like a general still a person with family maybe kids grandkids like who wants to live in a world with ai empowered autonomous weapons that have that speed [5679](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5679.199s)

of [[decision making]] and lethality like it's just a up world nobody would want to live in that but because we can't ensure that no one else is doing it because even if they say they aren't doing it how do we know for sure in some deep underground military base they aren't doing it we have to assume that they are and then we have to assume that they are doing the most advanced version [5695](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5695.92s)

possible and then we have to still ensure that we beat them at it and then of course they also might want to not do it but they have to assume that we are so this is a [[collective action]] problem a coordination problem and we can see the application in [[arms race|arms races]] now as we mentioned earlier up until world war ii in the nuclear bomb every time there was a more [5713](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5713.92s)

advanced weapons technology there was a race to implement it um for the advantage it would give with nuclear bombs you had a situation where the destructive capability could be omni-destructive that you had a race to develop more and more potential capacity to use it while trying to ensure that no one actually used it it's a weird situation [5732](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5732.239s)

we're still in the place of trying to develop the potential capacity to win just through deterrence threats you know whatever it is but obviously our the total lethality and the total consequentiality of what could happen if initiated even because of accidents especially in a [5753](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5753.679s)

time where launching disinformation campaigns and cyber attacks on proper information of uh if someone else launched their thing or not is getting increasingly easy for for non-state actors it then affects everything else the precarity of that much destructive capacity in that many locations [5773](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5773.44s)

like it's just obvious right just to think about the precarity of even [[nuclear weapon|nuclear weapons]] if you haven't read the doomsday machine by daniel ellsberg it's really worth reading to see how many times [[nuclear weapon|nuclear weapons]] almost fired just because of accidents like person accidents or computer glitches and it's almost [5793](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5793.36s)

it almost inspires some sense of like supernatural awe that we are still here but increasingly so as we think about how many more catastrophic capabilities and how many more hands are emerging so the [[multipolar trap]] is underneath why we can't say let's just not do a particular thing and we see that in this [5814](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5814.96s)

kind of military example here you can take that all the way back to kind of early tribal warfare and let's say that there was a area where there were some tribes that uh were actually quite peace loving and not oriented towards warfare and maybe had some kind of animistic or spiritual ideals to want to [5839](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5839.28s)

live in harmony with nature or whatever it was as much as they could if any tribe around them starts being oriented to tribal warfare realizing that the increasing population in the area is creating a competition for the dwindling amount of natural resources available fishing or hunting or whatever it is [5856](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5856.719s)

and that killing people in another tribe means decreasing the competition for those resources plus getting the stuff and the surplus they've already created and that the weapons you use to hunt and the weapons used to go kill another tribe are not that different if any tribe orients towards that every other tribe has to orient towards that or they [5873](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5873.28s)

lose by default you don't get to just say hey i opt out of this game right and so then that creates a situation where if some group orients towards that very powerfully right like genghis khan or the spartans or whoever who are going to invest most of their capacity in in military tech how does any other culture in the presence of them not get [5894](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5894.56s)

destroyed if it doesn't develop adequate military tech to at least defend itself and how do you defend yourself against someone that is that exceptional in that without having that change who you are as a culture completely because you have to now create all the investment in that category so when we were talking earlier about kind of long arc of history the idea [5912](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5912.0s)

that um warfare is one of the selection environments where cultures made it through or didn't make it through and the ones that were not successful at warfare in relationship with the ones who were waging it didn't make it through so there was a selection both for the capacity and orientation to be effective [5931](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5931.84s)

at it and then the more the more successfully violent ones took out the less successfully violent ones the successfully violent ones warning with each other upregulated each other's capacity in a particular kind of you know [[multipolar trap]] scenario and then we are the descendants of those who made it through that um [5950](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5950.719s)

it's an interesting and important insight you can see that for a couple hundred thousand years give or take of homo sapien history we mostly lived in these very small tribes you know below the [[dunbar number]] because people we we can assume didn't want to live in much larger groups [5974](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5974.4s)

where for the group to have coherence they would be bound by certain rules that if the group was too large they didn't have a saiyan when you are below the [[dunbar number]] everybody can sit around a circle around a fire and all have a say on a big decision so if i'm going to be bound to something i at least want to say in it i want if i'm going to [5991](https://www.youtube.com/watch?v=8XCXvzQdcug&t=5991.44s)

sacrifice for other people that they're people that i really know as soon as the group gets too large i'm supposed to make sacrifices for people i don't know and i'm bound by rules i don't get a say in no the group would rather just cleave and make smaller groups it seems clear that uh humanity stayed below the [[dunbar number]] for whatever set of reasons pretty rigorously for a very long time and so that's very you know it's very interesting from like the scale at which humans evolved to be able to operate like our whole evolutionary genetic history was operating at that kind of scale mediated in in those ways [6027](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6027.28s)

but of course amongst other things one of the things that would have selected for ending that would have been tribal warfare and if say a larger tribe uh wants to initiate warfare smaller tribes better merge together to be able to defend themselves and that means probably giving up some uh say and freedoms in um and quality of [6047](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6047.76s)

life so as to have safety and security and now of course the race for larger groups with more effective weaponry and more division of labor to have more you know capacities and more surplus which means more extraction from the environment that race is on so we can then kind of see the history of civilization in terms of the history of extraction capability from agriculture [6068](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6068.239s)

and mining and whatever the um what we would call um exploration capability which means being able to convert more of the natural world into stuff that we use the expansion of military capacities the expansion of coordination technologies the expansion of um you know size of group that can be in coherence with each other to fight [[rivalrous dynamics]] externally and so you know eventually we got empires and kingdoms and the [[nation state|nation states]] and then kind of global economic trading blocks and nato's and things like that uh with the exponential increasing types of technologies that we have both for extraction you think about a mile-long drift net being able to pull uh hundreds of thousands of pounds of fish out of the ocean in a single go compared to a fishing line or compared to what an orca can do this [6131](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6131.84s)

is exponential extraction right music and we can see that in every area of industry from [[factory farm|factory farms]] to mining to drilling to fracking to whatever exponential extraction exponential monetary creation exponential information processing weaponry et cetera but where there is some externality to the environment and [6151](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6151.52s)

to social cohesion and to um sense-making happening everywhere you're advancing some things causing externalities but at you know exponential increasing scales so historically what has won and made it through was an increase in the capacity to win a [[game theory]] and yet that is kind of a long [6175](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6175.119s)

[[exponential curve]] that is really verticalizing now and it's verticalizing in its total game theoretic which also means externality creating and destructive capacity while reaching [[planetary boundary|planetary boundaries]] and so if we continue to do that which is always one which means win at [[arms race|arms races]] that process itself self-terminates and so this is a real tricky thing because we can neither say well let's kind of do the luddite direction of like less advancing military attack or whatever and just lose that doesn't work we don't want like uh what happened between tibetan china has happened a lot of times throughout [6213](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6213.04s)

history and trying to do tibet doesn't work right but trying to continue to win at [[game theory]] driving [[arms race|arms races]] that are increasing destructive capacity and externalities also doesn't work as you're approaching the point at which that creates inexorable [[catastrophic risk]] so something that has never happened before has to happen [6230](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6230.88s)

soon there are some other examples of [[multipolar trap|multipolar traps]] this is an example of kind of the [[arms race]] side we can think about the tragedy of the commons as another [[multipolar trap]] and it's not that no [[multipolar trap|multipolar traps]] have ever been solved or bound they have you can read eleanor ostrom's work you can read the process of commons management you can obviously see how [[mutually assured destruction]] was binding a [[multipolar trap]] on [[nuclear weapon|nuclear weapons]] in a particular way it's that we don't have adequate solutions to the nature of the [[multipolar trap|multipolar traps]] that are catastrophic that we face currently so rule of law is a way to bind a [[multipolar trap]] right inside of a [[nation state]] so that everyone isn't racing to cut down all the trees and there's no national parks we agreed to make national parks and then create a monopoly of violence which is a police force to be able to back that up so if people try to go to do it they you know [6287](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6287.28s)

be physically forcibly stopped until we get to have some trees um and that would also be true for crime and pollution and you know other things like that where we use law and the ability for enforcement of law to be able to back it up within a [[nation state]] there are places where that's really hard to work because of course then the [6305](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6305.04s)

economic incentive is to try to capture the regulator the regulatory apparatus is trying to bind where there is excessive [[perverse incentive]] in the market right the idea of kind of a [[liberal democracy]] is let's let's let the market do most things because it's kind of a decentralized [[collective intelligence]] where hopefully people demand real goods and services [6325](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6325.44s)

that will benefit their life which creates a in evolutionary niche for people to create products and services as supply and to compete with each other to make the very best product or service at the best price so that the rational actor will buy that that's kind of like old-school market theory this is obviously not true it has some truth in it but it's not completely true [6343](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6343.04s)

as the behavioral economist showed people are not rational actors who make the the best choice especially in a world where nobody can even see all the choices there's a kind of information overwhelmed so uh the thing that actually is the most effectively marketed thing will end up succeeding over the most effective thing [6360](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6360.88s)

uh manufactured demand is very easy so rather than demand driving supply people now want that won't actually increase the quality of their life will empirically make their life worse that they never wanted before because the nature of marketing manufactures demand that wasn't there the whole idea of the [[collective intelligence]] of a market is that demand drives supply like that's a foundational idea i would suggest as to why it is actually net good the moment that the supply side can drive demand for things that don't actually increase the quality of life meaningfully which is through largely appealing to addiction and keeping up with joneses and kind of lower angels of our nature stuff and of course as soon [6398](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6398.32s)

as corporations start to become large which earlier if you think of like a local market that wouldn't have been the case but as soon as corporations become very large then supply and demand have a radical asymmetry the of course supply and demand should be the same size in aggregate but the supply side of a major corporation a billion-dollar [6419](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6419.44s)

corporation is coordinated as a corporation with a org chart and decision-making processes and all of the consumers are not in some kind of like labor union for consumers some consumer union that give it has equal information processing to be able to play that [[game theory]] it's the multi-billion dollar corporation against the individual in terms of the [[game theory]] so of course the corporation can employ behavioral psychologists and ai split testing and all kinds of things to be able to optimize supply driving demand rather than the other way around underlying intelligence of the market is broken at that point and you really just have [[asymmetric power]] having captured the ability to maintain and advance its own [6456](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6456.96s)

power but so the idea was in kind of formation of modern democracies market should be largely free because it does a lot of good decentralized things we want to decentralize stuff as much as possible democratize decentralized but the market will eventually create a power law distribution some people will be better [6481](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6481.84s)

at market than others and as a result they will make more money and they will be able to use their more money to make more money and so you'll end up getting rather than an equal distribution of money a pretty tight power law distribution of money and then the people with the money have maximum control and it'll become feudalism again and we're trying to get [6496](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6496.96s)

away from feudalism so you have to make something more powerful than the most powerful wealth class if you don't want it to be feudalism again realizing that the wealth will follow a power law distribution so the idea of let's make a state that has rule of law and has a monopoly of violence so that it is more powerful than the most powerful of the top of the [6514](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6514.96s)

market and then the state is run democratically so that the collective values of the people and then of course this only works if the values of the people are somehow developed so all of the kind of founding documents in the us and other modern democracies talk about things like the number one aim of government should [6530](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6530.88s)

be the comprehensive education of every citizen in the science of government george washington or things like that that it requires a comprehensive education informedness and some kind of moral education simultaneously for a democracy to work otherwise democracies are just a really dumb idea of lots of [6547](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6547.76s)

rivalrous uneducated people all having a say in how things go about that they don't know anything about socrates is kind of critique of why democracy was a dumb idea in ancient greece so if you want to be able to democratize [[decision making]] you've got to educate and enlighten the people i think it was franklin [6565](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6565.679s)

or jefferson's quote on if you believe who should the ultimate uh depository of the power live with and if you believe the people to be too unenlightened to hold it then the obligation is to enlighten the people because there is no other force that can hold it that doesn't become despotic these are paraphrases so the idea is uh a civilization you [6585](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6585.119s)

know our society that invests in the collective human development of the people that the values of the people then get encoded through some kind of democratic process into rule of law the rule of law has a monopoly of violence so that it can then bind the predatory aspects of the market because mostly things that are against the law are [6606](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6606.48s)

things where somebody has an incentive to do something but that we collectively agree we shouldn't let people do but there's an incentive to do it which is fundamentally a market type force so let the market do a lot of things regulate the up things of course the challenge becomes that the market where it would be regulated by the state [6624](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6624.08s)

in a way that is disadvantageous towards it has its own incentive to try to change how the state regulates and so uh this is where lobbying comes in this is where campaign finance comes in and this is where you know all of the ways in which regulatory capture by uh market starts to come in and when you realize that the people in market positions have an enduring in [6642](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6642.88s)

incentive to the market where the people in representative government positions don't have an enduring um loyalty to that position this is the public choice critique of representing democracy it becomes pretty easy for regulatory capture to occur see heaps of examples of that but so there there was clearly some right ideas in those structures of what should be done through decentralized type process where does that still have failures how do we figure out how to create some centralized power that still represents the decentralized will of the people to be able to create checks and balances on power coming out of the problems of uh monarchy not having the no bless oblige that it was supposedly supposed to have the modern systems were very much developed around the idea of checks and balances on power so don't allow too much power to concentrate anywhere as that ends up having you know uncheckable corrupting orientation so let's create a separation [6706](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6706.96s)

between the market and the state let's create a separation between the state and the church and other kind of civic organizations let's make sure there's no monopoly on religion so all of the religions are allowed let's make sure there's laws against monopoly on corporations so the competition between corporations can [6725](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6725.28s)

check each other let's split the government into three different branches um you know on and on right this all designed to be how do we create checks and balances on power so that abuses of power because where people are acting harmfully with symmetrical power they can kind of check it themselves where someone with [[asymmetric power]] over someone else is acting harmfully it's very hard to check so how do we create checks and balances there's a lot of right thinking in this but total advancement in technological capacity and population size and many things have made it to where those systems as they were put in place not the principles but the systems have mostly broken [6766](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6766.239s)

music if we were trying to build a [[open society]] a kind of democratic or [[participatory governance]] system from scratch today in the 21st century we wouldn't be thinking about people meeting physically in a town hall that can't possibly hold the population of a local area to have a representative who has to ride a horse to like we wouldn't [6787](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6787.119s)

be thinking of that we'd be thinking about how to use the internet to create town halls big enough that everybody could fit in we'd be thinking about since there's too much information to process we'd be thinking about how to use [[artificial intelligence]] to process the everybody's views into forms information compressed forms that we can actually work with so this obviously has to happen how do we take the advanced technology that has fundamentally changed the nature of governance and implement it to build new governance systems aligned with similar principles and evolutions of those principles that we've gained since [6821](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6821.36s)

then mediated through the right capacities currently the idea that rule of law an estate is a way to bind a particular kind of market-driven [[multipolar trap]] but that is of course within the domain of the rule of law within its jurisdiction so then international tragedy of the commons issues are a [6840](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6840.639s)

different kind of thing because where does the enforcement live becomes a trickier issue so if we think about uh tragedy of the commons issues that operate at a international and particularly at a global level we can see that the world is having a really hard time figuring out how to deal with these [6858](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6858.88s)

[[climate change]] is a very classic example because every place is utilizing i mean every nation is utilizing hydrocarbon fuels and given that energy use in gdp correlate and everybody's in a [[multipolar trap]] race for gdp growth because that equals increased optionality for everything else which also means the race to use more total energy and which is driving [[climate change]] how do we get out of that well obviously we aren't paying for the real price of energy right we're simply paying for the cost of extraction [6897](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6897.36s)

uh my friend nate hagen says really great work on this topic has a very good podcast we've done some discussions there if you want to get more into the issues of energy ecology but we basically pay for the extraction of the hydrocarbon like what does it cost to mine this barrel of oil and then add some little margin to make a profit but that's not the cost that it [6916](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6916.56s)

would take if we needed to make those hydrocarbons ourselves would it cost nature to do it as they're fundamentally unrenewable or the cost to the environment of the pollution side of it if we were trying to cost appropriately what it would cost for us to make that fuel renewably and not cause environmental externality in the process the price would go up so much and then that as a key input to every industry that markets would as we understand them today fail in every sector it's a big deal like because that's real but we're incentivized to externalize all the costs because other people are and if we don't we will lose in comparison so an incentivize to use [6956](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6956.08s)

all the energy we possibly can to grow the gdp as much so if we try to make the price of carbon more real we try to drive the cost of carbon up to disincentivize the use of it we so radically disadvantage ourselves in terms of gdp growth that if anyone else if any other major [6977](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6977.76s)

player doesn't also do that then they will gain so much geopolitical advantage military advantage population growth advantage that they will simply win this [[multipolar trap]] so unless we could get all of the major players to agree to the thing and have the kind of transparency to ensure that they actually were keeping the agreement and then have some kind of [6998](https://www.youtube.com/watch?v=8XCXvzQdcug&t=6998.88s)

enforcement mechanisms where if they didn't we could enforce it and this is also really tricky because how do you enforce adherence to something of another country that also has nukes right like what what what are you how far are you willing to escalate the thing before you're like now we're just actually not going to use our nukes on you so if we do a sanction [7019](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7019.679s)

and you don't back down and so then we do some limited military action you don't back down at some point you just got to say okay we just don't have the ability to enforce this therefore we have to race because if we go all the way in enforcement and you go back we're all  so um so transparency can we see if the other people are keeping the agreement or not the ability to create those agreements the transparency to see if they're being kept in the capacity for enforcement are critical things to be able to bind [[multipolar trap|multipolar traps]] at international levels so whether we're talking about overfishing of the oceans or the [[dead zone|dead zones]] in the oceans or the depletion of topsoil or the depletion of pollinators or [[climate change]] or any of those issues that advantage us to continue to externalize the cost to the commons in the near term relative to others also doing it and it would disadvantage us not to unless we can get over the [[multipolar trap]] we don't solve these issues [7073](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7073.119s)

so this is a kind of environment or tragedy of the commons case we already gave a kind of military [[arms race]] case i'll give another example of a market case uh which is basically the race to first mover advantage of new technologies entering the market the race to market dominance network dominance as we mentioned earlier there's kind of a perverse [[game theory]] and this is underlying the [[game theory]] of [[multipolar trap|multipolar traps]] that those who are oriented to advance a game theoretic opportunity will get a lot further ahead than those that are oriented to prevent a harm particularly those who are [7118](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7118.239s)

oriented to advance an opportunity for themselves as players and willing to externalize the harm cost to the commons they're not responsible for will get much further ahead than those that are willing to bind their own game theoretic advantage to prevent the harm occurring to the commons and now we're back to the [7136](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7136.32s)

how does the peaceful tribe not die in relationship to the warring tribe without becoming a warring tribe topic and so let's say we're looking at the advancement of new technologies that could be radically destructive to the world many different ways like let's say particular types of [[artificial intelligence]] if i don't really if for whatever reasons whatever cognitive dispositions or whatever i don't really pay attention to the risk or i don't buy it that much and i buy the opportunity i'm going to do better in being able to advance the product quickly sell it to people you know et cetera than the [7180](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7180.56s)

person who's paying much more attention to the risk even if i buy the risks if i want to ensure that i'm advancing it in a way that cannot cause those risks i'm going to move a lot slower and do a lot more steps of protection and safety and due diligence for the commons it still means [7198](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7198.0s)

i will lose first mover advantage and specifically when [[network dynamics]] are at play [[network dynamics]] are very important um we look at say metcalfe's law is the entry to understanding [[network dynamics]] this is where the value of a particular company or technology or whatever is mediated by [7217](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7217.679s)

interactions between customers or users in that platform the more users that engage with the technology the more the value goes up the value actually goes up more than linearly it goes up by a second power to the number of users so let's say we're talking about something like a search engine or a [7237](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7237.36s)

[[social media]] or a um currency i don't want to use a currency that like 100 stores use where then i have to have like 30 different currencies in my wallet that's pain in the ass i would like to be able to use a dollar that everybody takes um i don't want to have 50 logins to different [[social media]] accounts that i have to remember where [7257](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7257.52s)

only a few friends are in different ones i'd like to be able to go to a place where everybody is so there's obviously so much advantage to the number of users on the network being able to share value in value exchange that you end up getting a situation where once any particular technology or let's say [7276](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7276.719s)

implementation of technology which is mostly as companies gets to enough market penetration there's kind of an escape velocity where they will then gain more market penetration faster and this is why i believe in the early days paypal was actually paying people to join the platform right because it made sense they got the amount of money that they [7296](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7296.8s)

had to give in coupons or whatever to join the platform was tiny compared to the increased valuation per user they followed a second power equation and this is why there are not lots of fintech platforms of comparable size and that's why amazon is bigger than all the other online stores youtube video players facebook [[social media]] google search etc so this is a kind of [7317](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7317.92s)

monopoly right fundamentally it's kind of monopoly but that is not the kind of monopoly that we've historically thought of as something that like was a monopoly through government participation and so we have not uh oriented towards how to actually bind [7333](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7333.119s)

this thing very well and it can happen very quickly as we could see you know facebook and google and youtube achieved fundamental monopoly status in a very short period of time at a global scale or at least a western world scale that's a big deal it's a big deal to realize because then the idea of checks and balances of power within the market [7352](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7352.56s)

is kind of gone right and music so in a world where [[network dynamics]] are a thing then there is an even more intense race for first mover advantage and as rapid growth as possible because if you don't get to that escape velocity somebody [7370](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7370.48s)

else will whoever gets to that escape velocity will dominate everything for a very long time so that just the [[network dynamics]] intensified the market races radically so of course anything that would slow down my speed to market and my speed to user adoption uh decreases my chance of [7391](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7391.599s)

being the top of the power law distribution and no other position really matters right so how to just race in that way is dominating market dynamics in most areas of emerging technologies and [7407](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7407.44s)

particularly you know exponential technologies so this means ai being developed for a positive purpose that has negative externalities that either nobody's thought of or nobody feels like they can do anything about it we hope we'll just be able to solve later being developed for a positive purpose that can be repurposed for negative capacities being developed for a hopefully positive purpose that might become autopoetic and take off in ways that are totally uncontrollable etc right where then of course our speed of advancement with that drives the [[arms race]] of everybody else's increased speed of advancement this is also a [[multipolar trap]] it's a [[multipolar trap]] in the market and given that now these competitions are not just at the level of a local market but all at the level of a global market then the total speed of the race and the scale of the competition and the scale of what is affected is just its zenith so in the area of the environment and tragedy of the commons and the particularly in the international cases where enforcement is difficult in the area of actual [[arms race|arms races]] of kind of military technology in the area of market races [7485](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7485.36s)

where the race to first mover advantage of market dominance ends up being a [[race to the bottom]] in some important way these are all examples of a [[multipolar trap]] or a situation in which the inability to get out of the perceived competitive dynamic means that if anybody does the up thing and since you can't prove that [7507](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7507.28s)

they aren't doing it you have to assume that they are means everybody has to race to do it as fast as possible which means a uh a globally worst case scenario across all these axes for everyone with each actor doing the rational choice that makes most sense to them in the context in the moment so this is not a particular person being [7523](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7523.92s)

bad it's like well it makes sense of course if they are possibly building the ai weapons and we don't want our people to die we should build their weapons so you have a situation where each person can do what seems like the obligately moral thing and yet everyone is collectively doing the stupidest thing for the whole [7540](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7540.079s)

possible and this is a kind of [[collective action]] failure where our inability to create relationships of trust and our inability to coordinate creates not just inefficiencies and duplication but radically destructive orientation on what could be otherwise constructive capacity this is one of the uh yeah most kind of fundamental dynamics underneath most of both what is driving the [[catastrophic risk|catastrophic risks]] and what makes them so hard to solve there's also a question that could be an orienting question for humanity of how do we progressively better bind and solve multiple traps particularly the ones that are driving near-term [[catastrophic risk|catastrophic risks]] and this is an area that i think actually has a lot of solutions not a categorical or perfect solution but a lot of solutions uh and that i think a lot of humanities collective innovative intelligence [7611](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7611.119s)

focused on would make a really huge difference for instance we said one of the challenges of solving the multiple trap internationally is the inability to make international agreements and one of the reasons where either we don't make the international agreement because we it's not even worth [7629](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7629.36s)

making because we're sure they're going to defect on it so why even bother or we make the agreement knowing that they're going to defect on it and we're going to defect on it but we're going to say that we're keeping it and we know they're going to say they're keeping it we're going to spy on them and we're going to lie to their spies [7644](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7644.159s)

and all this kind of waste that goes into that uh if the transparency to know what they were actually doing and them to know what we were doing was there the ability to make and keep the agreement would be fundamentally different so underneath [[multipolar trap|multipolar traps]] is the perverse [[game theory]] to orient towards opaqueness rather than transparency and this is you know the whole nature of how many things are considered trade secrets in the market or [[national security]] secrets and you know all of the different types of security clearance and classification [7679](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7679.84s)

and special compartmentalized information and whatever because we're trying to have information advantage information asymmetry advantage on the other side and we don't want them to know what we're doing but we do want to know what they're doing and so we invest a lot in this but the [7694](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7694.56s)

opaqueness means that the agreements can't be made so the [[multipolar trap]] is the only thing that is left so um let's say there's a company called planet labs it's one of the largest private satellite imaging networks in the world and they've already been working on this [7715](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7715.599s)

for different applications and we've talked about more applications that could happen let's say that we take a particular kind of problem that drives a global [[multipolar trap]] that can be seen on the surface of the earth we don't have to deal with the deep underground military bases yet so let's say we're talking about um streams of pollution that are flowing into rivers or things like that if we're talking about real-time video imaging at pretty high of the entire surface of the earth pretty high granular detail can we see where the mining waste is being dumped can we see where the uh major plastic in the ocean or the [[dead zone|dead zones]] in the ocean where the affluent is coming from by kind of reversing the time sequence on the images yeah you know satellites are one example of sensor networks but they can operate in that way does the ability to do attribution [7769](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7769.679s)

right specific verifiable attribution of where a particular harm is coming from does that increase the capacity to create justice to be able to bind it totally so is it possible that certain types of forced transparency can make it to where the ability to hide the harms that then have everyone race [7793](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7793.76s)

to do the harms goes away and then the need the fact that they can be shown means there's a need to account for them and better methods of accountability emerge i think there's a lot that can be done with forced transparency that orients towards a fundamentally better [7813](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7813.92s)

uh attractor of the [[game theory]] space there's a very interesting question i don't know the answer to this but i am intrigued of are there also scenarios where transparency besides being forced in that kind of way like satellites that are looking at the entire world from international space so the law allows them to do that [7835](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7835.599s)

are there ways in which transparent solutions win game theoretically as a different peak in the adaptive landscape relative to the opaque solutions why the opaque solutions win is very obvious surprise attacks help right the ability to advance something where they don't know that we're advancing it we mislead them about it they build a false defense [7855](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7855.84s)

like it's obvious why the desire for um information asymmetry in that way is there i was talking to someone in [[national security]] of sweden who was telling me some very fascinating things and i haven't been able to verify [7874](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7874.32s)

all of them but saying that the of kind of major nations that have meaningful defense capacities sweden has maybe the most transparent intelligence and military and security apparatus and their underlying philosophy was that the major players are going to be effective with their spying and no [7894](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7894.88s)

anyways they don't really get that much information asymmetry that's more of an illusion of control than a reality of it and so russia and china and the us are going to know anyways and so the huge amount of resource that they would have to put into trying to hide from them is mostly a waste so they're just not even a try and that if you have to try to hide [7912](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7912.4s)

the [[national security]] stuff from the quote-unquote enemy that also means you have to hide it from your citizens because otherwise your citizens don't all know how to keep classification which is why like in this thing pretty much makes democracy impossible in any real sense more than just a simulation at the time of the founding of modern [7930](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7930.719s)

democracies and particularly i'll mention the united states here the united states had an ocean on both sides to anybody else it had no kind of contiguous um rival land contiguous rival that was a pretty awesome security situation and so the decisions that needed to be made about anything including military things could be shared with the people the people could actually weigh in on them and sharing that information with those citizens didn't instantly mean sharing it with the british or the spanish or the anybody else because there was no way to get that information across the [7968](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7968.079s)

ocean quickly and um simultaneously once someone else got that information they couldn't launch an attack that quickly they'd have to launch boats that we could see that would take months it would give us time to launch a you know a response [7983](https://www.youtube.com/watch?v=8XCXvzQdcug&t=7983.44s)

and so the ability to share with the citizens was actually viable in that world because of those sets of reasons as soon as we get to a world where whatever is being shared with the citizens can be known by rival countries instantly because of uh electronic uh you know telecommunications and where they can then launch attacks [8003](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8003.04s)

instantly including ones that are hidden with [[plausible deniability]] like cyber attacks or economic attacks or geopolitical positioning let alone missiles now the threat of sharing information with the citizens meaning sharing with the rivals is way too high therefore more and more things become classified [8021](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8021.76s)

more and more things become [[national security]] secrets obviously attacks on our water supply or our energy grid or our [[food supply]] could all be [[national security]] threats so we start finding that there's [[national security]] secrets  everywhere well how do you do democracy if the citizens can't actually know what is going on and what the real [8037](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8037.52s)

considerations are well you can't it's it's a simulation of it this is a real challenge that like we have to think of in a deep way when we consider what does a [[participatory governance]] system in the context of the modern world look like because it makes sense that there would be a black budget and it makes sense [8060](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8060.079s)

that there would be [[national security]] secrets but then how do you verify that those authorities are not corrupt how do you verify that they are actually doing the will of the people or how do you you know how do you create checks and balances on power or adjudicate issues or things like that this also relates to the thing we were [8077](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8077.44s)

mentioning earlier about that when even scientific publishing equals increasing [[catastrophic risk]] because the scientific publishing creates the capacity for more catastrophic technology simply through information i don't have to actually give the capacity to manufacture the tech that is easy give the information on how to code a [8096](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8096.639s)

particular thing catastrophic ability increases how do we do open sharing of information in a world where other actors and increasingly smaller actors can use that information in increasingly destructive ways and if you don't then how do you have anything like [[participatory governance]] without open access to the information this is now why we talk about that the two primary attractors for the world are catastrophes and dystopias that uh if we continue to advance exponential technologies where more and more actors have capacity to intentionally or accidentally catastrophic technology and that them like the industrial tech cumulative effects the now not just weaponized or accidental immediate catastrophes but the cumulative externality effects of the technologies continue to advance so rapidly that world orients towards increasing likelihood of [[catastrophic risk]] to be able to prevent those [[catastrophic risk|catastrophic risks]] means being able to bind the intentionally or even accidentally or even externality driven catastrophic potentials the ability to bind that looks like some very very powerful regulatory capacities of some kind whether it's a decentralized network regulation or whether it's a [8181](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8181.92s)

state or whether it's a whatever the whatever it is and then how and then most of the ways in which we could build a thing that could do that that thing to have the power to check decentralized exponential attack has to be powerful enough that what can check it and so then you end up getting dystopic solutions [8201](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8201.359s)

so a classic example though by no means the only one is i can't build [[nuclear weapon|nuclear weapons]] in my basement it's too hard to build them but if i can build bio-weapons or i can build ai weapons or cyber weapons or drone weapons in my basement that can produce [8220](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8220.88s)

not only really bad harm but possibly cascading harm or illicit other actors to do similar things in the presence of decentralized [[catastrophe weapon]] capability involving no exotic materials how do we prevent the world from breaking which increases in probability as time goes on without something like a system of [8248](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8248.639s)

surveillance that knows what people are doing in their basements well it's very hard to imagine how to do that actually and yet it's very hard to imagine how a system of surveillance that can prevent that which is a very understandable thing to want to do an [8266](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8266.24s)

important thing to want to do who who has access to that surveillance how do the issues of determining right use of that surveillance and the power of that get adjudicated very easy to see that becoming a really dystopian big brother scenario already in the west many people feel [8285](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8285.679s)

that the approach that the chinese government is taking to address very real issues that they see as kind of catastrophic to their civilization that we're not addressing well enough and are eroding our civilization we see as dystopic to certain kinds of civil liberties [8303](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8303.76s)

we can see the way that it's clear that the polarization engine that [[social media]] and infotech is that is driven increasing polarization uh in the united states in particular china resolved that very easily by having their central government just start to ban and regulate those [8322](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8322.96s)

technologies right that kids only had access to a subset of tick tock that shows patriotic and educational videos and they have a limit to the amount of minutes per day and per week they can play them in video games and no live streaming and like they were they this is a huge deal now that's totally a [8339](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8339.599s)

you know something we could call a paternalistic like overreach of state but we can also see that our state is eroding by not doing that and being captured by market forces and broken down by polarization forces and the sesame credit system and the iot the ai mediated iot kind of surveillance system makes a lot of sense to prevent [8365](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8365.84s)

catastrophic technologies happening decentrally it also creates a lot of uncheckable centralized power so we i would say that uh when we talk about what is a desirable civilization it becomes a really tricky [8383](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8383.04s)

topic because it's like centrally existential questions to say what is a what is a good civilization we don't have a system like science this is kind of the is ought distinction where science can say what is but not what are we we don't have a as powerful as sciences [8404](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8404.399s)

for being able to understand the objective world which then allows us to create tech objective tech that affects the objective world we don't have a comparably effective way of studying the subjective and inter-subjective world of being able to say good right and so if you have the ability to affect the world exponentially more powerfully through science and applied sciences technology but you don't have a comparable powerful force for what is good or wise guidance of that technology then what is guiding that technology ends up being [[game theory]] right and [[game theory]] is actually like a the closest thing to a scientific [8443](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8443.28s)

to something that is commensurable with the scientific system in terms of what is a good choice which is kind of the social darwinism of a good choice as a choice that doesn't lose game theoretically to other choices that are also seeking maximum advantage but we can see that the advance of [[game theory]] under the presence of [[exponential tech]] in this way self-terminates so that clearly cannot be called a good choice and yet losing in the near term is also not a good choice so we need something that is option d none of the above so while i think it is important for us to become as good at the type of mind at the type of internal human capacity that can do wisdom and ethics as we are at the capacity to do science and technology and to be able to think about what is a desirable civilization i think we can start by agreeing on a couple things that are not desirable and i think that's actually very helpful i think the idea that a [8506](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8506.8s)

civilization that self-terminates is probably doesn't meet the criteria of what a optimal civilization is so that we are wanting to prevent the movements towards cascading catastrophes that seems pretty straightforward and that one that is clearly dystopic meaning that there are such radical asymmetries of power that uh the freedoms of almost everyone are radically curtailed uh is also not an ideal case and so and yet it's very easy to see that [[exponential tech]] has the ability to decentralize power [8548](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8548.96s)

as the market cases giving an example of which increases which creates these coordination uh [[collective action]] problems and [[multipolar trap|multipolar traps]] and so the decentralized catastrophic or the decentralized exponential power creates [[multipolar trap|multipolar traps]] creates increasing catastrophes so then it also has the ability to centralize power [8568](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8568.16s)

right if i could have an entire nation-state in historically the nation-state couldn't be too top-down and too big because it would get fragile because you can't actually see what everyone's doing and control it but the ability to have sensors everywhere and have no person could make sense of that and [8585](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8585.84s)

you couldn't even trust the chains of command but ai systems could and then getting everybody to spy on each other is tricky but being able to mediate that through sesame credit type systems i could do that thing so the [[exponential tech]] also creates way more powerful autocratic systems at scale [8605](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8605.52s)

you know centralizing power which brings us back to why the [[multipolar trap]] is one of the very deep underlying things to work on ah and this also brings us back to the swedish example that i did not complete of where transparency could win so the example he was giving is that rather than invest any resource in um opaqueness or you know hiding or cloaking stuff they would just assume that the rivals would find out anyways and as a result they didn't have to keep stuff from their own population in the same way as a result the population has [8650](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8650.0s)

way higher trust than government as a result way less money has to be spent in campaigning and convincing people of things and there's more kind of emergent coordination and things like that and the various departments of government because they're and especially of military have more transparency to what each other are doing because they're [8671](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8671.439s)

transparent whereas in the classification you don't just have overarching classification you have this kind of special compartmentalized information process which means that a general in one area in a general and the other still don't know what's going on in the other domain so that both means that duplication can be happening it means that a lack of efficiency of [8690](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8690.08s)

coordination happens and that particularly when there's too much information it kind of doesn't even matter to have access to all the information because nobody can process it this is the infosingularity issue and we'll talk about this more but when we have more computational capacities to process large information sets then it actually really does matter [8709](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8709.28s)

having transparent access to all of it we can make progressively better sense of it with the right computational [[sensemaking]] augmentation so their ideas the transparency regarding things that would have otherwise been classified doesn't lose us that much [8726](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8726.64s)

it gains us a lot of trust in government which gains us a lot of discretionary participation of citizenry and it also gains us the ability for the various departments of government and military to be in much more coordination with less duplication and less waste because they have more transparency to what each other are doing it also means that it's much easier to check [8744](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8744.56s)

corruption because they increase transparency and so you have more you know efficiency and integrity and things like that and as a result you lose the little bit of asymmetry of information advantage but you gain a lot of other kinds of advantages so it's a different peak in the adaptive landscape i thought this was fascinating when you [8762](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8762.64s)

share this with me and so i asked you know that's cute and all as a country that has eu backing which fundamentally has nato backing um you know indirectly and that is not at the head of an [[arms race]] uh do you think something like that could work for say the united states his take was yes actually could work for [8781](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8781.359s)

the united states because the amount of capacity uplift that would occur and this didn't mean he thought it was inactive the the vested interest against enacting it would be ridiculous but just hypothetically as a [[thought experiment]] if that kind of transparency did happen the amount of duplication that's occurring is huge the amount of [8805](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8805.28s)

corruption and waste that's occurring is huge the um ineffectiveness of coordination that could be lifted would be huge the ability to start getting increased trust in government and as a result having the uh the democratic and government sector be [8824](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8824.0s)

more coherent aligned with the military sector as opposed to the increasing dis discoherence in the government public sector um and that even if some first attack capabilities were increased because of the information sharing of other parties that our total strategic capacity and response and deterrence would still make [8845](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8845.439s)

it or nobody would mess with that that such a thing could be advanced and i think this is a fascinating line of inquiry so if say more total strategic military capacity emerged out of the transparency than the opaqueness approach [8862](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8862.88s)

meaning per you know military power per dollar then it would actually drive a race to the top on transparency where russia and china would be oriented to try to do a similar thing because otherwise they'd actually be losing the [[multipolar trap]] that is now a race to the top on transparency rather than [[race to the bottom]] on opaqueness which is increasing the capacity for international agreement rather than decreasing the capacity and fundamentally addressing the [[multipolar trap]] progressively better if we think about having some forced transparencies through things like international satellite capability and [8898](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8898.479s)

things that uh and [[open source]] intel capacities that kind of mess up the opaque anyways can we make the opaqueness increasingly uh poor as an adaptive strategy the transparency both more forced and more capable of actually winning now we start to get a strategy where for the first time in history possibly something wins game theoretically [8920](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8920.479s)

that is also better in fundamental ways regarding its long-term viability that the culture more oriented to peacefulness can actually beat the culture more orange doorfulness you know warring without becoming more warring in all the most problematic ways it can maintain adequate strategic capacity while being oriented in a way that [8946](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8946.56s)

fundamentally is decreasing the types of pathological competition within the system and as a result and driving races to the top between systems of things that are um more positive some and less pathological as a whole ultimately whatever you know we i would say threading the [8966](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8966.96s)

needle of something that is neither catastrophes or dystopias and without being able to you know wave a magic wand and do enactment at the level of the whole world at once if any group were to do something the thing they would do has to not lose to the rest of the world not doing that thing not just not lose but it also has to [8984](https://www.youtube.com/watch?v=8XCXvzQdcug&t=8984.24s)

influence the rest of the world because if let's say we could get some country to do some very enlightened set of practices it still dies from [[climate change]] and ai and whatever so long as it doesn't change what the us and russia and china and other places are doing so it has to actually be able to influence the whole world shifting but it has to do it [9001](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9001.52s)

so it has to basically be able to win in some critical influence ways where the nature of what creates the win isn't externalizing harm or driving [[arms race|arms races]] or whatever um so it has to both be obsoleting some kinds of destructive [[game theory]] while winning at some fundamental types of [[game theory]] at the same time like so much the threading of the needle has to occur and i think when we go back to the sub dunbar tribes one of the things that mediated their effective protocols was that there was very high transparency which allowed for uh pretty good coordination [9043](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9043.52s)

and not having [[collective action]] failures within the group there was no real incentive for anyone to be sociopathic or narcissistic because nobody would want sociopaths or narcissists in the system and unless you can like  people and hide it that strategy doesn't pay if everybody can see that you're lying in a small [9060](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9060.64s)

travel scenario or they can see that you put your trash down or didn't do your part of the chores you're going to clean it up you're going to kick it out of the tribe so that the smallness creates a force transparency creates a situation in which what is best for the tribe and what's best for you are more closely aligned i'm not saying perfect but more closely [9078](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9078.56s)

aligned when the groups get much larger where somebody has the ability to play people off of each other who don't know that that's happening because there aren't enough communication channels and be able to um you know screw some people over here and then go somewhere else to get a new [9097](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9097.68s)

supply of people and whatever then of course the ability to hide the effects of what i'm doing i'll create a incentive for sociopathy and things like that which is why we see that those types of power oriented say cluster b personality disorders or something like three times more prevalent in c-suites and positions of more power [9120](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9120.56s)

than they are in the general population is that they are adaptive in those environments so they're selected for conditioned incentivized so of course we can get the high transparency and thus better alignment between the individual agents incentive and the whole in a small environment but that has never scaled if we want to be able to [9141](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9141.92s)

scale it are some of the new technologies that allow for certain kinds of transparency and then certain kinds of information processing across larger scale and communication could they facilitate better methods of [[collective intelligence]] that create that notice [[perverse incentive|perverse incentives]] and as a result of noticing them and being able to create accounting for them and externalities be able to create accounting for them create progressively better incentives and more capable deterrence to align the um motivations of individual agents with the whole [9178](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9178.319s)

better i believe so i believe that um some of the exponential computational technologies in particular that portend kind of the fastest and worst [[existential risk|existential risks]] in many ways also portend the possibility for better coordination systems and i'm not talking about ai [9199](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9199.52s)

disintermediating humans and having some ai singleton run the world i think that's a really bad idea for lots of reasons i'm talking about ai being able to facilitate human [[collective intelligence]] ai amongst other capacities but where i don't want [[artificial intelligence]] making the decisions by itself in most scenarios i want [9222](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9222.24s)

processes of [[collective intelligence]] of humans making it and we can get into obviously people voting yes no on a binary proposition where both sides both versions of the proposition suck if it goes through it benefits something and harm something else if it doesn't go through the thing it would benefit is now harmed [9239](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9239.92s)

because the proposition was just designed stupidly to begin with it didn't factor how interconnected everything was so the yes no on it can't not polarize the population like that's just a stupid system of [[collective intelligence]] right like that's just we can just do much much better where before you make a proposition you actually do the [[sensemaking]] of what are all the interconnected things what are all the values you take those as design constraints to go through a better proposition crafting process of what is the best synergistic satisfier with the least theory of trade-offs possible and what are better voting systems than binary that inherently polarize the population so i think we can do a radically better job of systems of [[collective intelligence]] and a radically better job of education of people to be able to participate with these things and an incentive system where as people become more educated in topics they actually get more ability to influence those topics um we could get into that it's beyond the scope of this initial introduction but one of the issues is that where there's more information that anybody can process right the information singularity there's more journal articles on a topic than any expert can read so nobody can ever be an expert on anything how do we solve that one idea is we [9308](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9308.96s)

don't and we simply need ai's to run the world the other idea is we have to be able to merge with the ais through some kind of brain computer interface or something like that i would say another version is that when you look at even the current state of generator ai which is really not advanced compared to what will be a year from now or five years [9328](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9328.64s)

from now because it's advancing so rapidly but you look at the current state which would be say gpt-3 today open ai it can use exclusively natural language input i don't have to be able to program i just speak to it and it understands my words and it does stuff based on understanding the words that's amazing right like go [9348](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9348.88s)

watch the dolly and the gpt3 um demos on youtube to just get a sense of what they can currently do because it's mind-blowing and this only thing more mind-blowing is the speed at which it's advancing the destructive capabilities of this don't take thinking very hard to imagine and they're very near-term [9368](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9368.88s)

the beneficial cases but that are narrow are also really obvious the omni-beneficial facilitation how do we create better [[collective intelligence]] and governance writ large is not as obvious until you really start to think about it but then it is amazing i i feel and this is not a techno optimist answer i'm very acutely aware that the [9393](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9393.6s)

technology on the current trajectory is most likely catastrophic and what it takes to make the other version of it is [[value system|value systems]] that have to be able to bind guide and direct it and influence [[social system|social systems]] that have that create the capacity to bind guide and direct markets and technology in a way they don't currently have [9412](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9412.16s)

but it is saying that the technology is new capacity and that that capacity if rightly directed does make new things possible in the same way that the [[printing press]] made democracy possible where it wouldn't have been before because without any newspaper and without textbooks you can't have a comprehensively educated and informed [9430](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9430.319s)

society when hand copying a book is so hard and expensive only a nobility class with the wealth can have access to it of course that technology of the [[printing press]] did make possible different types of coordination than was possible before obviously the internet anybody talked to anybody anywhere in the world made possible different types of coordination make possible and orient it to happen that way or different um while most people could use their phone to access any information in the world what they end up doing on it is usually not that interesting examples because of the nature of the choice architectures that they're engaging with in their user interfaces and the choice architectures [9468](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9468.0s)

are that the user interfaces that they engage with have goals for them that are other than that person's highest goals for themselves and they're effective um so this is not a i will save the world it's also not a i will necessarily destroy [9486](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9486.88s)

the world this is a since we have the power to create such powerful technology we need the orientation to ha to think about what wise application of that technology is and the intersection of comparable wisdom to guide right design and development of that technology that in turn then is developing wisdom and everyone else based on their interface [9507](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9507.12s)

in the same way that facebook can increase and it's a known thing you can change the algorithm that is affecting what's in people's newsfeed and they get more depressed or suicidal or more body image issues or not or because we're affected by what we untake could we create [9521](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9521.359s)

information platforms that rather than doubling down on my existing bias were oriented to help expose me to information that would that is antithetical to the things that i currently think but in the most compelling cases so as to increase my kind of dialectical awareness that rather than orient me to more people that are like the people i [9541](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9541.04s)

already know that orient me to people that are most unlike the people i already know to increase the total connectivity of my network that rather than maximizing for things like my engagement and time on site it was maximizing for things like um as i was showing the capacity to take and synthesize more perspectives the content that did that got upregulated in the algorithm right are there ways that that same type of technology could be applied that would be wisdom advancing of course this sounds scary because like who's idea of wisdom and who's going to control that but it's important to get it's already doing it right it's [9578](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9578.56s)

already controlling minds at scale so it's not a question of do we do it or not it's how do we do it since it is happening right and now the core question of well what how do we adjudicate what right use of the technology when you realize that the technology is not only radically affecting the earth physically but radically affecting our mind society's [9597](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9597.12s)

cultures now this again the the wisdom of gods to deal with the power of them become central what is the right use of that what are wrong uses where should that be bound how do we understand this how do we make sure that the binding a particular application of a problem doesn't make another worse problem so [9615](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9615.439s)

we don't like a particular kind of partisan-led censorship so we want more free speech but if a particular approach to free speech also means a lot more um ubiquitous deep fakes and an upregulation of the worst voices because they get most uh tension that creates eliciting of violence and the breakdowns [9634](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9634.24s)

of democracy it's like okay the obvious answers are all wrong right because the [[problem space]] is more interconnected and more complex so we have to hold all those [[problem space|problem spaces]] together and think about it but we come back to this you know gpt3 like ai type tech solving the info singularity [9652](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9652.16s)

so when you put something to gpthree it's not going to find a existing web page for you the way that a search engine would it can generate bespoke content right you can say write me an article in the voice of such and such it factors these kinds of facts and orients and towards this kind of conclusion and whatever and it can do [9674](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9674.0s)

that and progressively more and more effectively more and more turing tests passing across more domains well what if that just becomes the future of search right where if i'm searching for the information that could inform a particular choice we're wanting to make we're wanting to do something regarding grid security but grid security i need to know all the things [9693](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9693.2s)

about what really affects good security and how what other environmental and [[national security]] and you know et cetera issues are connected to that right now i can get billions of search results i can't read billions of search results that's not useful for me if i uh can the ai read billions of search [9713](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9713.52s)

results find the information that is decision informing based on parameters that i'm specifying and create new bespoke content that is the synthesis of that for incision decision and forming not decision creating the groups of people doing [[collective intelligence]] are still making the decisions but now with the ability to [9733](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9733.76s)

take a synthesized or refined set of more information than they can process it is pre-processed into decision-making information now you say well who controls that algorithm because that's a big deal well what if you can do it lots of different ways right what if you can um put [9750](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9750.8s)

different criteria for how to inform it and in the [[collective intelligence]] system all the agents have the capacity to do that kind of thing there are heaps of challenges and problems that we have to solve here but this is an example of ways that coordination technology the [[multipolar trap]] is a [[coordination failure]] it's a [[collective action]] failure the [[dunbar number]] can be thought of as an upper boundary of a particular type of coordination capacity where everybody can know everybody and see what everybody's doing talk to everybody and so the collective activity is able to be bound through very high bandwidth communication once we start getting larger than that [9792](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9792.96s)

early empires we got command and control hierarchies and we started to get all the problems that we see in the world today that are um now at the scale that we are driving [[catastrophic risk|catastrophic risks]] um democracies where how do we have a much larger system or rather than have [9811](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9811.12s)

uh somebody at the top rule whether it's one monarch or some small kind of uh nobility class or whatever how do we at least have since we can't get everybody at scale to agree the way that we could maybe get everybody at a tiny scale to agree but just a minority agreeing seems like a [9828](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9828.84s)

bummer can we at least get a majority to agree but then of course that thing intrinsically ends up driving polarization in its own decay and so can we make the types of transparency and the types of incentive alignment the types of capacity for deterrence that would exist at a small tribal type scale possible at much much larger [9853](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9853.279s)

scales where the increase in effective coordination starts to be uh more effective right you start to reduce a huge amount of waste and duplication and you know um failures of those kinds and so what makes this thing adaptive and selective in a kind of game theoretic situation is also what makes it healthy in terms of the health of the people inside in terms of classes relative people relative to each other and its relationship with the environment i think that something like that has to [9891](https://www.youtube.com/watch?v=8XCXvzQdcug&t=9891.2s)

be the answer and i think that it's interesting that the technologies that have the most destructive capability i think also have the most and uniquely facilitative capability for um solving [[collective action]] or facilitating us solving [[collective action]] problems music