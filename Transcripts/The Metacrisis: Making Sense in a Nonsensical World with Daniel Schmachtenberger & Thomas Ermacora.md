---
tags: transcript
aliases:
youtube_id: 6aKI2C61jVE
published_at: '2023-06-23T02:32:28-07:00'
---

<div class="yt-container"><iframe src="https://www.youtube.com/embed/6aKI2C61jVE"></iframe></div>

thank you i just want to say thank you for this welcome again from from the team at harvest it's great for me to have been able to suggest daniel as a speaker here i'm very fond of him as a human as a fellow futurist and as a thinker for our time i think it probably this needs a little introduction you know why is daniel here daniel is not a prophet of doom [36](https://www.youtube.com/watch?v=6aKI2C61jVE&t=36.5s)

absolutely not he's trying to equip us with the understanding that will help us navigate some of the crises that are ahead of us and something that some people call the [[metacrisis]] and he's one of the main people in the world right now who can explain it very clearly i'll try and break it up a little bit so that we can sort of go over some of the points again it's difficult to sort of [59](https://www.youtube.com/watch?v=6aKI2C61jVE&t=59.579s)

say what consilience project is in a few words because it has evolved over time to sort of confront the reality of what the world is ready to accept however it's certainly one of in my opinions the best attempts and very tangible attempts to help people navigate what's right now in front of us and the news cycle is certainly not [80](https://www.youtube.com/watch?v=6aKI2C61jVE&t=80.64s)

helping us understand it's so distracting our minds from the real things that are going on and um so daniel is one of these people out there who's working really to formalize the way that we can anticipate connect uh collaborate and work more effectively to solve problems that we are facing so daniel i think there's something that we should [108](https://www.youtube.com/watch?v=6aKI2C61jVE&t=108.06s)

know about your past and i'm going to be provocative if you didn't actually start out with the same objective you sort of thought that maybe we were doomed and that we had to accelerate doom in order to get somewhere i'm going to be very provocative so that you can explain your journey from a young man to where you are now [133](https://www.youtube.com/watch?v=6aKI2C61jVE&t=133.56s)

i was homeschooled and when i was nine i was at a gas station in a factory farming cattle truck pulled up and so i went and looked inside the holes the cow nearest me was missing its eye and bleeding all the cows were in terrible condition and uh i grew up loving animals eating meat from [[factory farm|factory farms]] not putting the two together and i was just kind of shocked and horrified by that asked my parents about it they said that's where animals come from so i asked to go to a [[factory farm]] and i started you know i became a vegetarian that day started working with pita and greenpeace and studying animal rights work that took me from the issue of factory farming to the issue of [[species extinction]] wailing overfishing the oceans which took me into the issues of the environment and that took me into global poverty and just kind of the whole set of issues as a young person i was fortunate being homeschooled that i got to just have that be my curriculum i was actually a um educational experiment my parents ran where i didn't have any fixed curriculum i just got a study what i was interested in so this became the context of most of my life study and the next really important part happened i was 13 i was working on a project at greenpeace and world wildlife federation were leading to protect elephant [214](https://www.youtube.com/watch?v=6aKI2C61jVE&t=214.379s)

poaching in a particular elephant preserve in kenya where the poachers had come in over the preserve and hunted a bunch of elephants i saw the videos of the elephant slaughter and was moved in the same way as the [[factory farm|factory farms]] and the thing i observed though was over the two years of the people on the ground working extremely hard to protect the elephants [233](https://www.youtube.com/watch?v=6aKI2C61jVE&t=233.879s)

there the strategy was get bigger fences around the preserve so the poachers couldn't get in and do legislation to get harsher sentencing for poachers in the area all the activists had their life threatened but they finally succeeded it was a huge win those elephants didn't get hunted but they didn't address the [251](https://www.youtube.com/watch?v=6aKI2C61jVE&t=251.099s)

poverty of the people that were doing the poaching they didn't address a macroeconomy that creates poverty at scale they didn't address the views towards animals or identity regarding them or black markets on animal parts so the same poaching groups moved to hunt other things which happened to be the white rhino and the mountain gorilla both of which were more endangered than [267](https://www.youtube.com/watch?v=6aKI2C61jVE&t=267.6s)

the elephant and i was working with enough groups that i got to see those other issues get worse as a direct result of the success of that project and then that was that was like the second existential hit the first existential hit with the [[factory farm|factory farms]] was and i'm saying this to relate that was the first time i had like a suicidal ideation around not feeling okay being [287](https://www.youtube.com/watch?v=6aKI2C61jVE&t=287.699s)

complicit with my species that my species was somehow fundamentally up and but as a kid i'm it wasn't that hard to realize if i kill myself all those cows are still in the [[factory farm|factory farms]] they didn't help them that's unethical but then i'm like if i stay alive to try to help it like couldn't can my life be a success well sentient beings are experiencing that [312](https://www.youtube.com/watch?v=6aKI2C61jVE&t=312.84s)

much suffering like what does it say about me that i can be totally stoked that my life is a success when other beings are in that kind of suffering i'm like there's no answer for me that doesn't address that so i remember thinking to myself then i'm like all right well if i die and [[factory farm|factory farms]] still exist i failed like there is no definition of success for me [330](https://www.youtube.com/watch?v=6aKI2C61jVE&t=330.84s)

that isn't a sociopath definition of success it has to empathetically separate uh too intensely but at least the hope came that like activism might work and so then when this thing happened where i saw that the activism for one thing made other things worse that was the next kind of devastation [349](https://www.youtube.com/watch?v=6aKI2C61jVE&t=349.5s)

and that led to me starting to look at how many other places where we were doing activism where the world was doing activism did that kind of issue and i saw that there were projects to solve global poverty by creating hydroelectric dams to bring electricity to areas in the hydroelectric dams of course drowned whole ecosystems and extincted species and on and on and kind of like it seemed [370](https://www.youtube.com/watch?v=6aKI2C61jVE&t=370.46s)

like the world was caught in these uh trade-offs where when they would focus on solving one problem it was too narrowly defined the result of solving that problem would have externalities related with larger systems i started to do kind of historical analysis on that and that became kind of a defining trend of all of the issues we we created the automobile to solve a transportation [394](https://www.youtube.com/watch?v=6aKI2C61jVE&t=394.979s)

issue which was that horses were a very limited means of transportation horses in the cities caused a lot of horse shed in places like london literally the excessive horseshit in the cities of london was one of the kind of like significant impetuses to make a horseless carriage and in solving that problem and creating transportation that increased mobility and comfort for the [413](https://www.youtube.com/watch?v=6aKI2C61jVE&t=413.34s)

whole world [[climate change]] like the venusification of the entire planet and oil spills and wars over oil in the u.s petrodollar like all of that were the side effects of solving a transportation issue you know a couple hundred years later and i got to see that there was this underlying deep issue that statecraft that is [433](https://www.youtube.com/watch?v=6aKI2C61jVE&t=433.02s)

thinking about the well-being of its own citizens the rest of the world so it's not just exporting its harm somewhere else and of the planet and there's a lot of countries where their genie coefficient meaning their measure of wealth inequality is pretty good within their country but they import a bunch of stuff to make their country function from countries that have the worst genie [451](https://www.youtube.com/watch?v=6aKI2C61jVE&t=451.38s)

coefficient so you can't actually do genie coefficients at the level of a country it ends up just being a way to kind of whitewash the reality of global [[supply chain|supply chains]] oh so the conscious statecraft thing so how how do you do what is good for your own country what's good for other countries and what's good for the planet when there are fundamental trade-offs [468](https://www.youtube.com/watch?v=6aKI2C61jVE&t=468.96s)

between them and you're stuck in those trade-offs that becomes really the deep challenging question if we look at [[climate change]] today we can see that for the planet and for all of us in the future we should not just decarbonize but degrowth we can also see that any nation that tries to lead that will do worse gdp wise in the near term which means worse [488](https://www.youtube.com/watch?v=6aKI2C61jVE&t=488.46s)

geopolitically and actually so much worse particularly for the leading countries like u.s and china uh change the control systems of the world so so many of the people in the u.s that are anti-[[climate change]] aren't actually anti-[[climate change]] because they did a good analysis of the ipcc science it's that the solution of increasing the price of carbon for us which will [509](https://www.youtube.com/watch?v=6aKI2C61jVE&t=509.46s)

decrease our gdp relative to china's gdp in a great power game which will increase planetary autocracy seems like such a bad solution that they don't want the [[climate change]] assessment because they don't want the solution that goes with it so um so that a part of the thing that i um focus on is how do we understand the interconnectivity and the generators of [529](https://www.youtube.com/watch?v=6aKI2C61jVE&t=529.74s)

all the issues deeply enough that we can come up with solutions that don't cause other problems and uh but one point was a little while after this i had come to i started doing forecasting on um how many people have read limits of growth the mit club of rome book so i read that as a teenager and then started looking at a lot of other analyzes on [550](https://www.youtube.com/watch?v=6aKI2C61jVE&t=550.56s)

[[species extinction]] and [[biodiversity loss]] and [[dead zone|dead zones]] and oceans and all those things and then i looked at the you know stephen pinker kind of stuff of everything's getting better a lot of people might have that question of like you hear stephen pinker hans rossling gates and like everything's getting better and then you hear all the environmental statistics and like [569](https://www.youtube.com/watch?v=6aKI2C61jVE&t=569.82s)

everything's getting worse they're both true you can cherry pick your stats but they're not equally true the things that are getting worse are leading to the unviability of human habitation ongoingly in a way that the things that are getting better don't converge on solving automatically so there's a real and the things that we're making better are causing the [591](https://www.youtube.com/watch?v=6aKI2C61jVE&t=591.24s)

things that are getting worse towards self-extinction points right like grow global gdp where we all have like nice stuff because of that in a way that breaks the biosphere's capacity to continue to make life possible so uh we have to do something deeper than saying it's getting better and worse so we just choose it's like the way that we make things get better is a [610](https://www.youtube.com/watch?v=6aKI2C61jVE&t=610.2s)

major part of what's making them get worse towards tipping points that are unique now to any point in previous civilization so when i was at 15 i came to the assessment that there was no chance that humanity would actually make it in time and that if we had radically less population we might have a chance and i started studying viruses and [630](https://www.youtube.com/watch?v=6aKI2C61jVE&t=630.6s)

depopulation strategies which is a thing that an angsty but earnest caring you know teenager might do i had a spiritual experience that took me off that path while i was working on it but like but i was seriously studying vector delivery of of novel pathogens and the spiritual experience was um something bucky fuller used to say and i [653](https://www.youtube.com/watch?v=6aKI2C61jVE&t=653.64s)

had heard it a lot but it hadn't hit me in the same way of that the chicken developing inside of a shell is totally unsustainable right it's eating the unrenewable resource to egg white it's creating metabolic pollution in its uh environment it doesn't even know that it's inside of a shell but it's in a developmental phase and of course there's it doesn't [677](https://www.youtube.com/watch?v=6aKI2C61jVE&t=677.459s)

have the beak or the gastrointestinal tract to eat seeds yet the whites are exactly kind of what it developmentally needs to go through that embryonic phase and right as it runs out of whites is as soon as it's gi track and beak and all the things are are developed to be able to crack through the shell and emerge into a world where now it's part of a new phase and and i started thinking [696](https://www.youtube.com/watch?v=6aKI2C61jVE&t=696.48s)

about humanity as being unrenewable because of being in a developmental phase or a discrete phase shift that doesn't that isn't the result of just a continuity of the previous lines and i thought about all the examples of caterpillar to chrysalis to butterfly and that in the chrysalis there's a fundamental dissolution of all the organs and a restructuring with a [717](https://www.youtube.com/watch?v=6aKI2C61jVE&t=717.6s)

different genetic code that if a fetus went more than 40 weeks in the mother's utero uterus it would kill itself and kill the mom but it has to go through that developmental period and then the birth is a discreet kind of difficult process and then the umbilical cords cut now there's a new developmental time and so i had this kind of profound experience that [738](https://www.youtube.com/watch?v=6aKI2C61jVE&t=738.3s)

developmental phases whether inside of an egg or in a chrysalis or in a womb are always unsustainable there is some discrete nonlinear phase shift that is different than the curve in the developmental phase and will be different afterwards and i started thinking about if humanity was in a humanity as a species was in a [760](https://www.youtube.com/watch?v=6aKI2C61jVE&t=760.62s)

developmental phase and there was a discrete phase shift that was different than the curves what that might look like but that got me off of the track that thomas was bringing up but what's really interesting is a lot of my work now involves the way that [[exponential tech|exponential technology]] equals exponential a decentralized [[catastrophe weapon|catastrophe weapons]] for everyone whenever we talk about the positives of [[exponential tech]] ai biotechnology nanotechnology cyber technology we talk about in positive terms usually like the democratization of this great technological power of creation but the democratization of [[catastrophe weapon|catastrophe weapons]] is actually not a great idea right like keeping nukes to [806](https://www.youtube.com/watch?v=6aKI2C61jVE&t=806.519s)

the g8 you can do because it's really hard to make nukes and you can see who's making nukes and there's not that many places that have uranium and enriching uraniums hard and you can see it from outer space but it's pretty easy to make drone weapons and it's increasingly becoming easy and the ability to use those for infrastructure targets and specifically it's becoming pretty easy [826](https://www.youtube.com/watch?v=6aKI2C61jVE&t=826.82s)

to make pathogens in the advancing of synthetic biology we're only a few years away from the ability to synthesize novel pathogens on a desktop for a thousand dollars anywhere and so when i was a kid that was not true it took it was actually like a hard thing to do it's becoming an increasingly easy thing to do well increasingly more people are feeling [847](https://www.youtube.com/watch?v=6aKI2C61jVE&t=847.019s)

kind of concerned and disenfranchised so as the group of people that would be motivated to uh change this [[world system]] in harmful ways and the group of people that are capable is converging and increasing there's a lot of risk associated with that how do we deal with that that's a interesting part of the topic i'm really excited that you didn't turn [869](https://www.youtube.com/watch?v=6aKI2C61jVE&t=869.279s)

out to become a terrorist s it wasn't motivated by not liking people it was motivated by seeing self-induced human extinction is inevitable and as that as being the only way out it was and that's actually like most terrorists are well motivated you know they're motivated they're motivated in service of something they care about that they [887](https://www.youtube.com/watch?v=6aKI2C61jVE&t=887.639s)

feel is being harmed and they don't know other solutions well we could agree but i'll i'll pause on that one um i think what a lot of people here are are probably expecting if you have heard anything about daniel is you present a little bit about the [[metacrisis]] so there's a framework of thinking around [906](https://www.youtube.com/watch?v=6aKI2C61jVE&t=906.0s)

how we can put dots in between a lot of the crises that we're facing collectively and instead of addressing one and creating externalities in another problem set perhaps understanding the total problems at the same time and before you act actually you have a more enlightened perspective gives you more edge so that's an assumption and a hopeful one [930](https://www.youtube.com/watch?v=6aKI2C61jVE&t=930.6s)

and some people might argue that we need to act very fast on certain issues so they don't really like this sort of temporization of it but i'm of the belief like you that basically having better tools to understand the world we live in is essential for us to make you know critical decisions and i would love for you to spend a moment unfolding what you call or what we call the [[metacrisis]] and why it's unique to this moment in history and why humanity you know has to put some effort towards solving that concretely or we will probably end up in a pretty bad place very quickly so it could easily seem like the stuff that i'm talking about is just the collection of all the worst news in one place i would bother sharing it because i think it is true [976](https://www.youtube.com/watch?v=6aKI2C61jVE&t=976.38s)

the risks that we're talking about are true uh it's not determined that we definitely fail at them or that we definitely succeed at them so what we do actually matters in determining it and there's no chance that we can solve it if we don't more competently understand it so more people competently understanding [997](https://www.youtube.com/watch?v=6aKI2C61jVE&t=997.82s)

and seriously working to apply themselves to the unique needs of this particular time in the world is something that i'm hopeful for and i guess that's why speaking here and said yes to thomas inviting me here um so the [[metacrisis]] frame might actually help deal with some catastrophe fatigue because rather than see [1022](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1022.16s)

the issue of drones and autonomous weapons and the issue of [[exponential tech]] empowered terrorism and this [[planetary boundary]] issue and this pollinator issue and this forever chemical issue is separate issues i look at them all as expressions of a interconnected set of generative dynamics that we call the [[metacrisis]] where what it takes to solve any of them is the same actually and if you try to solve them without factoring these deep underlying generative dynamics you will at bet you probably won't solve it and if you do you'll displace problems somewhere else and actually kind of mess the whole thing up so when you understand that all those problems are connected at first it makes [1063](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1063.5s)

it seem more overwhelming because you're like to think about [[climate change]] i also have to think about geopolitics and fundamental changes to finance and all these other issues and that seems like a lot of complexity but it actually takes it from too many problems to tractably manage all of which have solutions that end up externalizing harm elsewhere which means impossible too [1083](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1083.12s)

hard but tractable so hopefully in terms of being able to see it all as one interconnected set of issues you're like all right there's a lot of there's a lot more learning that i need to do to be able to competently engage but there is actually a way through there's actually kind of a tractable analysis so that's what i hope to share so if you can move towards what people call the [[third attractor]] or that you like to call the [[third attractor]] so that we sort of gravitate towards a landscape of defining what is the solution environment that we want to find ourselves in because obviously you know there are a lot of people who are very competent who are deploying intelligence and capital and being very innovative [1125](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1125.66s)

about what they do but they sometimes miss the fact that they are creating really negative externalities in other let's say problem sets so the third attracted to me seems like a very easy thing to understand for people even though if we don't have the answer to what the [[third attractor]] is but it's at least theoretically a framework for understanding why the [[metacrisis]] may find a solution set through the retractor yeah let me give an example though of how we solve problems and make worse problems that are current and really relevant we're working to try to change currently uh u.s federal government program and have had some really good success with it for pandemic prevention for preventing whatever the next pandemic from animal sources do [1168](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1168.38s)

noticed spillover would be and the federal government and it's not only the us lots of countries employ this approach us has been leading the way in what seems like great science and technology and innovation towards preemptive problem solving which all seems like the right thing but the approach to uh uh preventing zoonotic spillover [1187](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1187.64s)

involves viral hunting so going out and finding tens of thousands of new viruses and bat caves that have mammalian viruses that have never been exposed to humans before bring them back to labs doing gain of function research on them to figure out how to how they might mutate into things that are more virulent or transmissible and then publishing all those genome sequences to [1207](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1207.799s)

an [[open source]] database so everyone who wants to work on vaccines has access to the knowledge it seems like a decentralizing information democratizing multi-state coordination science anticipatory good thing and it's maybe one of the worst things happening in the world and so we're lucky that we've been able to shift it uh if you [[open source]] publish all of the pandemic grade viral gene sequences in an age where gene synthesis is becoming extremely cheap that we're about three years out from tabletop gene drives and crispr and like that the you know bioterrorism potential of that is just unimaginable and even just the accidental kind of lab leak dynamics that when you have enough labs working with enough things the probability that [1251](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1251.84s)

none of them happens drops towards zero over enough period of time there's a lab doing gain of function research that figured out how to make an extremely virulent version of h1n1 like an r naught of 18 h1n1 is like a 60 fatality rate and it did that in a [[biosecurity]] level 2 lab so lab leaks happen right like this is an example of trying to do the right thing but not understanding [1273](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1273.44s)

the [[problem space]] well enough and doing something totally that's the wrong thing and and what i remember the first time i was engaged in the un network it was a project with world food program when i was 20 the solution to world hunger involved bringing conventional npk based agriculture to the developing world so we didn't have to send food over there [1292](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1292.94s)

and the answer was way more nitrogen and phosphorus affluent into the rivers that would cause faster [[dead zone|dead zones]] in the ocean and so i talked to the guy about it and i said you realize you'll speed up the rate of [[dead zone|dead zones]] in the ocean catastrophically if you do this and he said i hadn't thought of that but those aren't the metrics i'm tasked with and those aren't the metrics i'm tasked with so i'm gonna for a few years decrease hunger while working to extinct the planet because that's what my accountability is like it just became very clear that that problem-solving approach was ubiquitous and so another great example is you look at the advancement of something like um gene editing crispr it's being advanced [1332](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1332.9s)

for purposes we all want like immuno oncology how do you change 15 000 genes at once to be able to you know cure and prevent cancers that were genetically predisposed to but all technologies or dual purpose or multi-purpose meaning every technology that you can make for some positive purpose has a military or otherwise weaponizer kind of externalizing [1354](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1354.62s)

application so uh the research that's being done on how to do that type of gene editing is making it then really cheap and easy once it once we figured out how to do it it takes major universities that have ethical review boards to do it for that purpose to develop the technologies that then drop the price by orders of magnitude to do it for any purpose and it's open [1376](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1376.64s)

publishing so to give a little bit of history because some people might think well people have been predicting uh rapture since the 1600s there's always some kind of like mayan 2012 whatever and this is just new catastrophism i would really like people to think more deeply about what is discontinuous and novel in this time [1397](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1397.419s)

relative to other times so i want to argue that real quick the first technology we had that was powerful enough for humans to actually make the planet meaningfully uninhabitable was the nuclear bomb in world war ii that was the first truly existential technology it was not an [[exponential tech|exponential technology]] meaning nukes don't automatically make better nukes in [1417](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1417.2s)

the ways that computers automatically make better computers computation allows us to design better computer chips recursively you get moore's law but um but it was the first existential technology and that was really a break from the history of the entire world of tech up until that point because up until that point every new military tech that we had there was an absolute [[arms race]] to deploy it as quickly as we could and to win more battles and territory based on deploying it this was the first one where we actually had to make an entire [[world system]] to ensure we would never deploy it because nobody would win [[mutually assured destruction]] and all of a sudden you're like whoa we're so big that we can't actually deploy our tech without destroying everything right we [1457](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1457.28s)

can't actually do this versus them effectively anymore at that level and so post-world war ii and we haven't had another world war that is kinetic between superpowers yet and we're at the brink of it right now right um post-world war ii because of that tech we rebuilt the entire global [[world system]] to deal with preventing kinetic world war iii and that kind of [[bretton woods]] uh [[world system]] igo [[world system]] has been effective at preventing world war iii but that [[world system]] is almost totally broken down now and it drove all of the [[catastrophic risk|catastrophic risks]] we're facing currently so specifically one part of the post-world war ii system was a international monetary system [1502](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1502.94s)

that created that had [[exponential growth]] of gdp why is [[exponential growth]] of gdp important is because the wars are based on everybody wanting more stuff and if you don't have [[exponential growth]] of gdp the best way to get more stuff is to take somebody else's stuff if you have [[exponential growth]] of stuff everybody can have more stuff without taking other stuff roughly or at least in major [1521](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1521.9s)

nations don't have to take each other's stuff they can do it through colonialism or vassal nations but [[exponential growth]] of gdp is comprehensively bad for the environment right like that all of that growth of gdp equaled it's there's a there's an important uh thing called the garrett relation that shows a one for one correlation between energy used and [1543](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1543.26s)

global gdp global energy use and global gdp it's a it's a 99 correlation actually meaning that the increases in efficiency of energy generation only give you about one percent change of more dollars per joule per year um but for the most part [[exponential growth]] of gdp equals exponential energy demand so [[climate change]] and exponential gdp are exactly correlated and all of [1566](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1566.6s)

that money gets used in a [[materials economy]] a [[supply chain]] that's a linear [[materials economy]] that through mining logging phishing etc is unrenewably taking stuff from the earth on one side turning it into we use for a little while and making it into trash and pollution on the other side you cannot run this is like so obvious but you cannot run an exponential [1586](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1586.4s)

[[financial system]] on a linear [[materials economy]] that has to be coupled to it on a finite planet forever so you start to hit [[planetary boundary|planetary boundaries]] right so what decreased us having likelihood for war moved us towards [[planetary boundary|planetary boundaries]] on all the [[planetary boundary|planetary boundaries]] we said we can all have more stuff without taking each other's stuff by taking all the  from nature as quickly as we can so [1608](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1608.96s)

this was obviously not that smart for our own long term and now we're now we're there where we're actually bypassing some of the [[planetary boundary|planetary boundaries]] critical tipping points already there is a paper published a couple months ago in the american uh chemical society journal that said the planetary tipping point on certain environmental pollutants particularly [1629](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1629.659s)

floral surfactants had already been passed meaning rainwater all around the world in very remote areas contain these pfos forever chemicals beyond epa safe levels that means that if you're gathering rain water in the middle of nowhere for your off-grid sustainable thing it has beyond epa levels of carcinogen neurotoxin endocrine disrupting chemicals everywhere no [1652](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1652.64s)

matter where you are on the planet because we've put that many of them into the environment already and an exponential [[financial system]] means an exponential amount of pollution mining etc and um so the [[metacrisis]] what happened for me was like all right well if i have to if we have to address [[factory farm|factory farms]] but then should we also have to address overfishing we have to address what is the problem set what is the actual problem set that we have to face how do we make sure that when we're addressing it we don't cause other worse problems so how do we understand the interconnectedness i was always asking if we were to actually try to rebuild the world from scratch with 21st century [1689](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1689.96s)

problems and technologies and capacities that actually worked with the biosphere and [[human nature]] how would we do it and then what does enactment look like to get there given all the vested interests and issues in the current [[world system]] uh so you were mentioning [[third attractor]] [[third attractor]] roughly is there are two futures that we want to avoid well mention the first and the [1713](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1713.299s)

second first yeah so that people can understand the sort of negative image of it um but maybe just before you go there just maybe explain um what you really think you know if there's a takeaway you know what's absolutely different about this moment in history for mankind yes you've kind of said it in a roundabout way which is [1731](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1731.36s)

explaining the sort of crumbling of the bretonwood's [[world system]] um and you know that a lot of the solutions that we're trying to put forward actually generate you know bigger problems that we can possibly face and in many instances and we can talk about you know the situation of the [[arms race]] between china and and the us with ai or biotech for example without [1753](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1753.62s)

even talking about road actors that are in garages um but i think you if you can sort of map this a little bit because i think that it's helpful for people to see their place in history okay so i was saying that the first existential tech was the bomb we built a [[world system]] to deal with that but so one of this answers to that [[world system]] was the global [[financial system]] which has driven us to uh all of the [[planetary boundary|planetary boundaries]] that we currently face [[planetary boundary]] is a good way to put all the environmental issues in one place so when we're talking about [[dead zone|dead zones]] and oceans uh overfishing [[species extinction]] loss of pollinators uh [[climate change]] ozone all of those are basically places where the human social [1795](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1795.86s)

sphere technosphere complex is incompatible with the biosphere but that means we're debasing the substrate that we depend upon that means it's a system that's [[self-terminating]] you cannot debase your own substrate forever one of the other parts of the post-world war ii system was globalization and these radically interconnected six continent global [[supply chain|supply chains]] that are necessary to make this microphone or these speakers or anything one of the downsides of that we've seen during covid is the radically interconnected [[supply chain]] the benefit was you're less likely to bomb somebody who you depend upon for fundamental [[supply chain]] purposes this is one of the big benefits of globalism so the localism movement if you were really [1836](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1836.0s)

successful at localism there's actually less investedness in the other guy over there when i don't actually depend upon them so these are some of the tensions we have to factor of okay do i want to make everything local or do we want to actually have interdependence on them but if we have it all global then we get these cascading fragilities of where you can have an issue in wuhan and get [1854](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1854.179s)

[[supply chain]] shutting down all around the world which then means you don't get the movement of pesticides and fertilizers for the agricultural system in iran and northern africa that probably put more people into radical food insecurity than we're totally at risk from covid and it's like so you can see how the the those post-world war ii situations gave [1873](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1873.919s)

us this world of high interconnectedness but very high fragility and then high planetary fragility and then also the exponential [[financial system]] meant the growth of [[exponential tech|exponential technology]] um you know speeding up commerce and the key thing to understand about that is that uh we don't have one technological weapon of mass destruction now we have [1897](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1897.799s)

many and in the world war ii system the [[mutually assured destruction]] system you had one [[catastrophe weapon]] and two actors that had it so you could create a system of [[mutually assured destruction]] where neither one could utilize it we currently have a world where you have dozens of [[catastrophe weapon|catastrophe weapons]] if we include all of the types of not only weapons of mass destruction but [1918](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1918.919s)

the ability to take out [[critical infrastructure]] and in a highly connected [[supply chain]] system we have dozens of [[catastrophe weapon|catastrophe weapons]] with not just many state actors but non-state actors having access to them so you can't put some [[mutually assured destruction]] system on it so it's like how do we make it through this much [1939](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1939.26s)

distributed technological power with the current incentive systems so if you if you want to look at what is unique to this period of time humans have been here for roughly 200 000 years biologically identical you know two million years of hominins with tools we didn't reach the first billion people until 1815. [1961](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1961.399s)

right we were less than a half a billion people for that entire history and then uh with the [[industrial revolution]] and liquid nitrogen fertilizer we went from half a billion people to 8 billion people almost overnight we simultaneously increased our energy consumption per person and our total resource consumption per person exponentially so we exponentially [1985](https://www.youtube.com/watch?v=6aKI2C61jVE&t=1985.52s)

increased the number of people and the consumption of resource per people per person and um this does bring us so for the for the whole history of the world we did not have the technological power to quickly destroy everything like nukes or even to pose a threat to the biosphere as a whole that is only the result of [2008](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2008.74s)

post-industrial and now particularly post-layed industrial technological capacity really important thing to understand is you know as a species we because of tool creating were able to move from early environments to other environments in a way no other animal could and become the [[apex predator]] in every environment so when we over hunted an environment [2031](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2031.059s)

every a lion can't increase its predatory capacity radically faster than the gazelles can because predatory capacity only comes through genetic evolution which is very slow over time and there's co-selective pressures with [[tool making]] we were able to increase our predative capacity through a different process that wasn't genetic evolution radically faster than anything else [2051](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2051.76s)

could increase its resilience to our predative capacity so we could over hunt an environment then rather than have our population fall back move to a new environment and so we've actually been on the beginning of a [[self-terminating]] path for a very long time it's just an [[exponential curve]] that looks like this and the first major bump was agriculture [2069](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2069.599s)

and then the next major bump was the [[industrial revolution]] and then it's been verticalizing and um so regarding earlier civilizations though we are we didn't have the technological capacity even in aggregate to mess up the biosphere but we did have the technological capacity to mess up our own local [2092](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2092.379s)

environments and that's one of the main reasons early civilizations died if you actually read the collapse of complex societies by joseph tainter reread um jared diamond's book on it many early civilizations actually died because they created topsoil erosion from bad agricultural practices cut down too many trees and stop being able to feed their people so [[civilizational collapse]] from overuse of the environment is actually a multi-thousand year reality um and if you think about early civilizations one of the first insights you'll have whether we're thinking about the ottoman empire the egyptian empire the roman empire is that none of them still exist so it's actually the precedent of [2133](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2133.0s)

civilizations to have a life cycle and to fall but most of them fall for from internal [[self-terminating]] causes either environmental ones or even if they lose a war to someone else very often they lose a war to a smaller foe than they had defeated during their peak because internal decay and infighting happens from generational [[institutional decay]] so self-induced purposes make civilizations [2154](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2154.859s)

break down so uh [[civilizational collapse]] is actually the norm right that's the first thing that's important to understand it's just it was always a local phenomena this is the first time that we really have a global civilization in terms of the [[supply chain|supply chains]] that we depend upon to meet our fundamental needs and so we're in the process of a breakdown of this [2176](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2176.56s)

civilization but what that portends in scale and what it portends to be having the biospheric the the ecological effects but at a biosphere level is totally unprecedented and what i would also say is that our solutions to the previous problems because there's this nice narrative that they've always been problems but we always come up with solutions and necessities the mother of [2197](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2197.26s)

invention and we'll figure our way out of this and then we get to live to solve new problems and that's kind of true but it is also true that the problem-solving process we have employed is actually drives larger problems and you get to a place where those problems are actually beyond the scale of what the biosphere can handle in human capacity and so you actually have to have a different [2219](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2219.04s)

problem-solving process so if you think about making a technology to solve a problem or a business or a law to solve a problem you define the problem in a narrow like this viral issue or like a transportation issue or whatever it is you define it in a narrow way there's one or some small number of metrics you're trying to change and you create a [2237](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2237.76s)

technology or a law or a business or a non-profit to produce a first order effect meaning a direct effect to solve that problem but it interacts with ecologies and societies and psychologies which are complex and it has second and third and fourth order effects on a whole bunch of metrics that aren't even identified and that's where the harm ends up being externalized so the [[metacrisis]] that we face currently and we we can talk about very specifically uh what the [[generator function|generator functions]] are but if we look at all of the [[planetary boundary|planetary boundaries]] from [[species extinction]] to [[biodiversity loss]] writ large to nitrogen and phosphorus cycles to [[climate change]] and ozone all of those are the result of a financial an exponential [[financial system]] coupled to a linear [[materials economy]] hitting [[planetary boundary|planetary boundaries]] it's right so so you have to fundamentally make the [[materials economy]] go [[closed loop]] and the [[financial system]] has to stop being exponential which means a post-growth [[financial system]] that's a really really huge li lift to get from here to there um and then when we look at all of the issues associated with externalization [2308](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2308.079s)

from [[exponential tech]] how do we steward the power that [[exponential tech|exponential technology]] gives us safely does require a totally different level of consideration of like yes i'm making this amino i'm doing this genetic modification science for cancer purposes but as soon as i've done it it now becomes cheap and easy for designer babies and every other kind of purpose so uh how do we kind of mytho poetically [2334](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2334.599s)

say if no other no other animal had the ability to extinct species at scale or destroy ecosystems or genetically engineered new species so this is not the power of [[apex predator|apex predators]] this is the power of nature or the power of gods if we have the power of gods and not the love and wisdom of gods to steward it we don't make it so to make it through this technological kind of adolescence what [2359](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2359.02s)

is the what is the infrastructure that can make it and what is the [[social structure]] and culture that are required to be able to guide that our core interesting questions so you've very eloquently defined how good we've been for a long time at being [[self-terminating]] civilizations and we've scaled it to the planet now so um i [2380](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2380.56s)

think you know to go back to my my question around um the first and second attractors and then the third maybe browse very quickly on the first and the second because there's a whole theory around that um but there's a theory of change which you're proposing through the [[third attractor]] and i think that's you know where there's hope and not only hope [2402](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2402.22s)

it's sort of a story of collective ingenuity that has to unfold and unfortunately you have to go through a little bit of a difficult phase to appreciate the complexity of the problem with the new set of eyes before you can do so effectively so that's how the lens of the [[metacrisis]] is useful because you can't get to that through the tractor before you've understood that yeah so [2424](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2424.72s)

could you maybe just go quickly over the two thirds of tractors and then the third one that will give us a little bit of a glimpse of hope if we just think about if you can build some gene synthesis in your basement cheaply with no exotic materials if anybody can build gene synthesis in their basement how does the world make it through the [2452](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2452.44s)

district that technology being a distributed capacity if you think about it for a while the answer almost everybody comes up with is it can't so that can't become a distributed capacity okay so we have to make it to where the companies that make the gene synthesizers are regulated what about the diy version that makes it [2475](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2475.72s)

on the internet well now either we have to control information on the internet and some kind of so who does that that can radically control the information or we have to know what people are doing in their basement some kind of ubiquitous surveillance uh this is some of the thinking behind the iot and sesame credit system in [2494](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2494.099s)

china is actually not stupid thinking it's forward thinking two distributed [[exponential tech]] and how do we deal with that so you can see that the solution to preventing a catastrophe can be a control mechanism that can look like a [[dystopia]] so the two attractors that i say we want to avoid are catastrophes on one hand and solutions to catastrophes that involve being able to keep those [2517](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2517.3s)

from happening which requires both optics of what's happening and the ability to prevent it which sound like control mechanisms which become dystopic and so right now and one thing i'll say about the catastrophes is you have you have to look at the cascades between all of them together to make good sense of it if you look at [[exponential tech]] as one category and environment is another and war is another and [[supply chain]] and electrical grid separately you'll miss the way it actually happens so when does [[climate change]] become a [[catastrophic risk]] well you're talking about like the venusification of the planet or the drowning of coastal cities or something like that long time before that happens extreme [2556](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2556.72s)

weather events that start to hit high population density areas and cause human migration can cause escalation to world war iii right so you think about the extreme weather events in australia it was just very fortunate that that was low population density low total population area you look at the droughts in syria that cause population movement and did [2576](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2576.579s)

cause a war what if you look at the temperatures that pakistan and bangladesh and northern india have been starting to hit during the summer and just say sometime in the next few summers you get past a temperature where the crops fail and they don't actually have stored crop a lot of it was destroyed during covid they don't have [2601](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2601.42s)

groundwater when you're in a 50 celsius heat wave but you're talking about an area that has 100 million people now as opposed to a very small number of people what happens does that does the resource war fall along muslim hindu lines does that lead to an india-pakistan war so with [[climate change]] you're not looking at [[climate change]] just as a problem itself but it is a force amplifier of [2623](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2623.26s)

the other problems and you have to look at all of them that way so there's a lot of different entry ways to catastrophic collapse and we're seeing some of them right now um and so one attractor is increasing catastrophes the other meaning a likely path the world goes another attractor is the [2641](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2641.56s)

world recognizing that and saying we have to keep that from happening so we have to actually deal with [[climate change]] through pricing carbon properly and degrowth but that is really bad for a lot of people because as soon as you make carbon more expensive you make all the commodities more expensive which hurts the poor people the fastest and [2663](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2663.64s)

um on and on and everyone who doesn't want that do you use violence against them and so to to prevent certain things ends up meaning control if what if currently human behavior is doing that and so how do you prevent increasing dystopias which we a lot of people think the chinese state is you know in the direction of so [2683](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2683.2s)

a desirable future is a future that doesn't self-terminate and that doesn't have unchecked centralized power structures the question one of the causes of the increase in nationalism is the distrust in globalism and one of the major reasons of the distrust of globalism is the idea that unchecked power doesn't have a good history and so the idea that we at least keep power [2706](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2706.839s)

checked in a multilateral way is preferable for a lot of people but if you have many different nations that are in economic competition with each other nobody wants to price carbon properly because if the u.s does it'll be radically disadvantaged relative to china as a result china's belt and road will geopolitically dominate the world and crowd out you know democracy and [2728](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2728.56s)

those types of things and so if you have nation-states in competition with each other they just can't deal with global issues well if you have [[global governance]] who's creating a check on that power system where it can't be captured or corrupted so i would say thinking in terms of the design criteria we need has to be able to do [[global governance]] it has to be able to deal with things like decentralized [[catastrophe weapon|catastrophe weapons]] in basements but it also simultaneously has to have checks and balances on every power system or every control system that are there that are adjudicatable it would take me a long time to describe what i think the best process is for how to do that are i will say that there are [[world system|world systems]] that there are technological systems that could be enacted that meet these criteria that align with [[human nature]] so i am i am optimistic about that the enactment to get there takes a lot of work so just briefly mention the [[third attractor]] i'll move afterwards towards you know some hopeful scenarios that we might encounter so that you know people don't leave this room with a [2795](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2795.819s)

sense of fear and catastrophe as being dominant but you know like there is there's a real in order for us to create a [[third attractor]] we have to put some energy towards developing one and that's not a simple thing to do but first we have to understand what it is and how that could drive us away from those two attractors you know decentralized catastrophic capability and you know a [2818](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2818.619s)

centralized capacity to control on you know which is kind of dystopian foreign there is not a term there's not like a term for a type of [[political economy]] or system that makes that [[third attractor]] and we actually don't know so specifically what i mean by the [[third attractor]] is literally something that is [2843](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2843.16s)

can prevent all the catastrophic possibilities where the control mechanisms required to do so have the types of checks and balances that they prevent uh centralized power issues so we're actually defining in terms of what it isn't right it's not catastrophes and it's not that the solution of the [2865](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2865.18s)

catastrophes involves dystopias exactly what that looks like there's both how would we design it from scratch which is a nice question but it ends up being kind of a nonsense question because we don't get to design it from scratch there's this enactment issue of with all of the vested interests that the world currently has in play how do we actually get there so i can give you a few [2885](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2885.579s)

examples of things that give the sense of what can make a [[third attractor]] possible um so i'm i'm just going to mention one which i think you'll probably refer to we have a common friend in will marshall um were you going to mention planet labs i wasn't but we can't okay well i mean so planet labs you know i'll let you talk about it but effectively i think [2904](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2904.72s)

it's interesting to see also that some of those third tractors reside in the domain of intelligence plus or human intelligence plus technology applied to a new level of what you've actually yourself called forced transparency and you know that probably is not it doesn't define exactly what the thorough tractor is but it's sort of you know hopeful way of [2925](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2925.48s)

looking at technology that can constitute a uh an underlying let's say conversation between different actors whether they're state or civic actors or technology bodies uh that can start to formulate more of those so i think we both agree that there needs to be a proliferation of these examples um and open and force transparency is a really important tool because we've got [2947](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2947.859s)

very weak international governance and law yeah so maybe you can address the [[third attractor]] by giving some examples yeah so market forces like incentive by itself doesn't solve all the problems uh so you end up having to use both incentive and deterrent there if we didn't have law protecting national forests we wouldn't have national forests you'd have market [2970](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2970.839s)

forces that um continue to turn everything into commodities um but as far as international law it's tricky because law most mostly exists where you have a monopoly of violence that can enact the law a police state inside of a nation-state so where we have global issues like the oceans or the atmosphere this is where we have a really tricky time [2993](https://www.youtube.com/watch?v=6aKI2C61jVE&t=2993.94s)

because uh how do you if you're going to make a law it requires multinational agreement and then the ability to see if it's being violated and then the ability to enforce some enactment and the ability to enforce it where it's not more expensive to do so than the benefit you get right so let's say that we have an agreement [3013](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3013.92s)

about oceans and china is violating it and so we say okay we're going to sanction you for that like how but the sanction is on a [[supply chain|supply chains]] that we depend upon and if you escalate they also have nukes so it's like there's a tricky thing with all that but one of the places where a lot of environmental issues uh global environmental issues don't get legal [3036](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3036.66s)

support is where we just don't even know what's happening it's hard to know what's happening in the middle of the amazon it's hard to know what's happening in the middle of the open oceans so this particular example is where a technology can be repurposed in a positive way there's a satellite imagery of the earth is a [3054](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3054.0s)

pretty amazing technology there's a friend of ours who runs a company called planet labs and they image the entire surface of the earth every day 30 terabytes of compressed data but they're increasing the spectral and temporal resolution of that and spatial resolution sets that it'll be pretty much real time human level video capture of the surface of the earth in about [3074](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3074.22s)

three years which is amazing and one of the things it means is the ability to see where logging is happening and where mining is happening and where dumping is happening and where legal phishing is happening and even to be able to see in a [[dead zone]] in the ocean the effluent how much of it came from which source how much came from which port and all those types [3093](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3093.72s)

of things the ability to see all that use machine learning to process it means that there's a whole bunch of international law that we've never even bothered to create because it'd be no way to know if it was being violated or enforce it now we'd have the ability to create international law that says no we actually you don't have [[plausible deniability]] anymore we know exactly how much of the trash or the nitrogen affluent came from there because we can see the whole thing um it also has the ability to do spectral analysis that can see an invasive species entering in an area or um soil microbes in an area to be able to actually support the environment when critical issues are starting to happen [3132](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3132.18s)

but this is itself very concerning because you probably many of you even as i'm describing this are like wow that's really hopeful for the environment to be able to have that level of transparency that could create law so we could support the environment but who gets to have access to video level data of the entire surface of the earth all of the time that sounds like pretty [3150](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3150.96s)

massive surveillance capability which it is so that can prevent certain catastrophes but can totally create dystopias depending upon how it's managed so how do we create the governance of that information such that it doesn't get used for uh nefarious purposes and that people get to know what it's being used for this is this is not trivial right because it's easy to [3172](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3172.38s)

deploy the technology to solve those problems it's actually quite hard to create the governance to ensure that it's used properly what the official version that will gives me is that it's 50 centimeter resolution so you can't see your face it's easier to count trees and cars and tanks in ukraine when the russians pretend that they're leaving a certain [3193](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3193.02s)

battle area um but let's agree that you know that power is something that needs to be at least checked so um what i guess i was trying to get at is there is some hope in terms of how we can leverage technology in order for us to sort of monitor um and then have some checks and balances and also create the [3215](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3215.04s)

international agreements and legal frameworks to enforce some form of yeah limits if you want to call it that but i know something i'd like to say is there is a naive techno-optimism that i think is super dangerous that just tech will solve all the problems um and the very worst version of it is we're only a few years from generalized [3238](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3238.5s)

ai and then that'll be able to solve all the problems if you study the alignment issue of how do we ensure that truly generalized ai is aligned with our interests it's a really really tricky problem there's also a naive anti-tech a kind of naive luddite perspective that's like man all these problems are because of excessive tech quality of life is [3260](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3260.04s)

actually better at a lower level of technology let's get back to the land and [[permaculture]] and that kind of thing but if you study the history of the world anytime there is a intersection of a less technologically advanced society with a more technologically advanced society it doesn't go well for the less technologically advanced and so the china tibet type interaction [3279](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3279.68s)

always happened and so you you whatever group of people are saying we're going to do the less technologically advanced will not actually influence the direction of the way the future goes because the technology is power which does mean influence so the future will be high tech but it has to be also high nature and high connectivity or it will self-terminate so you have to say we [3303](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3303.72s)

don't get a put the pandora's box of tech closed but we have to actually become wise stewards of it so what does a high-tech high nature high connectivity future actually look like and if we don't have the technological capacity for outsized influence over the current systems the current systems will be what dominates um and so i am a techno optimist but not a naive techno optimist meaning i know that all the [[existential risk|existential risks]] we couldn't do without text stone age people cannot destroy the planet so like i'm acutely aware that all the [[catastrophic risk|catastrophic risks]] are results of human activity extended through technological levers but i'm also aware that the solutions to those things can't avoid [3345](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3345.54s)

technological elements but the technology alone is not sufficient so one way we think about this there's a anthropologist named marvin harris and he said you can think about civilizations as these triples of what he called the infrastructure the [[social structure]] and the [[superstructure]] the infrastructure is the tech stack that the civilization depends upon and meets [3367](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3367.2s)

all of its needs with the [[social structure]] is the collective agreement field so economics governance law and the institutions and the [[superstructure]] is basically the culture the values the identity the definition of what the good life what we're motivated by are he particularly argued that they are interconnected but the tech changes in tech drive the other ones and [3390](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3390.3s)

he gave a heap of examples from the plow to the wheel to on and on where the where a change in tech meant that whoever used that tech now they're behaving differently right driving a plow is a different set of behaviors than hunting the that the but the no tech catches on if it doesn't provide adaptive advantage if it does provide [3411](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3411.24s)

adaptive advantage it changes pattern of human behavior by using it as a pattern of changing by changing human behavior you also change human values and then everybody else has to adopt it or they lose in war to whoever has that increased adaptive advantage so he basically said cultures and political systems change because tech changes there are other [3433](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3433.14s)

deep anthropologists and sociologists who say no actually and give a heap of examples of how cultural changes make us innovate in different ways aligned with our values or have us bind our technology like the sabbath or things like that and say that cultural changes are the deepest and then there are plenty of others who say no ultimately the economy and law is the deepest thing [3453](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3453.54s)

because ultimately whatever you incentivize financially is what the is the technology that will be developed if you change the subsidies and the taxes and the incentives the tech stack would evolve differently i would say that all three of these the infrastructure the [[social system|social systems]] and the [[superstructure]] culture are equally fundamental and inner affecting and you have to think [3473](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3473.16s)

about changes to all three simultaneously so if you dismiss any of them out of hand like our cultural changes don't matter that much or technological changes our government does and you're definitely not thinking comprehensively but if you have a favorite one like we can just do culture change and everything else will [3490](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3490.559s)

automatically happen that's also not thinking comprehensively they're all necessary and only thinking about them together and the way they intereffect each other is sufficient so we could think about if we want a future that avoids all these catastrophes what is the infrastructure have to look like pretty quickly we can say we can't keep using nature unrenewably and turning it [3509](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3509.22s)

into pollution and waste unrinobily so it has to look [[closed loop]] and it has to look postgrowth because you can't grow it exponentially on a finite planet so what types of technologies would mediate that and what things should be global and what things should be local has a lot to do within the [[social structure]] interaction of there are things that you [3526](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3526.079s)

want to be global in so long as you're wanting to bind the well-being of those people to each other through [[supply chain|supply chains]] and interdependence and that kind of thing um what would the [[social system|social systems]] of a future look like and what would the culture there have been conversation today around in-group out group and identity systems [3544](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3544.859s)

um that's culture questions right i think there's a lot of probably focus on the well being picture here at harvest in a spiritual picture of uh planetary identity and obviously the planetary identity has to be not just humans but all life forms because you can advance all humans at the expense of the biosphere for a little while but then it goes pretty badly for the humans [3566](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3566.579s)

um so when we think about [[third attractor]] we have to think about what is the culture of it what must it be what must the coordination systems and the distribution and allocation of resources and you start to get into things like well man doesn't interest by itself even if we don't think about central bank policy or interest rates or fractional [3589](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3589.44s)

reserve banking or anything doesn't interest itself compounding interest force [[exponential growth]] of finance yeah it does and then to not debase the currency doesn't that mean you have to have an [[exponential growth]] of goods and services yeah it does doesn't that mean you basically have an exponential [[materials economy]] on a finite planet yeah so interest has to go well that's really fundamental we don't know how to make that world um and then as long as most access to resources based on [[private property]] doesn't that mean rivalrous interest where i can do better at the expense of the environment and others based on [[private property]] probably a lot of stuff has to be rethought around property law and then even when you get to i can appreciate the atmosphere in fact my life depends upon it but i don't have to pay for it and so if i cut a tree down i get immediate benefit from the timber and the little tiny damage it causes to the atmosphere i don't really notice but when everybody [3652](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3652.079s)

thinks that way it does have that effect but locally i have way more incentive to cut it down than to leave it up because the extraction value that i get from turning it into lumber gives me [[game theory|game theoretic]] value whereas if i if if i put my resources towards planting more trees that i don't have economic interest in i do less well in the [[economic system]] this means that there is a fundamental rethinking of the value equation because whoever ends up valuing extractable exchangeable wealth ends up doing game theoretically much better than those who don't which means they influence the world and culture more those who pay more attention to commonwealth have less influence over the whole thing so the changes that we're talking about at the level of [3696](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3696.0s)

economics are things like interest [[private property]] fungible currency even deeper than whether we have [[nation state|nation states]] or not um and the the same in terms of thinking through what is the future of the tech stack look like so we share a lot of views and thank you for laying it out i hope everyone could follow with these [3715](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3715.26s)

um you know this way of presenting where we're at a lot of people are quite naturally fearful of where we're going in terms of the labor force because of ai for example and so in one of your talks i don't know if it was very recent and we shared this view about this by the way we talked about education or educators and nurses i [3738](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3738.96s)

think it's a it's a good way to present a hopeful opportunity for us to do something where humans are uniquely designed to something different than machines and where efficiency is not what matters it's more about qualitative than the quantitative and our computational capability is not challenged by that yeah so i thought maybe it's switching gears a little bit [3760](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3760.799s)

but it's giving a little bit of hope again in terms of how we can address concretely some of these challenges that we're facing whether we're techno optimists or techno skepticists and so i worked with the g7 on scheme to try and infuse into [[national security]] in the g8 countries a concept of benevolent ai and we were just studying with 80 scientists from all over the world how we could [3786](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3786.119s)

potentially put that into motion and start to educate government bodies and leaders and the main failure point was purely geopolitical so the [[arms race]] and ai just made it so that it made every single suggestion stalemate so we have to address it on a population level and also in terms of how in terms of society we adapt to the change that's coming towards us so we've [3811](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3811.02s)

adapted to bringing cars in our into our life arguably and perfectly um we've adapted to many changes in our society in terms of health care and pandemics and how we travel and etc etc give us a little um you know i i share this view with you by the way how you think educators and nurses could become a little bit of a new orientation for mankind as ai steps [3833](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3833.7s)

in so the topic of technological automation creating a jobs issue um there's a couple perspectives one primary perspective is uh technological automation will obsolete certain jobs but it'll create new jobs it's always been the case we don't have elevator operators anymore but there's plenty of new jobs and then there's the other [3862](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3862.02s)

perspective no actually advanced robotics and ai are different in kinds in some of the earlier industrial technologies and they're different in speed that as new jobs are created they will still be able to beat humans at doing it for market purposes which i think is much more true um so if you take an ai like uh google's ai you take alphago you [3885](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3885.359s)

can train it on chess and how to beat everybody in chess you can train it on go and how to beat everybody at go you can train it on starcraft and how to beat everybody at starcraft it can gain the capacity very quickly to beat humans at any finitely definable game and so ai is different in kind than other previous technologies it's more like the difference between us and [3909](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3909.18s)

all the other animals with our ability to innovate you know creating recursive technology on technology that allowed us to become [[apex predator|apex predators]] in every environment and then more than that the ai is kind of like that jump again and so it does portend um uh a break of capitalism and market structures as we know it and that most [3930](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3930.54s)

of not just labor but most of the jobs that we currently have and even the new jobs that emerge in the niches that it creates it's better at than we are that sounds pretty terrible if you keep the existing [[political economy]] where people need the jobs but one of the main reason we created a system where the people need the jobs is because the jobs needed the people to do them and if you [3953](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3953.64s)

to make a civilization run well if you had to get the people to do the jobs and a market seemed like a better answer than the state forcing the people to do it so let's let the market force people to do it and they can kind of self-organize and but as soon as the jobs don't need the people to do them anymore you can also start thinking about economies where the [3973](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3973.2s)

people don't need the jobs which is why now a lot of people are thinking about universal [[basic income]] and like different ways of thinking about that um there there's early naive thoughts on universal [[basic income]] of course it's the beginning of thinking about it but um there's a really deep question which is what is the role of humans in a world of [3993](https://www.youtube.com/watch?v=6aKI2C61jVE&t=3993.66s)

advanced robotics and ai because the advanced robotics and ai will be better than us at most of the things that we're used to being good at so what is the role of humans in that world what are we still uniquely good at and then what is also intrinsically fulfilling and meaningful and there becomes a steep question of what what does education become in a [4017](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4017.059s)

post-technological automation world where you're not preparing people for the workforce in the same way what is the role of education and human development but obviously to answer that you have to say not just education but and obviously there's the economics component how do we do resource allocation and access in that world but there's a really deep civilizational [4037](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4037.52s)

question of what is the role of human life and if we for a moment avoid the topic of sentient ai which is a whole theoretically difficult question and we just talk about functional ai meaning ai that we're not saying there's something that it is like to be it we're simply saying it's very good at figuring out how to do stuff then right away the the key what is [4059](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4059.619s)

uniquely different about humans and it is sentience is the capacity to actually have there be something that it is like to be you at all this is [[subjective experience]] and then intersubjective connective capacity and what's interesting is things related to sentience are what is is where our intrinsic motive if we're not being behaviorally controlled by [4086](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4086.119s)

extrinsic motive i.e being paid to do a thing or external deterrence and so mostly you have to pay people to do they don't want to do right and if the  that people don't want to do is increasingly getting automated can you then have a world where largely what humans are spending time doing also more deeply uh coincides with what they have the deepest intrinsic motive to do [4110](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4110.96s)

particularly if you then have a developmental system and developmental society oriented to find out what the unique human motivations and capacities of each person are and develop them in light of that and so not only does ai portend something in terms of the obsolescence of humans for lots of labor roles and repetitive things one of the things uh tomas was probably referencing [4130](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4130.759s)

was the topic of ai in human tutoring is pretty amazing it's also scary as because uh again you have to get this thing right if you have an ai that has so many orders of magnitude more information processing in terms of being able to model your micro expressions to see how you're learning it can also uh have undue influence in a [4156](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4156.259s)

way that no cult leader has dreamed of right in terms of asymmetries of power of influence so so who controls that and how do they control that these actually become the cultural questions the theoretical philosophic questions that are so fundamental if you can genetically engineer humans and have designer babies don't we all want to be like tall and beautiful and uh thin and [4177](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4177.679s)

is that actually the right idea when you as soon as you have the ability to actually design intelligent machines and design self-replicating machines and change biology the philosophic questions of what is good and desirable becomes so fundamental because so much becomes possible right but if you do it right imagine everybody's heard about deep fakes [4200](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4200.38s)

the ability to train an ai you can make basically pictures that aren't real faces that aren't real from ai images that look totally real you can also make a video of me speaking where it looks exactly like me sounds like me but it's totally i generated it's not real that technology already exists it's not that good some people have made deep fakes of [4222](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4222.98s)

me that are audio that sound like me um but the deep fake videos are currently about three years away from being turing test passing meaning you can watch a video of uh obama or bernie sanders or whoever say something and have no idea if it was real or not and you won't have the human capacity to tell if it's real or fake you can imagine what that does to our ability [4246](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4246.62s)

for eclectic collective [[sensemaking]] but that same deep fake capacity can be positively purposed because what that means is it's trained on the semantic patterns and the vocal patterns enough to be able to generate novel answers like a chat bot but where you can't tell that it's not real so now imagine an educational environment where you train that same ai [4267](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4267.14s)

this is large language models as the type of ai say you train it on all the writings of thomas jefferson or all the writings of socrates socrates through plato or whatever in writings about them such that i can go into a metaverse environment and say i want to pull up einstein and von neumann and kerr girdle and be able to have a talk with him about formal logic and not only [4290](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4290.48s)

can and they can it can seem like i'm actually having a conversation with them where they're sharing differing views based on their actual views writing etc um but i could also just have an avatar that is like the the voice of chemistry that is the holistic knowledge of all chemistry that no human could be and yet all of them are the ai's best [4312](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4312.38s)

attempt to model what that person would do in terms of semantic coherency with what they did and said in the past so now imagine a future where every kid has access to be able to study with einstein and gandhi and socrates and von neumann and whatever directly where those ais can model our theory of mind and titrate the learning directly to us associated with our learning dynamics [4336](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4336.219s)

but then also because the jobs have largely been automated what humans spend way more of their time with is things like being educators and being nurses and being musicians and the things that have kind of high connectivity value because those are the things that the machines don't do as well as the actual sense of shared interiority so now imagine that we have way more teachers [4357](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4357.8s)

per capita that are way more well trained so all the teachers are you know phd level trained there's one of them per 10 kids as opposed to one per 30 and now i get out of my ai environment where i was just studying physics with einstein and my tutor asks me a question like what do you think was different about what the ai einstein [4382](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4382.4s)

said than what in actual einstein live today might have said so then helping us to try to understand the difference between human intelligence and [[artificial intelligence]] and what it means to be sentient and what effect does consciousness have on intelligence so not only are they getting that level of educational access but they're that the ai can do but the differential of [4401](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4401.96s)

what is unique about human intelligence and [[artificial intelligence]] so this is one of a million examples we can give of how those technologies could do mind-bendingly amazing things i'll say one quick thing about this is um there is a there's a study done on super genius of the past or polymaths people who advanced many different fields beyond [4423](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4423.08s)

what the specialists in those fields did and uh was there anything that the great polymaths had in common and the single thing that stood out the most was that they were all the result of aristocratic tutoring and this was actually a very taboo topic because when we ended feudalism and tried to create democratic states uh the idea like if you if you think of [4446](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4446.239s)

[[meditation|meditations]] by marcus aurelius marcus aurelius spends the entire first chapter just thanking all of his tutors but when you're being raised to be the emperor of rome the best mathematician the best poet the best grammarian the best historian literally in all of rome are your private tutors and you can't learn to think like a mathematical genius from someone who [4467](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4467.12s)

wasn't a mathematical genius so your average math teacher cannot teach you to think like that because they don't think like that and yet that's how do you make that accessible to everyone you don't so the aristocratic tutoring in the past was a nice patronage job for the smartest people but it was also so radically unequal but it's what created the best minds so could that possibly be [4487](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4487.76s)

made popular well we can see in a [[third attractor]] kind of world the application of these technologies where you could actually have better tutoring than marcus aurelius had for everybody um you know et cetera et cetera now for each of these wonderful scenarios are like a million ways it goes wrong and so um how how we steward that properly is the key defining thing over the next [4514](https://www.youtube.com/watch?v=6aKI2C61jVE&t=4514.46s)

while thank you daniel applause