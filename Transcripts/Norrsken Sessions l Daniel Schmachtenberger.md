---
tags: transcript
aliases:
youtube_id: kbg8nHuNggU
published_at: '2022-10-24'
---

<div class="yt-container"><iframe src="https://www.youtube.com/embed/kbg8nHuNggU"></iframe></div>

foreign music applause music applause music i would actually like to just before we get into the subject um hear a bit about your reflections on that i mean i felt fear about thinking [34](https://www.youtube.com/watch?v=kbg8nHuNggU&t=34.38s)

about this uh for a few hours and you spend your days and your life engaging in thinking about existential and [[catastrophic risk|catastrophic risks]] how how do you deal with that it's working all right well first i just wanted to say that i think your intro where you shared personally that it was scary to come up here but you got over it because in the [62](https://www.youtube.com/watch?v=kbg8nHuNggU&t=62.039s)

face of the issues we face as a world you get over your own personal stuff one of the things that is critical for us to address the [[metacrisis]] is a certain kind of courage to be willing to look at the things that are scary that will break our current theories of change and we'll we'll have a while where we don't know what a new solution is and we have to be willing to go [84](https://www.youtube.com/watch?v=kbg8nHuNggU&t=84.84s)

through that adaptive valley to come up with solutions that might be adequate so you just model that beautifully and a vulnerability and a strength in that i'll just add in case it's humanizing um i don't like public speaking um never yeah i uh my that's why i even like hold the [105](https://www.youtube.com/watch?v=kbg8nHuNggU&t=105.78s)

mic away my first experience is public speaking were just like a panic attack and i got over it because the topics mattered enough to me i still get over it every time before i talk um but i think it's a good example of the kinds of sacrifices that are important and as we're talking about this today [126](https://www.youtube.com/watch?v=kbg8nHuNggU&t=126.42s)

it's like why do we want people to know about really consequential like maximally consequential scary things that they don't have any obvious agency to fix um and why do we not just go straight to solutions because there are not solutions to go [149](https://www.youtube.com/watch?v=kbg8nHuNggU&t=149.64s)

straight to that are adequate to the problems yet it requires more people being engaged in the earnest endeavor to find them which requires them being engaged in contact with reality as it is which does require like an earnestness and a courage and like that so um on the topic of i give a talk at a conference in turkey the other day and [174](https://www.youtube.com/watch?v=kbg8nHuNggU&t=174.72s)

there's a very strong emphasis in the audience to be optimistic and it's a funny thing the what i would hope for is a kind of post-cynical optimism there is a naive optimism which is um naive optimism has a lot of different voices the voices are like there have always been challenges and humanity just arrives rises to the challenge and tech [201](https://www.youtube.com/watch?v=kbg8nHuNggU&t=201.78s)

will solve everything and we'll get ai and it'll solve everything and whatever and these are not well thought through theories of change or everything's getting better and there are problems but the problems are less bad than the ones we used to have and everything will keep getting better through tech and capitalism and innovation this is the apologism we tell [219](https://www.youtube.com/watch?v=kbg8nHuNggU&t=219.36s)

ourselves to keep doing the standard model um so there's a certain kind of naive optimism it has many flavors that hasn't encountered the depth and complexity of the [[problem space]] when you start to encounter the depth and complexity of the [[problem space]] uh there is a cynicism and a nihilism that can occur that looks like [242](https://www.youtube.com/watch?v=kbg8nHuNggU&t=242.7s)

impossible to solve how can how can evolutionarily nasty chimpanzees that have a very high orientation for conflict and irrationality with [[nuclear weapon|nuclear weapons]] and ai and synthetic biology who have the history of using our technology as conflict-oriented and harm externalizing as we have how can 8 billion of us with [266](https://www.youtube.com/watch?v=kbg8nHuNggU&t=266.94s)

[[exponential tech]] do a good job of governing that much power doesn't actually look promising and that the solutions to most of the problems look like making another problem worse you recognize that in the age of [[exponential tech]] which democratizes which decentralizes exponential power that also means decentralizes and [293](https://www.youtube.com/watch?v=kbg8nHuNggU&t=293.699s)

democratizes catastrophic power and while we like the term democratize in some ways democratize [[catastrophe weapon|catastrophe weapons]] for everyone is actually not a nice world the first real catastrophic weapon the world ever came up with was the bomb and it was fortunate that the bomb was just really hard to make and because it was really hard to make you could limit the [315](https://www.youtube.com/watch?v=kbg8nHuNggU&t=315.24s)

number of players who could make it and so you just had two for a very long time with one [[catastrophe weapon]] and two players you can have [[mutually assured destruction]] and force in equilibrium with even a g8 or a small number of players that can monitor each other through satellites you can force an equilibrium but when you have a very large number of [332](https://www.youtube.com/watch?v=kbg8nHuNggU&t=332.58s)

players with [[catastrophe weapon|catastrophe weapons]] where you don't even know who the players are in their [[catastrophe weapon|catastrophe weapons]] of a different type because you can do gene synthesis in a basement or because you can make drone weapons in basements well how does the world make it through that the only people that have thought about it well mostly come up with [349](https://www.youtube.com/watch?v=kbg8nHuNggU&t=349.8s)

surveillance answers we have to know what people are doing in basements well then you get up dystopias or the answer that's going to make [[climate change]] better which is pricing carbon properly and putting heavy taxes on it well how do some leading countries do that if the other countries don't or the damage to the gdp of the countries that do it relative to the other ones just [373](https://www.youtube.com/watch?v=kbg8nHuNggU&t=373.44s)

means seeding power there so if the western alliance does that then you're actually just saying the chinese communism runs the world and on and on there's we can grow more food for people using nitrogen fertilizer that causes [[dead zone|dead zones]] and oceans faster so most of our approach to problem solving is looking at the problem too narrowly defining a solution to that [395](https://www.youtube.com/watch?v=kbg8nHuNggU&t=395.58s)

problem that externalizes harm to other problems with a cumulative effect of all of that as a [[self-terminating]] system and so either you solve one catastrophe make another one worse or you solve all catastrophes and make dystopias by creating strong enough control mechanisms that don't have checks and balances on [415](https://www.youtube.com/watch?v=kbg8nHuNggU&t=415.02s)

themselves so we're in search of a third possibility that is neither catastrophe or [[dystopia]] to not be catastrophe means that it has to be able to check all of the catastrophes that are otherwise impending which means all of the [[perverse incentive]] market forces that are driving us towards [[planetary boundary|planetary boundaries]] all of the incentives towards large-scale warfare on and on as well as what happens in basements and synthetic biology labs and to not be dystopic means the power that can witness all that surveil it whatever you want to call it and can regulate it has to have checks and balances on itself and yet it'll operate at such a level of complexity that the asymmetry of it is so far from what an [456](https://www.youtube.com/watch?v=kbg8nHuNggU&t=456.9s)

individual can process how do you possibly adjudicate that or democratize that this is super complicated and there are solutions but it's very much threading the eye of a needle but we do have to so there are naive optimism that just doesn't understand the complexity you start to understand all this complexity and see that the self-determination is [476](https://www.youtube.com/watch?v=kbg8nHuNggU&t=476.099s)

almost over determined by the core nature of the system that we live in the core nature of the interconnected systems that we live in and that our solution processes itself part of the problem the way that we have gone about doing solutions historically we don't get to just say well we've always had problems in necessities some other of innovation [496](https://www.youtube.com/watch?v=kbg8nHuNggU&t=496.8s)

and we'll indent new and because that process itself causes bigger problems not just new ones but fundamentally bigger ones because there has to be some scale at which the solution overtakes the problem i'll go ahead and expand on that a little bit because it's important people haven't thought of it [[climate change]] is a pretty big issue it uh is obviously threatening venusification of the planet and like very serious stuff and ocean acidification and biodiversity loss and all this stuff um well before it does that it's already producing extreme weather events that are a pretty big deal right drought in syria caused a massive issue that the [540](https://www.youtube.com/watch?v=kbg8nHuNggU&t=540.3s)

human migration refugee issues from that are still having shocks throughout the world regarding what do we do with immigration and that was a very small number of people the extreme weather events in australia damaged a lot more land space it was just low population density what happens when you have extreme weather events like the ones in australia but for high [560](https://www.youtube.com/watch?v=kbg8nHuNggU&t=560.279s)

population density high population areas that could happen this next year right it might not happen for three years it will certainly happen within five on the current trajectories so what happens when you have 50 celsius type heat waves for a little while in bangladesh and pakistan and india in nigeria let's take india as an example where you already don't have groundwater because it's been over utilized you don't have food stores they got messed up during covid because our solution to one problem which was let's stop the spread of covid by shutting down all travel meant you also shut down the [[supply chain]] so that fertilizer and pesticides for the industrial agriculture were shut down so [601](https://www.youtube.com/watch?v=kbg8nHuNggU&t=601.14s)

you lost crops and crops were lost in fields so the stalks of food are down so what happens when you have a heat wave that kills the crop you don't have background food you know stored of food the people don't die peacefully so you get resource orders do the resource wars cleave along muslim hindu lines probably does that lead to india pakistan conflict which are both nuclear [625](https://www.youtube.com/watch?v=kbg8nHuNggU&t=625.08s)

countries maybe does it lead to massive human migration when already nobody wants to take people probably when we're looking at un estimates of 300 million refugees in the next single digit number of years some people estimate a billion refugees as a result of extreme weather and things like that and nobody wants to take a million refugees the people just won't die peacefully outside of a wall and unlike in the past some of these people have high-tech skills and so it's not just looking at a war where they pick up pitchforks it's looking at the fact that today most technologists are gainfully employed as soon as you start having technologists who are part of the human [667](https://www.youtube.com/watch?v=kbg8nHuNggU&t=667.74s)

migrations are affected on the other sides of them that can build drones and you have careful infrastructure and other things like that you get these cascading catastrophe potentials and we're right at the brink of these things right and so coming back to [[climate change]] so [[climate change]] portends this risk to all of these things and it's this result of what a little bit our [688](https://www.youtube.com/watch?v=kbg8nHuNggU&t=688.62s)

agriculture and our waste management but largely energy generation and transport right fossil fuels so oil burning the primary thing it was the result of was the internal combustion engine and i'd like to give this example because it's just silly but it's so obvious what problem was the internal combustion engine solving it was solving a human [710](https://www.youtube.com/watch?v=kbg8nHuNggU&t=710.88s)

transport problem which was that horse-driven transport was slow and clunky and mostly horse husbandry was a problem and literally one of the big factors driving the push for the internal combustion engine was too much horseshit in the cities and the desire to solve the horseshit and horse husbandry problem that led to the horseless carriage [731](https://www.youtube.com/watch?v=kbg8nHuNggU&t=731.22s)

you know 100 plus years later has the venusification of the planet as a secondary side effect and it's like okay this is an example if we solve a problem in a way that causes a way bigger problem down the road right so now the answer is let's geoengineer it right the geoengineering i could get into does the same thing [752](https://www.youtube.com/watch?v=kbg8nHuNggU&t=752.94s)

um depending upon which technology so in general when we're trying to solve a problem we define the problem in a narrow way the problem is this many kids dying of starvation in this area it's not the macroeconomic system that creates poverty or the global order that creates political instability in those areas right we don't define it broadly enough [776](https://www.youtube.com/watch?v=kbg8nHuNggU&t=776.82s)

and so then we come up with a solution and the solution is either a law or a business or a technology or something like that a non-profit where the solution is going to produce a first order effect meaning we will directly produce this effect on some small number of metrics that we're measuring the problem with and it'll do that it's going to increase the genie coefficient [797](https://www.youtube.com/watch?v=kbg8nHuNggU&t=797.579s)

or it's going to decrease poverty or it's going to decrease co2 or whatever the measure is but the same technology or lower thing we implement we'll do other stuff it'll interact with ecosystems and political systems and [[economic system|economic systems]] [[complex system|complex systems]] where it'll produce second order effects and third order effects on a whole bunch of unknown metrics and many [816](https://www.youtube.com/watch?v=kbg8nHuNggU&t=816.54s)

of those are where harm will be externalized so the story that we always solve problems like it's true but one of the things that has to shift is how we solve problems and how we define problems which is why we need a deeper understanding of the what problems are what the cause of them are how to think about problem solving differently [834](https://www.youtube.com/watch?v=kbg8nHuNggU&t=834.66s)

so this uh just personal story this insight really hit me first when i was 13. i was uh helping with money raising and letter writing and stuff like that as a homeschooled kid a project for stopping elephant poaching in a particular preserve in kenya there was an elephant preserved the poachers were getting over [858](https://www.youtube.com/watch?v=kbg8nHuNggU&t=858.899s)

the fences they were hunting the elephants i was at a greenpeace headquarters and i saw a video that was taken of the elephants being poached and i was just like crying and shaking in in rage as a kid like how could they do that and so greenpeace and world wildlife federation and all these groups risk their life on the ground in the [879](https://www.youtube.com/watch?v=kbg8nHuNggU&t=879.06s)

face of the you know poaching invested interests uh to save these animal lives and the solution was put up bigger fences around the preserve the poachers can't get over very practical and do legislation that the local country increased the s the sentencing for poaching elephants in that preserve after a couple years of work that succeeded [903](https://www.youtube.com/watch?v=kbg8nHuNggU&t=903.0s)

it hadn't addressed the poverty of the people where poaching was the only solution to not be some of the people who 25 000 people starve to death a day in the world still and it hadn't addressed a macroeconomy that creates poverty at scale and it hadn't addressed a black market on animals it hadn't addressed [[value system|value systems]] around it had addressed any of those things so the [922](https://www.youtube.com/watch?v=kbg8nHuNggU&t=922.74s)

same poaching groups moved to start poaching both the white rhino and the mountain gorilla both of which were more endangered and i was working with enough orgs that i got to see that and i'm like we did all this tremendously hard work other people much more than me and we moved it to a more sensitive worse area [939](https://www.youtube.com/watch?v=kbg8nHuNggU&t=939.18s)

and that was a massive existential shock for me because i had already had the first existential shock of seeing a [[factory farm]] and feeling like it's not will there be an arm again there's already an armageddon for all the animals in a [[factory farm]] there's already a [[existential risk]] for every animal that goes extinct every day that humans induce we're already in a rolling [956](https://www.youtube.com/watch?v=kbg8nHuNggU&t=956.82s)

um you know armageddon of that sort and i'm like when i was a kid thinking about that first there was this question of if i know what's happening in a [[factory farm]] if i know what's happening in a thai child sex shop if i know all those things can my life feel like a success while that's still happening and i'm like i have to be a sociopath [980](https://www.youtube.com/watch?v=kbg8nHuNggU&t=980.639s)

for my life to be a success because i have to separate myself from the other sentient beings so much where ultimately i'm just luckier than them that i'm not born into that situation there's no meritocracy of why that's the case and they can't get themselves out of it and maybe i can so the only way i can't kill myself because that doesn't help any of them so the only way to actually have life be a success what it said at the end if it wins for you it wins for everyone if it doesn't actually win for everyone it can't be a success right and uh so i'm like all right well let's at least do the activism and figure out how to solve it so then when i saw that the activism moved the problems and didn't actually work and moved it to [1019](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1019.88s)

more sensitive areas that was the next existential shock and then i'm like well does it do that in other places and then i'm like all right well this solution to poverty to make a hydroelectric dam drown this whole area and extinct a whole bunch of species and this solution to poverty the world food program was working on brought npk fertilizer to [1038](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1038.419s)

areas that didn't have it that led to [[dead zone|dead zones]] and oceans faster and then when i talked to the guys about it they said those aren't the metrics we're tasked with and on and on and i'm like the solution space collectively is not converging on the [[problem space]] the [[problem space]] is actually taking off relative to the solution space so then that got me to think about all [1064](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1064.1s)

right how do we if we really want to stop the elephant poaching and not cause other problems you probably have to deal with how do you make an elephant worth more alive than dead how do you have to how do you deal with a macroeconomic system that doesn't create poverty how would you have a [1081](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1081.74s)

macroeconomic system with this many people that took them out of poverty they didn't ruin the environment without many resources per capita being engaged how do you and that looked like thinking through a lot like looking at all the proposed solutions scandinavia is pretty nice there's this whole idea of make the whole world scandinavia does that work and it [1103](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1103.4s)

doesn't for reasons everybody in here probably knows it's worth noting that a lot of the metrics of quality of life that we use for countries aren't nonsense because you just export the  somewhere else so i can have a hygiene coefficient because we import our our semiconductors where we get the cobalt from the congo [1125](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1125.24s)

or whatever it is my country doesn't actually run without the stuff from those other places and so those have very very low genie coefficients so i actually have to factor my [[supply chain]] dependence and when i factor the [[supply chain]] dependence well without china and without congo and without etc you know the whole thing's messed up and the same would be true for most of the metrics [1145](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1145.4s)

that we look at which is why you really have to think about these things globally in an age of planetary [[supply chain]] dependence for all the things that we depend upon foreign so you know that my life path was this was a very long response to uh post-cynical optimism is can we understand what the problem landscape is both the wicked problems that have been with us for a long time like poverty and conflict and things like that and then the fact that those are escalating towards [[catastrophic risk]] and not one [[catastrophic risk]] but many many that are converging in a way that is novel to this time in history that is totally [1187](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1187.46s)

different than any time in history can we understand that well enough to think through what adequate solutions would be that don't externalize harm somewhere else that don't cause other problems but that are actually competent to what needs to happen and that's what i think of as post-cynical optimism right which is um yes there are solutions but not if i [1206](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1206.12s)

don't understand the [[problem space]] adequately first and that as you do start to get into it very quickly you'll find that your thoughts on conscious capitalism or your thoughts on why [[web3]] and [[blockchain]] will save everything or whatever the that the solution is fails quite quickly in a full analysis but having the strategies get shattered [1227](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1227.96s)

on the rocks of kind of a deep understanding of reality is very good because then you can start to think what would be adequate and obviously having studied this as deeply as i have and knowing the [[catastrophic risk]] landscape well i'm here speaking and doing all the things that i do because i do see that there are actually adequate solutions and there's a story as inspiring which [1246](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1246.559s)

is say this is uh you know humans have modeled ourselves as [[apex predator|apex predators]] and in terms of kind of social darwinism uh we can't model humans as [[apex predator|apex predators]] because a really pissed off polar bear can't ruin the world um and a very hungry orca can't overfish the oceans if you look at the top [[apex predator|apex predators]] they they can't extinct other species they can't destroy ecosystems they can't cause catastrophic harm humans starting with stone tools were the first creature that because we were able to increase our predative capacity not through a genetic adaptation of our body but through the capacity for recursive abstraction and to be able to build a much bigger fang [1302](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1302.84s)

as a spear and build coordination mechanisms through abstract communication we were able to increase our predative capacity faster than the environment could increase its resilience and so in that that is something beyond genetic [[evolutionary process]] it's a totally different type of innovation process so we were able to over hunt an environment [1321](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1321.559s)

then rather than have our population come back into check like it would with any predator we could move to another environment become the [[apex predator]] in every environment then start farming the environments and on and on and obviously this led to tribes competing with each other which led to a imperative to grow the technology in [[arms race]] is relative to each other which leads to a long [1341](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1341.059s)

exponentiating curve that verticalized in the [[industrial revolution]] and really verticalizes now where if you have the ability to genetically modify new organisms and to extinct species and to destroy whole spaces and to have the main geologic force on the surface of the earth be human activity the anthropocene you can't model [1363](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1363.62s)

yourself as [[apex predator|apex predators]] you have to model yourself as nature itself right like we have the ability to destroy the world you have to be stewarding the world and otherwise that power self-terminates so mythopoetically it's if you have the power of gods you have to have the love and wisdom and prudence of gods to safely steward it how do we have a world where we can [1384](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1384.74s)

foreign modified organisms which means in a in a competitive race market-based competitive race if they start making designer babies with higher iqs how will we possibly compete we need to design our babies with higher iqs and what are the negative externalities of what other psychological downsides go with those higher iqs and blah blah blah right and [1407](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1407.96s)

when we're doing the gain of function research in a lab we don't have to intend to make a [[bioweapon]] to just have accidents happen and when we're making the ai to optimize a [[supply chain]] can that same ai be turned around to optimize how to break a [[supply chain]] um so how do we have humans steward the power of synthetic biology [1431](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1431.9s)

and [[artificial intelligence]] and technology is that powerful and that decentralizable this near [[planetary boundary|planetary boundaries]] we can't be we can't do it in anything like how humans have navigated their technological power previously and so i see that we are at a place where to kind of pass through the fermi [1458](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1458.48s)

gate right the fermi paradox why don't we see more aliens well maybe they kind of mostly self-terminated in their technological adolescence to not self-terminate and pass through the fermi gate there's a certain responsibility of do we have the power to steward do we have the intelligence and wisdom to steward that power well um i would say the shift that has to happen for humanity to make it is not similar to the post-world war ii bretonwood system it's not similar to the [[industrial revolution]] it's not similar to the agrarian revolution in terms of like epoch the closest thing would be similar to the early invention of stone tools [1499](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1499.22s)

where early humans early earthen hominids homo habilis or whatever really differentiated themselves from the rest of nature in a fundamental way that was a fundamental shift in [[evolutionary process]] all those other ones were iterations in [[game theory]] develop more technological capacity use it to benefit an in-group at the expense of an out group or the [1520](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1520.1s)

expensive nature which can be thought of as an outgroup of the commons now it has to be how do we steward all this power in omni-considerate ways without benefiting in groups at expensive out groups or benefiting some metrics at expense of others and how do we get how do we do that factoring all of the humans that are here and all [1541](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1541.58s)

of the motives and like that so i would say um it's actually nothing less than that that is adequate to make it long term which is the inspiring site it's also really really far from where we are which is the hopefully motivating side so that's it for post-cynical optimism opening comments sorry foreign applause music to what extent the things that you see that we need to change to what extent do you say that they have to do with like our institutions and how we organize and and that side of the world versus how much has it to do with us as individuals and what we value and our [[social system]] versus how much this is is a [1594](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1594.559s)

technological problem if you have smart enough ai that will optimize this for us how do you think about those aspects um i'm laughing because everybody gets favorite theories of change and then they have a hammer and they try to conform the whole world to why that theory of change makes sense in an interconnected world you can argue this [1621](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1621.38s)

particular thing why everybody needs to do ayahuasca for consciousness change or why ai will create great efficiencies or why you know whatever um can affect all the things you we need an ecology of theories of change many different theories of change that are inter-affecting each other and one valuable way to think about that [1644](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1644.6s)

the anthropologist marvin harris talked about thinking of civilizations in terms of the technological infrastructure that they run on to meet all the physical needs and like that the [[social structure|social structures]] through which they do agreements so the political economy and the institutions and the [[superstructure]] or the culture and [[value system|value systems]] to which the whole thing is supposed to be [1666](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1666.14s)

oriented and marvin harris himself formed a field called cultural materialism they basically argued that tooling was most fundamental and the changes in tech necessarily always changed the [[social system|social systems]] the [[social structure|social structures]] and [[superstructure]] and he you know gave a big kind of opus analysis on why that [1690](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1690.08s)

was the case i don't agree but it is i don't agree that it's totally that way but it's a really deep factor and it's worth understanding it's worth understanding because it breaks the very superficial nonsense concept that technology is values agnostic and technology is neither good or bad it's just some inner thing and we can use it for good or bad purposes this is not a [1711](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1711.02s)

good assessment um technology changes inexorably human values human psyches cultures political systems it can't not we wrote a paper of the consilience project summarizing so you don't have to read 80 books on the topic um called technologies not values agnostic um but just briefly if uh a technology catches on because it confers adaptive advantage in some way makes us able to solve some problem which equals some kind of market competitiveness or military competitiveness or whatever it is and so as soon as you realize that the technology is catching on because humans using it increases their competitive [1753](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1753.5s)

advantage that everybody else has to use that or some comparable thing or lose and so the tech technological proliferation is obligate it's not like you can choose if somebody's getting nukes you can just choose not to and still have equal footing right or someone's doing autonomous weapons and you can just avoid ai and you'll be fine um and then if i'm using a technology [1777](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1777.2s)

i'm behaving differently right if i'm pushing a plow all day it's very different than being a hunter or gatherer or driving a tractor it's a different pattern of human behavior that pattern of human behavior is a different input to my consciousness my [[nervous system]] and a whole different set of human values and everything come out because changing patterns of human [1794](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1794.539s)

behavior change human psyches so the plow is my favorite example every example is good um marvin harris is good to read for this marshall mcluhan is very good to read for specifically how media and information technologies change cultures and psychologies but the plow it's more nuanced than this when you actually go through how the plow was introduced [1814](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1814.399s)

differently in different areas but as we went from hunter-gatherer cultures and then hunter-gather that had horticulture meaning just a digging stick to an ox-drawn plow or a horse-drawn plow uh you had to have an animal domestication animal husbandry too draw that plow and the animal the wild animal is not oriented to do that so you have to [1835](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1835.52s)

domesticate them well the domestication process is very interesting because you all of the cultures pre-plow were animistic pretty universally they talked about the spirit of the buffalo and the horse and the tree and the whatever and post plow none of them were animistic because you can't say you know i respect the great spirit of the buffalo and yet yoke it to an a plow [1858](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1858.62s)

and beat it all day long and so then we have to move to memetics that justify doing that thing like man was granted dominion over the animals and that kind of thing and yet another tribe can't say hey that's sucked up we're not going to use the plow because the tribe that does is going to grow its population get a lot more caloric surplus and then beat the other one in tribal warfare which is [1881](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1881.48s)

why you don't see that many pre agrarian cultures left and so there's an interesting analysis that showed it ended animism it likely entered the thing we called patriarchy because before that men did the hunting and women did the gathering or women used the digging stick they both provided calories after that the men did the hunting and the animal husbandry and [1903](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1903.26s)

the plowing to provide the vegetative stuff because the upper body strength needed for the plow as a result within 100 years of entering the plow female gods went away and most cultures where there had been more equality of male and female gods now with the plow you get surplus because of grain with surplus you get differential ownership in class systems like you start to think about [1922](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1922.46s)

wow the emergence of capitalism the emergence of institutional marriage to say who owns stuff to deal with the issue of inheritance for when you die views towards animals views towards men and women are the result of a tool and so we get a tool called a smartphone and we don't have eye contact retention spans you know we don't have we have huge amounts of information we're now [1943](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1943.82s)

susceptible to state-sponsored population-centric warfare on our minds where we think we believe the we believe for our own reasons and it's actually mostly population-centric warfare getting us to believe for other people's reasons and we don't even know it and that's the result of tools that we're using that also happens to be [1961](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1961.46s)

useful or at least addictive in some ways so uh does so tools affect our psyches individually and affect our cultures and affect our institutional processes obviously you can't run a digital currency based uh monetary system without ubiquitous computing right so it's only once you have [1985](https://www.youtube.com/watch?v=kbg8nHuNggU&t=1985.76s)

ubiquitous computing that you can think about moving from a [[printing press]] of money to a digitized money system on and on right so the political and [[economic system|economic systems]] change is the tooling system change so uh there's a lot of argument to understand how one more thing on this the [2004](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2004.899s)

one type of externality is we make a tool to benefit something but it has other externalities and obviously all of the environmental [[planetary boundary]] stuff is an example of externalities where we're talking about a physical externality right in the process of manufacturing this some pollution of a particular kind we put water repellent on that water repellent was say a a [2023](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2023.5s)

fluorinated surfactant which are the forever chemicals that are now in the rainwater everywhere the past [[planetary boundary|planetary boundaries]] it was an article published in the american chemical society journal two months ago that said the epa and the european union level of safe exposure to forever chemicals of that class the fluorinated surfactants is past that in rainwater all around the world [2046](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2046.24s)

so that's a [[planetary boundary]] that we already passed um and that's the side effect of just making water repellent right where then that stuff breaks off and it goes into the water and if it's water repellent it doesn't break down and then it has effects it's carcinogen and a endocrine disruptor but it's [2061](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2061.54s)

invisible so you don't see it so everything still looks kind of fine um so there are physical externalities but there are also psychosocial externalities psychosocial externality is the way that a tool produces effects on psyches and produces effects on families and [2080](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2080.32s)

communities and cultures that have negative effects that we didn't intend or effects of either kind of negative or positive it's an externality so we have to think about the fact that the technologies we create have physical and psychosocial effects other than the ones we intend and think about how to factor that more in the design and the iteration of the design process [2100](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2100.119s)

so this is all just a little bit on the way that infrastructure or the set of tooling effects your [[social structure|social structures]] and your [[superstructure|superstructures]] but of course there are people who will argue that the [[social structure]] is the most fundamental thing because if the [[economic system]] incentivized different stuff the tools that were evolved would be different [2121](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2121.06s)

right if you remove the subsidies from oil and put them on some other energy generation you'd have different kind of technologies emerging if you had a law that bound the cost of externalities into the market different technologies would emerge and so they would say no actually the the institutional [[social structure]] layer is more fundamental and there's of course truth to that other [2141](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2141.16s)

people would say no the [[social structure]] layer the culture layer is more fundamental because the culture if the governance is not an instantiation of the values of the people the people will see it as tyrannical and eventually throw it off so ultimately the values of the people have to be the thing that is the basis for the system of governance that binds and directs the tooling in [2159](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2159.339s)

the economy and the culture is the basis of all the human choices where all the decentralized activity occurs and ultimately what we define is the good life and we're innovating and service to and there are all partially right and so what i would say is if you want to think about how to design how to solve them at a crisis how to design the world better you have to [2182](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2182.02s)

think about what are the changes in infrastructure that have to occur and if we think about the set of planetary level what we're saying is what would necessary and sufficient criteria for a global infrastructure be that is commensurable with [[planetary boundary|planetary boundaries]] meets human needs and where the physical and psychosocial effects are aligned with a metastable planet right so of [2203](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2203.92s)

course you're going to get that it can't be a linear [[materials economy]] that takes  out of nature faster than it can be replenished and turns it into waste and pollution in nature faster than it can be processed it's going to have to be closed loop where all the new stuff is taken from old stuff the old stuff etc and it has to be based on renewable energy within the finite energy [2221](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2221.92s)

bandwidth that's possible but there's a lot of other stuff we can get into of what what are the design criteria of a viable infrastructure what are the design criteria of a viable political economy this is hard this is actually really hard because you start to just very quickly get to stuff like it can't have [[exponential growth]] of the monetary system like that's duh right like that's the first kind of da hippie insight is an exponential financial system that is coupled to material goods and services on a finite plan it doesn't get to run forever we can say more sophisticated versions of that but that's an obvious insight and yet if you say you can't exponentiate [2261](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2261.28s)

the monetary supply well that means you can't have interest because just interest not even fractional reserve banking or complicated financial instruments or speculate speculative investment or anything just even interest is compounding equals an [[exponential curve]] on the monetary supply and of course we post world war ii tried to make an exponential monetary system we we did make an exponential monetary system post world war ii we said we can't have superpower wars again because now we have weapons that are too big to use which is a big deal it's first time in history that we had catastrophic tech before that we never we never could mess [2299](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2299.98s)

everything up from a dumb decision then we could and so history of the world the major empires always wore now the major empire is cantor so how do we build a new [[world system]] that ensures that rather than use the tech as fast as we can how do we make a [[world system]] that ensures we don't use the new tech it's very very massive change in the calculus post world war ii in the bomb [2320](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2320.079s)

um and many things were part of it [[mutually assured destruction]] was part obviously as we mentioned that doesn't apply anymore to the current situation of many [[catastrophe weapon|catastrophe weapons]] with many actors but the [[bretton woods]] monetary system was a major part of it which was let's make these central banks everywhere and let's make uh you know the imf and etc so that we [2338](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2338.339s)

can have everybody have more without having to take each other's stuff if everybody can have more which will motivate their own desire for progress greed whatever you want to call it without taking each other's stuff then the underlying basis for war is mostly resource conflict whatever except where did we get the stuff from oh increased production kind of but also [2360](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2360.88s)

increased extraction right we took the stuff from nature faster so all the [[planetary boundary|planetary boundaries]] were close to hitting are the result of the success of that system preventing kinetic world war iii up till now which is another example of benefit one thing mess up other things a little while later so um but you can say well maybe we could keep an [2382](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2382.0s)

exponential monetary system because you you the calculus is easy you just can't right even if you go closed loop on the economy um there's a pretty close to one for one correlation between global gdp and global energy use this is formalized in the garrett relation and a few other um mathematical equations it's a 99 correlation not 100 because energy [2404](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2404.98s)

efficiency makes a tiny difference basically what that means is from 1970 till now roughly increases in efficiency give us one more percent uh dollar per joule per year but we still end up needing more joules because we've got three percent growth that has to occur and so what that means is if and it kind of makes [2430](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2430.48s)

sense that dollars every industry needs energy right there's no industry that doesn't need energy you're using energy to move bits around in virtual space or atoms around in physical space and some industries produce more dollars per joule but they depend on other industries that have less dollars per joules so when you average it across industries you get [2451](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2451.42s)

this very kind of fixed equation um so if you have a financial system that has to do this just to keep up with interest and it's bound to an energy system that means we have to produce exponentially more joules per year so far that has been you have to produce exponentially more co2 per year by in exponentially more hydrocarbons [2472](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2472.24s)

as of about 2019 we already got to diminishing return on hydrocarbons meaning that it takes a larger percentage of a barrel of oil to get a new barrel of oil which is why we're fracking in tar sands and offshore and because we've used up so much of the easy stuff so when you have diminishing energy return on energy investment of hydrocarbons and the hydrocarbons [2490](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2490.599s)

invested in non-hydrocarbon energy have a long energy return on energy investment so if i want to make renewables i'm going to have to use many years worth of hydrocarbons to do that before it pays itself off you have a major problem right so it's pretty quick to realize even if we figured out how to get off hydrocarbons onto other energy i still can't produce [2512](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2512.14s)

exponentially more physical stuff forever the physical things have limits so how do we go post growth well obviously if i say we got to deal with interest that looks like a complete rework of the monetary system now it goes much deeper i don't have time so i won't get into it but it's a pretty easy analysis to recognize we actually have to end fungible currencies [2532](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2532.78s)

and change what we think of as property law really fundamentally so it's like deep shifts so and even [[nation state]]-based governance um in which you end up getting these [[multipolar trap|multipolar traps]] where we can't be sure china's not building autonomous weapons or since bio weapons in an underground military base therefore we're not going to make an agreement that we're not [2556](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2556.96s)

going to so blah blah blah and the same thing with pricing carbon or fishing the oceans so if you have truly global issues you need [[global governance]] but we don't want global government because we don't want some centralized power that can't be checked so how do we get emergent [[global governance]] that checks the power that becomes a key question in this area of the future of [[social structure]] and i will say so we have to change infrastructure in some key ways we have to change our [[social structure|social structures]] in some really fundamental ways there's some near-term changes that are like just iterative changes on the current system that make them suck a little bit less then there's like phases of deeper changes that require [2595](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2595.24s)

deeper logic that have to occur then you've got the change in the [[superstructure]] the change in culture value identity anytime we have an identity that includes some people and not others or includes us and not the biosphere then obviously we can optimize that which we identify with at the expense of that which we don't identify with but that doesn't work because the [2615](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2615.94s)

people on the other side will do the same thing and you just get an [[arms race]] and the byproducts of that end up [[self-terminating]] so how do you like there's some pretty humongous shifts at the level of culture right that have to happen this can feel overwhelming and disheartening because you're like people don't change that much that [2634](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2634.66s)

quickly but think about this for a minute think about how quickly the facebook algorithm can i'm going to give examples in the us but i'm sure your news sees it can drive people to the january 6 riot on the capitol or to the george floyd kinds of things we can take people and move them into radicalized views relative to each [2658](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2658.839s)

other to the point of outrage violence like that fast because people can't tell that what they're seeing in their news feed isn't a fair representation of the world because it's everything they're seeing they can scroll forever and keep getting it because it's curated for them to and because the nature of the algorithm is optimizing for engagement the stuff that [2681](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2681.52s)

scares us and pisses us off actually maximizes engagement so it ends up appealing to tribalism to our existing confirmation biases to outraged all those kinds of things and that's because of an advertising model where the people are obviously the customers but unlike previous advertising on television or whatever this is able to look at your mouse hover [2703](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2703.54s)

patterns and your click patterns and the patterns of your friends and your network and do ai based personal data harvesting run split tests of things on you so we argue that that is a undue influence that that is um using a level of sensitive information that it should actually be illegal for that to happen [2728](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2728.14s)

it should be required to have a fiduciary responsibility because since it has privileged information meaning it knows more about your choices than your lawyer or your banker or your therapist or your doctor that it shouldn't be in an adversarial relationship with you imagine if we could take the facebook algorithm and the twitter algorithm and change what it optimizes for where [2747](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2747.28s)

rather than if content gets a lot of engagement even if half is negative and half is positive so it drives polarization imagine that you had an algorithm and this is technologically not hard to do that ranked the content more to the degree that it got positive sentiment across political and ideological divides and across network clusters so only if you [2766](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2766.96s)

write shift that people who currently disagree both end up agreeing with does your rank right or similarly you can use large language models to find things that people who disagree about lots of stuff agree on and where you get super majority agreement and you uprank all the things that get super majority agreements let's say that you used the large language [2787](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2787.96s)

models and the algorithms to put in front of you stuff that is to do friend requests of people that are farthest from your social network that are most likely to give totally new and novel input and to give content that is most likely to disrupt your existing worldview right the speed at which you could change [2812](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2812.98s)

culture because again like i said tech affects culture the speed up but but tech via just market process orients towards lower angels of our nature faster than higher angels because they capitalize quicker right one marshmallow behaviors capitalize quicker than two marshmallow behaviors and but that doesn't mean you can't do the other one so if you start [2836](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2836.079s)

to think about if we could apply the suite of technologies we have with a different motive how powerfully we could advance culture relative to anything that gone to your buddha or jesus could have ever imagined being able to do it's actually really exciting and ultimately what i'll say is we're in a time where our infrastructure guided by market forces is going through [2860](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2860.319s)

exponential rate of growth and we don't have comparable growth in our [[social system|social systems]] or in our culture and in fact what's happening is this is hollowing those out right the [[social media]] tech is debasing democracies by driving polarization and you know on and on driving addiction which is affecting um culture [2884](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2884.319s)

and so we're in a situation where our [[social system|social systems]] and our our [[social structure]] and our [[superstructure]] are largely being driven by the infrastructure in a kind of almost deterministic way for us to make it the causal arrows have to start going the other way more which means that you have to have the [[superstructure]] the collective values of the people and a wider shared identity becoming the basis of governance and law where the governance and law implements the tech so that it has the speed and capacity of that which it's trying to regulate so that it can bind guide and direct the tech factoring the way the tech will in turn affect these other areas and so if we want to make it changes [2924](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2924.819s)

have to happen in all three and ultimately the causal direction going this way has to be more emphasized music i want to make sure that we have some time to open up for uh for questions but make sure that you are kind of warmed up to participate just wanted to get a pulse check in the audience are that hearing all of this uh if you have the [2946](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2946.72s)

two choices of that okay this makes me feel uh super optimistic about that there is path forward versus it this is what it takes then we're pretty uh who are in what camp who would are sitting with the feeling that okay this is we're probably beyond saving at this point yeah and and who are then sitting with the feeling of that well uh grit there [2974](https://www.youtube.com/watch?v=kbg8nHuNggU&t=2974.2s)

is a path forward i feel optimistic after hearing this thank you for sharing um with that would would love to uh open up for uh some questions and i'll gather a few of them i want to say one thing about that please okay please do that daniel nobody has enough information to be sure [3008](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3008.119s)

we're it's that requires a unwarranted level of certainty because you actually don't know the possibilities in the solution space well enough and also nobody has the grounding to be sure we make it both of those certainties would be unwarranted [3033](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3033.42s)

and one of the things i want to call people to is um calibrating their confidence margins better and being more comfortable with uncertainty but it's a very specific thing there's a there's this funny thing that i notice often in the us i'm not sure how much it's the same here but i'll talk to someone who's pretty certain about [3053](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3053.88s)

something like trump is awesome or trump is terrible or [[climate change]] this or that or vaccines this or that or whatever thing and they have a pretty high degree of certainty and a pretty high degree of even sanctimony associated and then once i start challenging some of what they're missing in that or the assumptions enough that complexifies it very quickly when they [3074](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3074.04s)

really get that their certainty is not warranted they go into everything's too  complex to make any sense of so they go from certain to hopeless in one step as opposed to like oh maybe is more complex than i thought i should try learning more and so there's a position i would like people to be in which is [3096](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3096.599s)

more epistemic humility and more epistemic commitment and rigor which is not like i'm going to be comfortable with uncertainty and then just keep doing the same stuff it's i'm going to be comfortable with uncertainty because i have to be because any certainty that i pretend to have is probably unwarranted and that's just honest but i'm gonna [3118](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3118.2s)

work to seek better and better insight while still recognizing how much is in the unknown unknown set that i might not be factoring so there is a deepened commitment to better actionable intel with a continuous recognition that my best current understanding will almost certainly not still be the same in five years if i'm really paying attention [3142](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3142.859s)

and so it one of the things that's most dangerous is when people get over certain that we're screwed then there is a utilitarian calculus that makes very bad actions seem ethical right if i'm certain we're screwed then i should start thinking about depopulation strategies or i should try to get my i just try to win the ai race because the ai apocalypse is going to [3167](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3167.819s)

happen anyways but my company winning is a slightly less bad apocalypse because i'm going to make a good ai i'm mentioning that one because those are conversations i've had with people who run those companies who gave up on being able to prevent agi takeover believe it's inevitable so believe they should win because their [[dystopia]] will be less bad the moment you become over certain [3186](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3186.9s)

of a negative thing then with trolley problem calculus you justify other negative stuff this is uh so it's important to recognize something might seem with the data you have very likely but there's so much stuff in the unknown unknown set that you aren't factoring and so there's something like a kind of faith that you have to have and the faith is that there might be solutions that i can't comprehend right now that doesn't just let me sit back and chill it ha but it orients me towards the study because if i don't think there might be solutions i'm not going to try to study and innovate and figure it out and so it's not a blind faith but it's the appropriate faith that the unknown [3234](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3234.3s)

unknown said is a big infinity and so there is a certain kind of optimism not connected to something you know but connected to something you don't know right and then when i come up with a possible solution then i want to bring my pessimism in and red team it and try to find if it's likely to fail before actually [3252](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3252.359s)

doing it and then go back to innovating to find better solutions so i want to have an optimism bound to the unknown and then use my pessimism to red team and thus harden the adequateness of the solutions music i saw a hand please there is a microphone coming christian [3277](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3277.14s)

um so it seems like all of the things that you have talked about rests on a almost deeper mathematical truth that whenever you have some sort of universal optimization based on a narrow metric you will always see externalities regardless if the optimizer is a company an individual a country so with that in mind it is kind of painfully obvious right that ai is not [3308](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3308.819s)

going to solve the problem ai is going to turbos charge the problem because you apply universal optimization yet again on a very narrow metric so the only thing that can solve the day is you know like what you talked about high kind of high resolution complex models and mechanism design i guess based on those types of models but what i'm gonna do with that kind of deeper universal truth [3334](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3334.079s)

in mind is i'm gonna try to take what you have said that is super depressive and make it even more depressive and then i want to see your your reaction to that so in a sense evolution itself is a universal optimization based on a narrow success metric and that's the continuation of genetic material so that means that inevitably throughout you like evolutionary history you will see [3362](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3362.04s)

predators you will see cancer you will see viruses you will see these agents that have this very destructive behavior and humans just tend to be one of them right so it seems to me that life itself is almost inherently unstable that might be the answer to the fermi paradox and maybe we have been just lucky for you know three billion years and in an almost infinite universe by virtue of [3389](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3389.94s)

the entropic principle someone will have been lucky for three billion years so my question to you have we just been lucky for three billion years music yeah so fantastic points the point about whenever you're optimizing for one or a small number of metrics it is a [[paperclip maximizer]] of some kind um and that this is at the heart of the ai alignment problem if people have not studied this and are curious uh eliezer utkowski gave a talk on the ai alignment problem in 2016 that's still probably the best introduction to why this is hard that has to do with how do you define a utility function that is worth optimizing for that doesn't mess up a [3436](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3436.14s)

lot of things and on unobvious ways um so yeah i i think alignment is an extraordinarily hard problem and uh so many people like you know bostrom has proposed the idea humans are that the only solution to [[multipolar trap|multipolar traps]] we found where if one guy does the messed up thing but he gets so much [3465](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3465.599s)

near-term advantage like overfishing or cutting down all the trees or developing the weapon that everybody else has to or they lose by default the only solution we've ever found to that that works all that well is law which means a monopoly of violence which we don't have internationally so we need something like a one world government and yet um with decentralized tech there's not [3484](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3484.079s)

going to be the capacity to enforce a monopoly of island so you have to create even more asymmetry so we need an ai super intelligence overlord to run us because we're basically two kind of nasty and irrational to run ourselves um i don't have any hope in this model when you look at ai alignment issues and whatever i do think of a future that is based on [3506](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3506.64s)

a sin a symbiotic intelligence between unique capacities of human intelligence particularly developed in in certain ways and group [[collective intelligence]] the type of intelligence intrinsic to nature and the type of intelligence computation can do in a particular organization which is what ends up being the future of the political economy that i talk about [3531](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3531.48s)

the question of but oh i want to say something about if you have one metric and you optimize for it you'll cause a lot of harm if we you can get gdp to go up by war you can get gdp to go up by addiction by sick people getting more medicine whatever it is um so you get some more metrics and this is [3551](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3551.04s)

the iatrogenic model in in healthcare right we try to we define the disease by a small number of parameters you make a medicine that addresses that that doesn't address the underlying regulatory processes of the body causes side effects you take another medicine for that blah blah blah so the iatrogenic cascade that happens with that approach to medicine is the same [3572](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3572.76s)

thing that we're doing at a global level um there's something actually really beautiful about this the way i would think about this is that the model of reality is never reality and so you never want to optimize for the model but you can't optimize for reality because your model of it is the thing that you're gonna run your [[supply chain]] analysis off of and whatever it is and so the the old biblical principle of thou shall have no false idols i hold that the model of the reality being taken as reality is a false idol and so i don't want this is the metric set the global national happiness index or the whatever it is we're going to optimize for this thing that is fundamentally like the core sin that is losing contact with [[base reality]] and instead relating with a simulation of reality that we've made up so we can make models we just have to know they're wrong and where the model is different than [[base reality]] is we're optimizing the model will harm based reality so you can use it but you have to keep paying attention to where it's messing stuff up and keep upgrading the model and so you can't get any kind of [3637](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3637.079s)

attachment to the sufficiency or the adequacy of the model nor do you want to run exponential optimization on it right so that means you have to think in a way that is deeper than metrics-based optimization and so the reductionist approach of separate the wholeness of reality into parts find individual metrics to measure each and optimize some weighted [3656](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3656.7s)

combination of those is the wrong epistemic approach to think about wholeness and [[complex system|complex systems]] now what about evolution no there's a really interesting key distinction to make is evolution is not stable that's true but it is metastable and there's a way that human [[tool making]] broke the metastability of it that is the core of the thing we have to address now and what i mean by metastable is that in an ecosystem over time the complexity increases and of course an asteroid or something that is outside of that internal process can change that but why does the orderly complexity of the system tend to increase over time so one species might [3702](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3702.059s)

go extinct but overall the total number of species the complexity of each one the complexity of their interactions increases it's that the [[evolutionary process]] is radically decentralized right each of the animals have their are being guided by their own internal set of computations or whatever you want to think of it as each cell inside the body [3723](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3723.119s)

is governing its own metabolic functions it's not like the brain is regulating the metabolic functions of every cell so you have this radically decentralized process and you also have a process that when we think about evolution genetically we think about genetic mutations and then we think about the selection of [3741](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3741.66s)

those mutations if they lead to surviving and procreating right the forces that create genetic mutations are pretty evenly distributed across the ecosystem so the predator the prey the plant they're all receiving the same oxidative pressures the same gamma rays whatever and so you have a pretty even distribution of mutation the mutations change very little bit at [3761](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3761.7s)

once right you don't get 15 000 genes coordinatedly changing at once like you would in a crispr thing you get some tiny change most of them are non-adaptive if it is adaptive it increases the capacity of that agent a tiny bit and then that agent behaving a tiny bit with more capacity has co-selective pressures on all the other agents in the [3783](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3783.059s)

system so if the prey animal gets a tiny bit faster they're going to eat the predator does they're going to eat slightly more of the prey they're gonna eat the slower ones more which means the faster ones have their genes inbreed and which is another method other than mutation to upregulate the genetics of it and so what you end up getting is that there's this fascinating thing in nature that micro rivalry this lion and this gazelle being in a zero-sum dynamic leads to macro symbiosis across all lions and all gazelles both needing each other and that's almost the idea that we apply when we think of ourselves as [[apex predator|apex predators]] to this kind of theory of markets and social darwinism competition [3820](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3820.98s)

is good competition is what drives innovation blah blah blah there's some truth to that but the meta stability is the result of the symmetry of power between all the animals the gazelles get away as often as the lions catch them so there's a symmetry between predator and prey and there's a cemetery with within the species that the apex lion and the [3841](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3841.68s)

median lion are not that different right the apex lion is not as powerful as tin lions it's as powerful as 1.2 median lions or whatever but then you say how much destructive power does putin have compared to me and we're not talking about 1.2 x we're talking about billions x right or economic power whatever so with the beginning of [[tool making]] humans were able to increase their predatory capacity not through a mutation that occurred equally in everybody but through a conscious creation of an extra corporeal rather than a corporeal or physical capacity which means they were increasing in a way where you don't have the symmetry between everyone and where the other animals don't have the capacity to up [3885](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3885.96s)

regulate to get co-selective dynamics so we could increase our predatory capacity faster than the environment could increase its resilience and with that we went and became [[apex predator|apex predators]] everywhere started extincting species etc so i would argue that tool creation created radical asymmetries between some humans and other humans in terms of who could utilize the technologies better [3905](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3905.28s)

and not just tool creation recursive abstraction recursive abstraction is what leads to the creation of the infrastructure we have the [[social structure]] and the [[superstructure]] memetics is recursive abstraction right the recursive abstraction creates asymmetry between some people and others and then those who are trying to keep up in the [[arms race]] with each other drive an [[arms race]] that separates humans and nature completely all of the issues we're facing are the result of that so because humans have applied recursive abstraction to our methods of advancement we now have to also apply recursive abstractions to what we are trying to advance which means if we have beyond [3945](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3945.48s)

evolutionary capabilities we need beyond evolutionary motive and identity to be able to bind that so i'm not looking for stability i'm looking for meta stability i do see meta stability in ecosystems and i think for humans to be able to participate in that meta stability does require factoring the asymmetry we have relative to each other via recursive abstraction [3968](https://www.youtube.com/watch?v=kbg8nHuNggU&t=3968.04s)

and relative to nature and being able to bind those asymmetries in the design i'm not going to take two questions at the same time so first row working no yes um a question about you had a great beautiful example around synergetic thinking i'm gonna sound like a cartoon character after you so just bear with me um how we can think about not thesis [4008](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4008.24s)

antithesis but like synergetically i think this is something that we can use all of us as an argument and as a society can you talk about that a little bit to us yeah sure um someone actually asked me this question in an interview the other day of if you had one thing you could tell all the [4029](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4029.9s)

listeners to do what would it be and i usually just hate that question because what the computer scientists and what the artist and what the educator and whatever like it's just it's such a weird question to try to answer for everybody but there are some there are some things and the answer i gave her as relevant to this as um to to be able to not just argue but embody the perspectives of the people most different than you and whatever your political view is on vaccines on covet origins on russia on whatever it is the you know it's very easy to have high [4084](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4084.799s)

certainty that our view is right and high sanctimony that we're also morally superior to anyone who would think otherwise and of course the people on the other side think the same thing and so you get a a war of some kind but to be able to realize that the people on the other side have similar brains and have information environments where they're like they love their [4105](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4105.5s)

children they you know they didn't get there just by being dumb and bad um to try to be able to make the argument on the other side well enough they have nothing to add and then to also try to feel the legitimate values that those people hold to feel what the world experience is like and then to come back [4128](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4128.299s)

and see how it modifies the way you had held it and to see are there higher order perspectives that synthesize those things that seem to be in conflict um hey we need to drill more oil to get off of uh dependence on russian oil or sudanese oil or whatever it is for [[national security]] purposes um we need to get off all of the oil for [[climate change]] it's so easy to just be in that war but just take the other side right like if the if the person who's saying we have to get off it for [[climate change]] really looks at war and is like life was nice in ukraine a little while ago and it sucks and it can be that way here or anywhere very quickly and yeah i care about [[national security]] i actually don't want to be totally dependent upon someone who could shut our oil off and then you know and then on the other side they're like yeah i actually don't want increasing extreme weather events everywhere that disrupt everything and coastal cities start to go under it um obviously we live in a situation where there's a lot of incentive to drive polarization and there's [4188](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4188.66s)

underlying tech that motivates doing it um one type of externality that's very common is we appeal to people that think similarly to us to try to solve a problem and in our campaign message we don't think well enough about how that will land for the people that it doesn't land for and the blowback that'll create [4213](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4213.679s)

and so one of the negative results of the thing that you're doing is the blowback of all the opposition that's going to arise that disagrees with the way that you just posed it so rather than appeal to your support base and not pay attention to the other ones to be able to think through how will this land for everybody and are there elements of their [4231](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4231.44s)

perspective i can factor more deeply to be able to engage more people in participatory strategies gentlemen on the fourth row please thanks so much um to try to steer some good news in here and also just i selfishly want to hear your commentary on the the scandinavian or nordic model and you talk about [4266](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4266.3s)

ecosystems that have achieved more of that meta equilibrium um this seems to be a pretty healthy ecosystem relative to places where you're coming from where i'm coming from the u.s do you think there's anything we can learn about coordination of society about people taking care of one another's interests and and really [4285](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4285.38s)

having achieved a much more not perfect but certainly much more healthy society here is there anything we can work on or or champion from this part of the world and take with us as the ambassadors to solve this problem yeah great can i get a time check just to know where we're at 10 minutes [4307](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4307.219s)

um i was just talking with some guys here from swedish military that seemed like they have learned some things different than us and other militaries have um they might be very useful to decreasing conflict and i'm super interested to learn about that [4333](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4333.86s)

nicholas introduced me to a guy who's uh in swedish cyber security and it was a fascinating conversation for me having dealt with security in the u.s and the radically different approach it was the most different approach that i had come across in any country um in uh in u.s [[national security]] stuff almost everything is classified and it's tssci and top secret special compartmentalized information which means you don't just have a certain level then you have access to everything at that level there's a need to know basis only which means you can have a four-star general not have need [4375](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4375.56s)

to know access of something that is at the you know a base that they might manage in a situation like that it's very very easy for people to duplicate the same stuff and be very wasteful to not get to learn from everybody's experiments to actually be in competition with each other for who gets a larger percentage of the budget and [4395](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4395.239s)

thus do espionage and whatever on each other and yet you can see why to classify everything which is if we didn't have something classified let's say that we were to share with the public that means we are sharing with the russians and the chinese who are embedded and spying on everything which means we lose asymmetric information advantage and so when the u.s was formed [4416](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4416.36s)

it had the benefit of basically being an ocean away from everybody and that was pretty awesome from a [[national security]] perspective and in that world and you know 17 whatever the there was no way for a message of what was happening to get back to the british or whoever it was very quickly and there was no way for someone else knowing a vulnerability to attack it very quickly [4440](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4440.239s)

we could see ships coming from a long way away and once you start to get the telegraph and then wireless communications and on and on you get to a situation where actually you can't share honestly with your own citizens because you're sharing with your foe so you have to classify more stuff and as soon as there's more types of warfare you can't even share with the [4458](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4458.239s)

citizens where the food is stored or where the water supply is or whether anything because all of those could be military targets so you start to get a situation where almost everything is a [[national security]] secret well how the  is democracy supposed to work and when the citizens can tell that everything is being kept from them and they have distrust in government so then [4473](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4473.719s)

that orients towards despotic leaders that say it's the other guy's fault and they'll drain the swamp blah blah blah so this guy was telling me here and i don't know all the details but he was saying that um seeing that and sweden knowing that being between the ussr earlier and the us or the european uh you know side that it wasn't [4496](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4496.159s)

going to be able to maintain information asymmetry that long the russians would figure the stuff out the us would figure the stuff out um so they would just not declassify the stuff be able to have more trust of their population in government and be able to have more sharing of the stuff inside and even though that meant they weren't going to have asymmetric attack [4518](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4518.239s)

information they could invest all the resource that goes into classification to other types of security and he was saying we actually found other peaks in the adaptive landscape and where transparency rather than opaqueness one and that was fascinating because the opaqueness is what drives all the [[coordination failure|coordination failures]] right if i don't know if you're doing [[bioweapon|bioweapons]] in an underground lab i have to assume you are and do them as well if we have adequate transparency then we can actually create agreements and so upstream from the ability for agreements is the transparency to know if the agreement is being kept or not and i asked him i'm like well that is kind of easy for a country that isn't at the front of the total [4560](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4560.9s)

geopolitical [[arms race]] and has backing of ones that are do you think that could be applied to china or to u.s um he said that he thought that it could and you know i um i've been thinking about this more if we were to declassify a bunch of things we would open up a lot of vulnerability [4585](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4585.02s)

but we would also open up a lot of capacity to create less duplication more synergy and better coordination that might not have been usable earlier before we could share all that data but with with this as a positive application of ai being able to find where something that was figured out in one place could be applicable to another place and etc [4605](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4605.06s)

there could be a lot of efficiencies that come from that so this is an example of something that i think you know yes entirely possible and of course there's a million examples where i think um smaller countries wealthier countries you know not just northern countries i think we have a lot to learn from japan i think we have a lot to learn from singapore i think we [4626](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4626.06s)

have a lot to learn from bhutan um do the things automatically apply everywhere else no if you have way bigger geographical scale way bigger population scale if you have a different kind of entrenched vested interest that you have to deal with the enactment of not just the idea but how do you get it enacted in the presence of the vested interests that don't want it if you have [4644](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4644.96s)

way more cultural heterogeneity and ideological heterogeneity if you have lower education you're going to have different issues you have to deal with but i do think being able to study things like do even with covid being able to look at the way different countries responded to it and do analysis you know post-mortem analyzes that could inform international policy [4667](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4667.88s)

we could do much better job with that than we do currently music question on the first row but i think that they are fixing it over there um when you were speaking about well first of all when you were speaking about um certainty it was a beautiful invitation to let go of certainty and then i was thinking where am i still holding on to certainty because i'm holding on to a lot of it and then you said what if facebook's algorithm or whatever [[social media]]'s algorithm were turned the other direction and then and what what that did was it allowed me to take the thing that i am so certain of as the great evil because that's my particular uh you know story and think as gr as deep as that evil is to me you could actually spin it the other direction like so so as as far as my [4746](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4746.719s)

imagination can go into the the darkness you're in essence inviting us in the other direction and saying like as far as the darkness can go the light can go which is beautiful it's just a beautiful way to think about it and then i was like okay what am i still certain about so here's my question for you um the the thing with [[social media]] which is so tough for me is pretty much everyone doesn't like it and doesn't want to be using it um and and so that that already seems like well then why are we still using it and and and the thing that that that scared me especially about being in in stockholm [4788](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4788.719s)

where we we care you know i'm american we it seems like they care i'm here because my kids couldn't go to school in california my kids can go to school here my kids didn't have to wear masks they didn't have to do with the whole story and this is a place that cares about children when i ask people here are they aware [4809](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4809.54s)

that [[social media]] is is is literally endangering the lives of their children you know francis helgen and all that it's not something that uh it's not something that we're we're aware of and even in the us we're i would imagine people are aware of it it doesn't it didn't seem to like if that doesn't move the needle what does [4835](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4835.219s)

that's that's what i'm yeah and there's a deeper way i would frame this because you can say why aren't we making more movement on the [[social media]] issue why aren't we making more movement on the [[planetary boundary|planetary boundaries]] issue like the overfishing of the ocean the depletion of the top soil [[species extinction]] like we should be freaked out about that and making more advanced and why [4855](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4855.44s)

why didn't we do nuclear de-escalation better why did blah blah blah there's all these questions um one interesting answer i was thinking about this morning as i was walking to a coffee shop here i got here this morning i can't see these problems right like i can't actually see [[climate change]] it's a hyper object that i can only understand through abstractions and math um i can't see [[species extinction]] uh i can't see nuclear threat right they're all i can see a nuclear bomb but that is not nuclear threat right nuclear threat is the total geopolitical arsenal and all the frailties that go along with it and blah blah i can't see the global [4900](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4900.14s)

material [[supply chain|supply chains]] or and so i and i i can't see forever chemicals that are invisible so basically all of these things are either invisible or they're hyper objects and so i have to understand them through the highest forms of abstract cognition and yet my sensory experience especially if i'm in somewhere like sweden is things seem pretty good [4922](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4922.58s)

and so there's this dissonance between my direct experience and my understanding and yet i'm also told that i'm being disinformed so is my thought of the catastrophe disinformation and and and now i'm actually busy and i have some other to get back to so i'm gonna stop thinking about it um when i go on facebook i don't experience [4946](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4946.04s)

i don't experience russian and chinese and north korean driven population-centric warfare that is targeting specific groups with this info to turn strong countries against themselves on political fault lines i don't experience that i experience content that i resonate with and even if it's pissing me off and polarizing me [4965](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4965.239s)

i'm already sure i'm right so i like it right it's just it's just making me feel badly about the people that are so dumb and so that i feel more motivated to do the good thing um and yet i also see my friends birthdays and stuff that i want to see and i want to post on there and so my and this is the asymmetry of if i cut down a tree [4986](https://www.youtube.com/watch?v=kbg8nHuNggU&t=4986.96s)

i don't get to breathe less the tiny marginal effect that has on decreasing oxygen production and co2 sequestering i still get to breathe so it does the harm that occurs is so marginal i don't notice it but the advantage i get from being able to sell the lumber is immediate real advantage to me where if i leave the tree up i don't breathe any better and yet i don't [5010](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5010.6s)

get that advantage so everyone doing the harmful thing that causes a micro harm that produces the great harm through cumulative effects and yet the the direct benefit happens to them in the moment the harm is invisible and happens supposedly over a very long time as a result of everybody doing the thing this is a real challenge [5031](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5031.6s)

right this requires something like khan's categorical imperative right i'm going to bind myself to what i would want everybody to do it requires a change in the [[perverse incentive]] landscape of um what will benefit me in the short term even if everyone does that causes harm like but if someone else is doing it how do i get out of it it also [5051](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5051.94s)

requires just at a personal level like taking your own choices more seriously like taking more responsibility for the meaningfulness of your life that's not a good enough answer at a public level at a public level trying to solved this problem already right like they solved it like that [5074](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5074.8s)

and then it was scary and awesome right they saw all the [[social media]] issues so they just banned tick tock their version of tick tock they made the version that was allowed to only play between certain hours so kids wouldn't stay up at night and it only now for kids produces educational and museum content and patriotic content they gave their military light phones that don't even [5096](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5096.159s)

have [[social media]] access so they can't get the people tactical capabilities can't get polarized they banned video games outside of certain hours whatever and they're just like oh yeah that's bad for our population it's done and that's where it's hard to be like okay what kind of political economy we want well we have a market based we we let our markets do technology [5115](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5115.84s)

in a way that we have a very hard time regulating and the chinese thing sounds kind of paternalistic but it also meant that the kids aren't all going to get body dysmorphia and it's not susceptible to population-centric warfare so i don't like that answer but i would say the the individual has to be able to [5137](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5137.1s)

compete against the trillion dollar ai empowered multi-billion dollar asymmetric warfare for your attention it's just not a good answer at scale and yet for you individually that is the right answer because it's the thing you have agency over so i know we have to wrap so i think this connects to a closing comment that i have is um all right so i think about i stop and think about ai really is advancing on an [[exponential curve]] way faster than moore's law and that means ai drones in they can be produced in basements it can take out infrastructure i think about [[species extinction]] i think about [[planetary boundary|planetary boundaries]] i think about all these things i'm like and then i gotta go to work or whatever it is or just like stop thinking about it and watch tv or something there are things that can be done some of which are already known and need done much of which need figured out [5206](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5206.8s)

but you've got to stay with it right and what i would offer is you like there is a reality of choice in which so i i want to say something that is very much against the simulation hypothesis and against the kind of modern western buddhist maya interpretation [5231](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5231.639s)

that reality is actually real when it's not an illusion it's not a simulation it would take me a while to argue why i would say that philosophically but i can do it formally um reality is actually real our understanding of reality in which what is important to me to get ahead and what i think i need to be happy is maya right [5252](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5252.76s)

as an illusion but the tree's not an illusion and the kid is not an illusion and if i think this is all illusion then i have no ethical obligation it doesn't even make sense to help the kid if a car is coming at them or anything else so reality is real and it matters and your choice is not perfect there's a lot of deterministic factors but there is an element of choice that is real and [5275](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5275.199s)

matters and in that there is meaningfulness to your life and choice and what i would offer is that currently there has never been a time where the choices we make could affect more because i would say that us failing to make it through the [[metacrisis]] is totally possible it's not a given that we make it and us making it is totally possible which means like it's not [5299](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5299.139s)

determined either way and the choices we make are actually capable of being influential to that and so if i was to leave a final thought on anything it would be if you actually really treated your life like it mattered and that all of your moments had a chance of mattering and they had a chance of mattering not just to you but or even to everybody but [5321](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5321.52s)

to the perpetuity of life's continuation at this unique time how would you live differently uh question we're spending some time on applause i just wanted to mention that nora bateson is here with us and i don't know if you all know her but uh i think nora is one of the great thinkers on these [5358](https://www.youtube.com/watch?v=kbg8nHuNggU&t=5358.659s)

topics in the world and she happens to live here and you should have her here and speak um go to her things she and i are actually doing a talk in a couple days so if you wanted to come do that it's at nav on saturday um it actually ended just with the right spot yeah and then i also just wanted to say thank you to nicholas for inviting me here and uh the team here has been big supports of our work and to you and everybody for making this happen thank you applause