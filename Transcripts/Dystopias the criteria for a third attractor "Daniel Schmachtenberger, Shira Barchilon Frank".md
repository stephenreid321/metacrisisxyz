---
tags: transcript
aliases:
youtube_id: 1r2TSpSNjDI
---

<div class="yt-container"><iframe src="https://www.youtube.com/embed/1r2TSpSNjDI"></iframe></div>

daniel uh thank you so much for coming to schelling point i invited daniel schmokenberger to come here to talk about [[existential risk]] and uh catastrophic [[catastrophic risk|catastrophic risks]] to civilization and he's one of the most lucid thinkers that i've ever listened to on the topic and i'm so excited for this conversation and what the web 3 community can learn [20](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=20.56s)

from the work that you've done so thank you for joining us daniel hey man i'm happy to be here can you guys hear us all right is av adjustable uh maybe we could be closer into the microphone or the av can boost daniel's mic all right is that better alright [42](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=42.0s)

so let's start here daniel what is the [[metacrisis]] and what does that assessment offer in terms of design considerations for our work in regenerative crypto economics yeah i'm going to ask you guys to forgive me i'm just going to kind of talk to kevin because it's easier to deal with the noise that way [61](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=61.52s)

um yeah so the [[metacrisis]] is a way of thinking about all of the interconnected catastrophic and [[existential risk|existential risks]] the world faces right now not just the fact they're interconnected but that they have similar drivers and that if we are to address them we have to not just address them all individually but [78](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=78.88s)

actually look at what the [[generator function|generator functions]] of them are so we know that we have [[existential risk]] many different ways to [[artificial intelligence]] whether we're talking about paper clip maximizing issues or ai drone warfare or simply like ai optimization of an extractive economy we know the same thing when it comes to [99](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=99.04s)

biotech crispr synthetic bio [[existential risk|existential risks]] when it comes to cyber attacks on infrastructure and drone attacks on infrastructure the whole category of [[exponential tech]] creates pretty radical fragilities in the world and um obviously in addition to not just [[climate change]] but all of the [[planetary boundary]] issues that cumulative industrial tech has created right so you can kind of think about [[catastrophic risk]] in two major categories which is the cumulative effects of industrial tech that have linear [[supply chain|supply chains]] linear [[materials economy]] uh hitting limits of growth and so on the extraction of finite resource side and then on the uh you know pollution side so obviously on the pollution side [143](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=143.599s)

of the energy economy you have [[climate change]] on the other side you have actually an issue that's probably going to hit us even sooner which is a diminishing return on uh energy returns on hydrocarbons right with hydrocarbons still being pretty difficult to replace in terms of energy and being pegged to the dollar or being [161](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=161.36s)

pegged to like global gdp and global energy being nearly one for one pegged right and an exponential [[embedded growth obligation]] on currency that means you have an exponential need to grow the total amount of energy in the system while having a diminishing return on energy availability so we can see like [[catastrophic risk]] across [181](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=181.519s)

trying to run exponential linear [[materials economy]] on a finite planet and then you add the x exponential technologies to that the exponential technologies basically radically centralize and decentralize power at the same time the decentralization of power looks like decentralized catastrophic capability so [202](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=202.959s)

the ability to build drone weapons cyber weapons bioweapons ai weapons in basements non-state actors having that where you can't use un style [[mutually assured destruction]] of everyone yeah so the the [[catastrophe weapon|catastrophe weapons]] for everyone world the main solution to solve that is things like kind of the china model which is ubiquitous surveillance to be able to prevent that [227](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=227.84s)

centralization which looks like increased centralization using [[exponential tech]] that gets dystopic so we can say that you have one attractor which is increasing catastrophes and what it takes to be able to control that are control systems that are in imposed central power control systems that create dystopias yeah so we're looking [247](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=247.439s)

for something that is neither catastrophe or [[dystopia]] which would be a [[third attractor]] and i think the thing that's interesting here is obviously underneath all those issues are patterns of human behavior empowered by technology right and patterns of human behavior looks like both our governance systems and our incentive systems right so the [268](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=268.24s)

kind of crypto economic world is looking at the intersection of new incentive systems and new governance systems while also building fundamentally new infrastructure that mediates those right and so what my hope is is that this space understands the design criteria of a [[third attractor]] well right so that they can actually work on making sure [290](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=290.96s)

the systems are developing meet those design criteria got it so if i could say back to you what you said to me it sounds like there's there's one model which is the china model where you've got a centralized actor that's kind of clamping down on their society through surveillance and control and then you've got another model which is kind of where [310](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=310.0s)

the west has traditionally been where you've got existential technology that creates more risks and you don't have uh you've got kind of like decentralization or not a good way of uh of managing that and that system will collapse because you have those technologies in the hands of more and more people and then those are the two attractors and then the [[third attractor]] would be how do we get away from those first two attractors is that roughly yeah the catastrophe model has both [[mistake theory]] and conflict area versions the [[conflict theory]] is catastrophes that somebody intends which is the decentralized [[catastrophe weapon|catastrophe weapons]] mediated by [[exponential tech]] the [[mistake theory|mistake theories]] just increasing externalities and that when your currency system that is mediating everything market wise all has externalities built in exponential externalities create you know eventually cascading catastrophes right so you get catastrophe on both mistake and [[conflict theory]] you get dystopias both at the [[nation state]] level but also at the um web 2 uh metcalfe company level right the facebook google amazon issue is a similar issue because you have corporations that have more power than most [[nation state|nation states]] that still don't have anything like participatory governance or jurisprudence there's no consent to the governed [391](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=391.84s)

so ultimately that's kind of a new feudal oligarchy so whether you're talking about the [[exponential tech]] empowered [[nation state]] like china or the next [[exponential tech]] empowered corporation those are both basically [[exponential tech]] top-down organizations okay got it so what is our way out of the [[metacrisis]] so obviously you've got to look at the [[generator function|generator functions]] of the [[metacrisis]] and then be able to understand the design criteria to solve them if you want to solve it categorically because if you just looked at let's say we sequester all of the co2 and solve near-term [[climate change]] from anthropogenic co2 that doesn't deal with dead zones in the ocean from nitrogen it doesn't deal with overfishing and doesn't deal with biodiversity loss or any of the other environmental issues you actually don't buy many years right if you just deal with one particular kind of ai weapons issue you don't deal with the other ai issues or bioweapons so if you don't [447](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=447.44s)

deal with it kind of categorically you really can't deal with it in an increasing so it's all all or nothing well it's fundamental redesign and i think the thing that's worth pointing out is we had a fundamental redesign of our global system following world war ii which was the bretton world's igo mutual [466](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=466.8s)

destruction world because it was the first time we had tech that could actually cause an [[existential risk]] right before the bomb we just couldn't destroy everything right and so major empires always ward over power this was the first time that you had a war that nobody could win and so you had to prevent what all of human history had all of human civilization history had [488](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=488.16s)

had which was war between the superpowers and so that that world the kind of [[bretton woods]] world mutual assured destruction works when you have two superpowers right and one [[catastrophe weapon]] right or at least a g8 a small number of [503](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=503.68s)

superpowers that can monitor each other okay and where the [[catastrophe weapon]] is very hard to build it takes [[nation state]] level capacities to build nukes it doesn't take [[nation state]] level capacities to build bio weapons right in fact we're like five years out from tabletop crispr being ubiquitous on the current trajectory so how do you create a force nash [521](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=521.839s)

equilibrium how do you create the equivalent of [[mutually assured destruction]] right when you have a undefinable number of non-state actors that are very hard to monitor so you can see that like that solution doesn't work anymore similarly one of the other key aspects of that world was globalization and the global monetary system right [542](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=542.0s)

that said everybody could have more without taking each other's stuff because you're going to exponentially grow the economy which also required exponentially growing the [[materials economy]] which also drove all the [[planetary boundary|planetary boundaries]] which are also [[catastrophic risk|catastrophic risks]] yeah so we have to get to how do you make a system that doesn't require [[exponential growth]] of the monetary system that internalizes externalities and closes loops on [[supply chain|supply chains]] right so this is where starting to think about fundamentally new economic systems and coordination systems gets very central and interesting right now i've read a little bit about [[game b]] which is opting out of our current rivalries games and into into uh something that would bring us towards that [[third attractor]] could you talk about what [[game b]] is and what the design criteria for it look like yeah [[game b]] is a term that um i wasn't part of the initial [[game b]] crew uh right after it kind of dissolved i made friends with jordan hall and jim rutt [602](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=602.56s)

and brett weinstein and some of the people who were that was at santa fe institute and it was just the recognition that this system is [[self-terminating]] right and what and there's a [[game theory]] underneath itself termination yeah so is there something that transcends [[game theory]] that doesn't self-terminate there was a general moniker for anything that met those criteria and then there was a bunch of work on what those criteria must be so right you have you have the idea of what would a good system be if it was globally implemented but then you also have the enactment problem of what does it take to globally implement it to [638](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=638.079s)

boot it yeah if you start with less than everybody right like so one of the reasons why internalizing externalities is so hard like even say a carbon tax is if everybody doesn't do it then whoever does it is relatively disadvantaged to everything yeah and so the global free writer problem [656](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=656.48s)

ends up creating inability for [[nation state|nation states]] to coordinate on stopping [[arms race|arms races]] and tragedy of the commons issues yeah so that issue the [[multipolar trap]] which is anybody does the thing that in the short-term game theoretically wins everyone else has to race to do that thing faster which in creates a system that long term everybody loses yeah this is one of the design constraints of a [678](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=678.079s)

[[game b]] is you actually have to be able to transcend [[multipolar trap|multipolar traps]] categorically right so you've got to be able to say how do we make race to the top scenarios where you make something that doesn't lose in the short term but that also doesn't self-terminate in the long term right and so you know you mentioned that it's hard for [[nation state|nation states]] to coordinate around this problem what if we had a global coordination layer that was transparent and uncorruptable and uh what if what would you say to a room full of 500 people who could program that coordination layer how can we bootload [[game b]] using that coordination layer and if in case it's not clear [716](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=716.24s)

to those who can't read between the lines i'm talking about ethereum uh as a coordination mechanism a substrate for humanity i'll say why transparent is really important is let's say you want to prevent a [[multipolar trap]] that is an [[arms race]] between superpowers that can actually possibly win the [[arms race]] right so far we almost exclusively fail at this right we didn't really achieve nuclear d proliferation and at the time we tried to do nuclear d proliferation there was still an [[arms race]] on hypersonics so that someone could win the first strike only on one vector and not all the other ones and you got more countries that had [753](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=753.6s)

nukes and then more countries that had alliances with countries that had nukes yeah it gets even harder with preventing ai [[arms race|arms races]] or bioarms races because let's say we make a u.n mediated treaty yeah and you're china and i'm the u.s or you're russia or whatever how do i know that you aren't defecting on the treaty in some secret deep underground military base i have to assume that you are so i [773](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=773.519s)

either don't make the treaty or i make the treaty and i defect on it while lying to you about it and trying to spy right and so we just don't have a way of getting out of that the only way to be able to have the treaties work was if there was some trust that there was adequate transparency right because otherwise the um first mover advantage is so powerful [791](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=791.04s)

in some of these areas that there will be the race for for first mover which means that then there's an incentive to classify everything really effectively right so for secrecy i was just talking to the head of cyber security for sweden and it's very interesting because sweden doesn't have a black budget at all really everything that their military does is completely transparent and transparent to their own people so that people can actually democratically participate obviously means transparent to the us russia china and everyone else right and he said their idea was everybody russia already knows the us already knows so rather than invest a bunch of resource in hiding it let's invest the resource [829](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=829.04s)

in just doing better okay i don't believe that works if they aren't backed up by nato that involves the us having a bunch of stuff in black projects that can win first mover advantage on [[arms race|arms races]] against russia or china in that case and so what you have to make happen is if you want to be able to solve [[arms race|arms races]] you have to be able to ensure that the various sides actually can monitor so you either need transparency or you need some kind of zero knowledge proof type phenomena right where then they can make an agreement and trust that the agreement actually has the transparency needed for enforcement now that means you have to make the transparent system beat the non-transparent system and i think there's a very real possibility because like in the us the special compartmentalized information classification means that there's such shitty coordination between the departments there's a huge amount of waste right so if you could remove all of if you could lose the benefits of classification but the benefits of [886](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=886.56s)

transparency were more game theoretically beneficial for that in-group relative to the rivalrous out group then you would drive a race to the top on transparency rather than a [[race to the bottom]] on secrecy yeah then you would have the transparent basis to actually be able to solve [[multipolar trap|multipolar traps]] i see okay [903](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=903.12s)

um so we would say that's that would be an example of a design constraint for a [[third attractor]] right is if you can make your transparent system categorically out compete the non-transparent system right you're going to drive fun significant races to the top but you have to and the same thing is like let's say you try to internalize an externality in your current system like [924](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=924.0s)

you're going to try to internalize the cost of carbon in the environment right the reason that we externalize it and just price the cost of coal or oil at the price of extraction plus a margin is because the more of the cost you externalize the more profit you make the profit the dollars are basically optionality tokens that mean i [943](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=943.36s)

have the maximum optionality for to be able to influence militaries or media or whatever i want right whoever maximizes the optionality tokens under rigorous competitive environments wins against those who don't yeah and so there's no real competitively effective way to internalize those externalities right unless you bind a whole system that internalizes its externalities but [965](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=965.6s)

also out innovates and you can't invest in the innovation thing without investing in the whole thing right and the whole thing even with the internalized externality still out competes the other rivalry system then you can start to get somewhere wow what a thread to pull um we only have two more minutes i just got the signal from the stage manager so what [986](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=986.079s)

didn't i ask you that you want to tell us and and and where should we leave the conversation how do we continue the conversation well you and i are gonna do a deep version of this what are the [[generator function|generator functions]] of the [[metacrisis]] and how do each of those [[generator function|generator functions]] give a design constraint for a non-[[self-terminating]] system but that also can bootload through rivalry right and we'll take the time to unpack that so if people are interested great um that's on your podcast yep so the greenpill podcast that we just launched on the bankless network we'll do a long-form portion of this conversation with daniel schmokenberger and uh lay out how we can get out of the [[metacrisis]] one thought i would share just in closing here is when you look at marvin harris's model for thinking about civilizations that any civilization you can think of as the infrastructure that mediates all the physical needs in relationship with the physical planet the [[social structure]] that are the kind of collective agreements fields [1042](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=1042.959s)

basically governance and law and then the [[superstructure]] which is culture and the ordinating values right you guys are the crypto space is building new fundamental infrastructure and fundamentally new [[social structure]] simultaneously the critical thing is the culture the [[superstructure]] that is what is the basis of the law that we use to bind the incentives [1061](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=1061.6s)

because incentive alone will create [[multipolar trap|multipolar traps]] and externalities you also have to have binding dynamics and ultimately law for jurisprudence has to be bound in culture cultural values so getting the cultural values right and having them informed by [[metacrisis]] so it says we can debate what a desirable civilization is but we're all pretty much in agreement [1082](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=1082.559s)

that at minimum it shouldn't self-terminate right and so if we take the criterion not self-terminate as a beginning point and then make sure that those values are encoded in the [[social structure]] layer and make sure that the crate the nature of the infrastructure insofar as that's influencing the [[social structure]] and the values is all moving in the right [1100](https://www.youtube.com/watch?v=1r2TSpSNjDI&t=1100.88s)

direction that's really really critical piece amazing well um i look forward to being your bridge to the ethereum space and to the ethereum space back to you everyone give it up for daniel schmackenberger thanks joe